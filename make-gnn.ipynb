{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import getpass\nfrom pathlib import Path\nfrom typing import Any, Callable, List, Optional, Sequence, Tuple, Union\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom scipy.interpolate import interp1d\nfrom sklearn.preprocessing import RobustScaler\nfrom torch import LongTensor, Tensor\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nfrom transformers import get_cosine_schedule_with_warmup\n\nCOMP_NAME = \"icecube-neutrinos-in-deep-ice\"\n# Return the “login name” of the user\nKERNEL = False if getpass.getuser() == \"anjum\" else True\nif not KERNEL:  # in personal computer\n    INPUT_PATH = Path(f\"/mnt/storage_dimm2/kaggle_data/{COMP_NAME}\")\n    OUTPUT_PATH = Path(f\"/mnt/storage_dimm2/kaggle_output/{COMP_NAME}\")\n    MODEL_CACHE = Path(\"/mnt/storage/model_cache/torch\")\n    TRANSPARENCY_PATH = INPUT_PATH / \"ice_transparency.txt\"\nelse:           # in kaggle\n    INPUT_PATH = Path(f\"/kaggle/input/{COMP_NAME}\")\n    MODEL_CACHE = None\n    TRANSPARENCY_PATH = \"/kaggle/input/icecubetransparency/ice_transparency.txt\"\n\n    # Install packages\n    import subprocess\n\n    if torch.cuda.is_available():\n        whls = [\n            \"/kaggle/input/pytorchgeometric/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl\",\n            \"/kaggle/input/pytorchgeometric/torch_scatter-2.1.0-cp37-cp37m-linux_x86_64.whl\",\n            \"/kaggle/input/pytorchgeometric/torch_sparse-0.6.16-cp37-cp37m-linux_x86_64.whl\",\n            \"/kaggle/input/pytorchgeometric/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl\",\n            \"/kaggle/input/pytorchgeometric/torch_geometric-2.2.0-py3-none-any.whl\",\n            \"/kaggle/input/pytorchgeometric/ruamel.yaml-0.17.21-py3-none-any.whl\",\n        ]\n    else:\n        whls = [\n            \"/kaggle/input/pytorch-geometric/PyTorch-Geometric/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl\",\n            \"/kaggle/input/pytorch-geometric/PyTorch-Geometric/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl\",\n            \"/kaggle/input/pytorch-geometric/PyTorch-Geometric/torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl\",\n            \"/kaggle/input/pytorch-geometric/PyTorch-Geometric/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl\",\n            \"/kaggle/input/pytorch-geometric/PyTorch-Geometric/torch_geometric-2.1.0.post1-py3-none-any.whl\",\n            \"/kaggle/input/pytorchgeometric/ruamel.yaml-0.17.21-py3-none-any.whl\",\n        ]\n\n    for w in whls:\n        print(\"Installing\", w)\n        subprocess.call([\"pip\", \"install\", w, \"--no-deps\", \"--upgrade\"])\n\n    import sys\n#     sys.path.append(\"/kaggle/input/graphnet/graphnet-main/src\")\n\n# from graphnet.models.graph_builders import KNNGraphBuilder\n# from graphnet.models.task.reconstruction import (\n#     AzimuthReconstructionWithKappa,\n#     ZenithReconstruction,\n# )\n# from graphnet.training.loss_functions import VonMisesFisher2DLoss, CosineLoss\n# from graphnet.models.gnn.gnn import GNN\n# from graphnet.models.utils import calculate_xyzt_homophily\n# from graphnet.utilities.config import save_model_config\n\nimport torch_geometric\nimport torch_geometric.nn as pyg_nn\nfrom torch_geometric.data import Data, Dataset\nfrom torch_geometric.loader import DataLoader\n# from torch_geometric.nn import EdgeConv\nfrom torch_geometric.nn import EdgeConv, SAGEConv, ChebConv, GCNConv\n# from torch_geometric.nn.pool import knn_graph\nfrom torch_geometric.nn import knn_graph\nfrom torch_geometric.typing import Adj\n\nimport torch_scatter\nfrom torch_scatter import scatter_max, scatter_mean, scatter_min, scatter_sum\n\nGLOBAL_POOLINGS = {\n    \"min\": scatter_min,\n    \"max\": scatter_max,\n    \"sum\": scatter_sum,\n    \"mean\": scatter_mean,\n}\n\n_dtype = {\n    \"batch_id\": \"int16\",\n    \"event_id\": \"int64\",\n}","metadata":{"_uuid":"632c42d7-0e51-42ee-8205-cc7fec9d0c56","_cell_guid":"7e3ab8b8-8781-4d27-958b-ea47012eb172","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-17T01:44:22.514994Z","iopub.execute_input":"2023-04-17T01:44:22.515320Z","iopub.status.idle":"2023-04-17T01:46:41.638752Z","shell.execute_reply.started":"2023-04-17T01:44:22.515242Z","shell.execute_reply":"2023-04-17T01:46:41.637497Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Installing /kaggle/input/pytorchgeometric/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl\nProcessing /kaggle/input/pytorchgeometric/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: torch-cluster\nSuccessfully installed torch-cluster-1.6.0\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: There was an error checking the latest version of pip.\n","output_type":"stream"},{"name":"stdout","text":"Installing /kaggle/input/pytorchgeometric/torch_scatter-2.1.0-cp37-cp37m-linux_x86_64.whl\nProcessing /kaggle/input/pytorchgeometric/torch_scatter-2.1.0-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: torch-scatter\nSuccessfully installed torch-scatter-2.1.0\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: There was an error checking the latest version of pip.\n","output_type":"stream"},{"name":"stdout","text":"Installing /kaggle/input/pytorchgeometric/torch_sparse-0.6.16-cp37-cp37m-linux_x86_64.whl\nProcessing /kaggle/input/pytorchgeometric/torch_sparse-0.6.16-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: torch-sparse\nSuccessfully installed torch-sparse-0.6.16\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: There was an error checking the latest version of pip.\n","output_type":"stream"},{"name":"stdout","text":"Installing /kaggle/input/pytorchgeometric/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl\nProcessing /kaggle/input/pytorchgeometric/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: torch-spline-conv\nSuccessfully installed torch-spline-conv-1.2.1\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: There was an error checking the latest version of pip.\n","output_type":"stream"},{"name":"stdout","text":"Installing /kaggle/input/pytorchgeometric/torch_geometric-2.2.0-py3-none-any.whl\nProcessing /kaggle/input/pytorchgeometric/torch_geometric-2.2.0-py3-none-any.whl\nInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.2.0\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: There was an error checking the latest version of pip.\n","output_type":"stream"},{"name":"stdout","text":"Installing /kaggle/input/pytorchgeometric/ruamel.yaml-0.17.21-py3-none-any.whl\nProcessing /kaggle/input/pytorchgeometric/ruamel.yaml-0.17.21-py3-none-any.whl\nInstalling collected packages: ruamel.yaml\nSuccessfully installed ruamel.yaml-0.17.21\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\nWARNING: There was an error checking the latest version of pip.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"https://github.com/graphnet-team/graphnet","metadata":{}},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"!cat /kaggle/input/icecubetransparency/ice_transparency.txt","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:46:41.641275Z","iopub.execute_input":"2023-04-17T01:46:41.642398Z","iopub.status.idle":"2023-04-17T01:46:42.652005Z","shell.execute_reply.started":"2023-04-17T01:46:41.642333Z","shell.execute_reply":"2023-04-17T01:46:42.650643Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"depth scattering_len absorption_len\n1398.4 13.2 45.1\n1408.4 14.0 48.6\n1418.4 14.7 53.2\n1428.4 17.0 57.6\n1438.4 16.0 57.6\n1448.4 14.4 52.2\n1458.4 16.0 60.1\n1468.4 20.8 74.6\n1478.4 26.7 96.6\n1488.4 34.7 110.5\n1498.4 39.7 135.6\n1508.5 38.7 134.7\n1518.6 27.8 98.2\n1528.7 16.6 64.7\n1538.8 13.7 48.5\n1548.7 13.5 44.3\n1558.7 15.7 54.4\n1568.5 15.7 56.7\n1578.5 14.7 52.1\n1588.5 17.6 60.7\n1598.5 21.6 72.7\n1608.5 24.0 78.9\n1618.5 20.0 68.7\n1628.5 17.8 66.6\n1638.5 28.9 100.0\n1648.4 36.9 128.6\n1658.4 42.1 148.2\n1668.4 46.5 165.7\n1678.5 45.4 156.0\n1688.5 39.1 138.5\n1698.5 30.6 113.9\n1708.5 26.5 90.2\n1718.5 19.3 73.5\n1728.5 20.8 75.9\n1738.5 20.1 67.8\n1748.5 20.3 68.6\n1758.5 24.5 83.8\n1768.5 33.5 119.5\n1778.5 36.2 121.6\n1788.5 35.4 108.3\n1798.5 32.3 113.4\n1808.5 40.2 139.1\n1818.4 44.7 148.1\n1828.4 34.5 122.8\n1838.4 30.6 113.8\n1848.4 27.5 89.9\n1858.4 19.7 71.7\n1868.5 21.4 70.6\n1878.5 28.8 95.9\n1888.5 38.3 116.5\n1898.5 38.4 143.6\n1908.5 44.2 169.4\n1918.5 50.5 178.0\n1928.5 46.6 156.5\n1938.5 36.8 135.3\n1948.5 26.7 103.9\n1958.5 20.3 75.2\n1968.5 17.4 66.2\n1978.5 16.1 53.7\n1988.4 9.4 33.6\n1998.4 10.6 36.2\n2008.4 13.2 44.0\n2018.5 10.9 40.4\n2028.5 6.8 24.9\n2038.5 5.5 20.1\n2048.5 5.0 17.9\n2058.5 7.2 28.4\n2068.5 9.8 34.4\n2078.5 12.2 41.6\n2088.5 21.1 84.4\n2098.5 54.3 173.1\n2108.5 50.5 180.8\n2118.4 33.5 116.7\n2128.4 34.6 120.4\n2138.4 48.4 164.4\n2148.4 53.2 172.8\n2158.3 46.3 149.2\n2168.3 32.9 108.4\n2178.3 27.4 91.1\n2188.2 30.5 98.9\n2198.2 28.9 94.0\n2208.2 35.1 113.1\n2218.2 39.9 134.8\n2228.2 48.0 154.1\n2238.3 53.3 157.6\n2248.3 54.8 180.5\n2258.3 57.9 179.7\n2268.2 61.1 185.2\n2278.2 76.8 227.2\n2288.1 79.0 220.8\n2298.0 75.6 223.9\n2308.0 75.3 256.6\n2318.0 78.0 264.4\n2328.0 59.4 193.7\n2338.0 51.8 159.1\n2348.0 32.9 118.7\n2357.9 23.9 86.2\n2367.8 28.6 104.0\n2377.8 32.5 119.7\n2387.8 44.5 140.6\n2397.9 56.9 203.5\n2408.0 57.5 201.8\n2418.0 54.3 178.2\n2428.1 61.3 206.0\n2438.1 68.8 205.2\n2448.2 77.6 232.1\n2458.2 79.8 259.4\n2468.3 89.4 276.1\n2478.4 80.7 244.3\n2488.4 56.7 185.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# datasets.py\ndef ice_transparency(data_path, datum=1950):\n    # Data from page 31 of https://arxiv.org/pdf/1301.5361.pdf\n    # Datum is from footnote 8 of page 29\n    df = pd.read_csv(data_path, delim_whitespace=True)\n    df[\"z\"] = df[\"depth\"] - datum\n    df[\"z_norm\"] = df[\"z\"] / 500\n    df[[\"scattering_len_norm\", \"absorption_len_norm\"]] = RobustScaler().fit_transform(\n        df[[\"scattering_len\", \"absorption_len\"]]\n    )\n\n    # These are both roughly equivalent after scaling\n    f_scattering = interp1d(df[\"z_norm\"], df[\"scattering_len_norm\"])\n    f_absorption = interp1d(df[\"z_norm\"], df[\"absorption_len_norm\"])\n    return f_scattering, f_absorption","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:46:42.654114Z","iopub.execute_input":"2023-04-17T01:46:42.654474Z","iopub.status.idle":"2023-04-17T01:46:42.662512Z","shell.execute_reply.started":"2023-04-17T01:46:42.654432Z","shell.execute_reply":"2023-04-17T01:46:42.661272Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class IceCubeDataset(Dataset):\n    def __init__(\n        self,\n        batch_id,\n        event_ids,\n        sensor_df,\n        mode=\"test\",\n        y=None,\n        pulse_limit=300,\n        transform=None,\n        pre_transform=None,\n        pre_filter=None,\n    ):\n        super().__init__(transform, pre_transform, pre_filter)\n        self.y = y\n        self.event_ids = event_ids\n        self.batch_df = pd.read_parquet(INPUT_PATH / mode / f\"batch_{batch_id}.parquet\")\n        self.sensor_df = sensor_df\n        self.pulse_limit = pulse_limit\n        self.f_scattering, self.f_absorption = ice_transparency(TRANSPARENCY_PATH)\n\n        self.batch_df[\"time\"] = (self.batch_df[\"time\"] - 1.0e04) / 3.0e4\n        self.batch_df[\"charge\"] = np.log10(self.batch_df[\"charge\"]) / 3.0\n        self.batch_df[\"auxiliary\"] = self.batch_df[\"auxiliary\"].astype(int) - 0.5\n\n    def len(self):\n        return len(self.event_ids)\n\n    def get(self, idx):\n        event_id = self.event_ids[idx]\n        event = self.batch_df.loc[event_id]\n    \n        # represent each event by a single graph\n        event = pd.merge(event, self.sensor_df, on=\"sensor_id\")\n        col = [\"x\", \"y\", \"z\", \"time\", \"charge\", \"qe\", \"auxiliary\"]\n\n        x = event[col].values\n        x = torch.tensor(x, dtype=torch.float32)\n        data = Data(x=x, n_pulses=torch.tensor(x.shape[0], dtype=torch.int32))\n\n        # Add ice transparency data\n        z = data.x[:, 2].numpy()\n        scattering = torch.tensor(self.f_scattering(z), dtype=torch.float32).view(-1, 1)\n        # absorption = torch.tensor(self.f_absorption(z), dtype=torch.float32).view(-1, 1)\n\n        data.x = torch.cat([data.x, scattering], dim=1)\n\n        # Downsample the large events\n        if data.n_pulses > self.pulse_limit:\n            data.x = data.x[np.random.choice(data.n_pulses, self.pulse_limit)]\n            data.n_pulses = torch.tensor(self.pulse_limit, dtype=torch.int32)\n    \n        # Builds graph from the k-nearest neighbours.\n        data.edge_index = knn_graph(\n            data.x[:, [0, 1, 2]],  # x, y, z\n            k=8,\n            batch=None,\n            loop=False\n        )\n\n        if self.y is not None:\n            y = self.y.loc[idx, :].values\n            y = torch.tensor(y, dtype=torch.float32)\n            data.y = y\n\n        return data","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:46:42.665673Z","iopub.execute_input":"2023-04-17T01:46:42.666333Z","iopub.status.idle":"2023-04-17T01:46:42.682256Z","shell.execute_reply.started":"2023-04-17T01:46:42.666273Z","shell.execute_reply":"2023-04-17T01:46:42.681382Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# preprocessing.py\ndef prepare_sensors():\n    sensors = pd.read_csv(INPUT_PATH / \"sensor_geometry.csv\").astype(\n        {\n            \"sensor_id\": np.int16,\n            \"x\": np.float32,\n            \"y\": np.float32,\n            \"z\": np.float32,\n        }\n    )\n    sensors[\"string\"] = 0\n    sensors[\"qe\"] = 1\n\n    for i in range(len(sensors) // 60):\n        start, end = i * 60, (i * 60) + 60\n        sensors.loc[start:end, \"string\"] = i\n\n        # High Quantum Efficiency in the lower 50 DOMs - https://arxiv.org/pdf/2209.03042.pdf (Figure 1)\n        if i in range(78, 86):\n            start_veto, end_veto = i * 60, (i * 60) + 10\n            start_core, end_core = end_veto + 1, (i * 60) + 60\n            sensors.loc[start_core:end_core, \"qe\"] = 1.35\n\n    # https://github.com/graphnet-team/graphnet/blob/b2bad25528652587ab0cdb7cf2335ee254cfa2db/src/graphnet/models/detector/icecube.py#L33-L41\n    # Assume that \"rde\" (relative dom efficiency) is equivalent to QE\n    sensors[\"x\"] /= 500\n    sensors[\"y\"] /= 500\n    sensors[\"z\"] /= 500\n    sensors[\"qe\"] -= 1.25\n    sensors[\"qe\"] /= 0.25\n\n    return sensors","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:46:42.684005Z","iopub.execute_input":"2023-04-17T01:46:42.684428Z","iopub.status.idle":"2023-04-17T01:46:42.696316Z","shell.execute_reply.started":"2023-04-17T01:46:42.684371Z","shell.execute_reply":"2023-04-17T01:46:42.695419Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sensors = prepare_sensors()\nsensors","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:46:42.697896Z","iopub.execute_input":"2023-04-17T01:46:42.698395Z","iopub.status.idle":"2023-04-17T01:46:42.771884Z","shell.execute_reply.started":"2023-04-17T01:46:42.698333Z","shell.execute_reply":"2023-04-17T01:46:42.770858Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      sensor_id        x        y        z  string   qe\n0             0 -0.51228 -1.04216  0.99206       0 -1.0\n1             1 -0.51228 -1.04216  0.95802       0 -1.0\n2             2 -0.51228 -1.04216  0.92398       0 -1.0\n3             3 -0.51228 -1.04216  0.88994       0 -1.0\n4             4 -0.51228 -1.04216  0.85590       0 -1.0\n...         ...      ...      ...      ...     ...  ...\n5155       5155 -0.02194  0.01344 -0.94478      85  0.4\n5156       5156 -0.02194  0.01344 -0.95878      85  0.4\n5157       5157 -0.02194  0.01344 -0.97280      85  0.4\n5158       5158 -0.02194  0.01344 -0.98682      85  0.4\n5159       5159 -0.02194  0.01344 -1.00146      85  0.4\n\n[5160 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sensor_id</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>string</th>\n      <th>qe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-0.51228</td>\n      <td>-1.04216</td>\n      <td>0.99206</td>\n      <td>0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-0.51228</td>\n      <td>-1.04216</td>\n      <td>0.95802</td>\n      <td>0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-0.51228</td>\n      <td>-1.04216</td>\n      <td>0.92398</td>\n      <td>0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>-0.51228</td>\n      <td>-1.04216</td>\n      <td>0.88994</td>\n      <td>0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>-0.51228</td>\n      <td>-1.04216</td>\n      <td>0.85590</td>\n      <td>0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5155</th>\n      <td>5155</td>\n      <td>-0.02194</td>\n      <td>0.01344</td>\n      <td>-0.94478</td>\n      <td>85</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>5156</th>\n      <td>5156</td>\n      <td>-0.02194</td>\n      <td>0.01344</td>\n      <td>-0.95878</td>\n      <td>85</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>5157</th>\n      <td>5157</td>\n      <td>-0.02194</td>\n      <td>0.01344</td>\n      <td>-0.97280</td>\n      <td>85</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>5158</th>\n      <td>5158</td>\n      <td>-0.02194</td>\n      <td>0.01344</td>\n      <td>-0.98682</td>\n      <td>85</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>5159</th>\n      <td>5159</td>\n      <td>-0.02194</td>\n      <td>0.01344</td>\n      <td>-1.00146</td>\n      <td>85</td>\n      <td>0.4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5160 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"meta = pd.read_parquet(\n    INPUT_PATH / f\"train_meta.parquet\", columns=[\"batch_id\", \"event_id\", \"azimuth\", \"zenith\"]\n).astype(_dtype)\nmeta","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:46:42.773790Z","iopub.execute_input":"2023-04-17T01:46:42.774208Z","iopub.status.idle":"2023-04-17T01:47:16.527434Z","shell.execute_reply.started":"2023-04-17T01:46:42.774170Z","shell.execute_reply":"2023-04-17T01:47:16.525567Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"           batch_id    event_id   azimuth    zenith\n0                 1          24  5.029555  2.087498\n1                 1          41  0.417742  1.549686\n2                 1          59  1.160466  2.401942\n3                 1          67  5.845952  0.759054\n4                 1          72  0.653719  0.939117\n...             ...         ...       ...       ...\n131953919       660  2147483597  5.895612  0.333071\n131953920       660  2147483603  3.273695  1.503301\n131953921       660  2147483617  2.945376  1.723253\n131953922       660  2147483626  1.616582  1.937025\n131953923       660  2147483627  3.062654  1.842630\n\n[131953924 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>batch_id</th>\n      <th>event_id</th>\n      <th>azimuth</th>\n      <th>zenith</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24</td>\n      <td>5.029555</td>\n      <td>2.087498</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>41</td>\n      <td>0.417742</td>\n      <td>1.549686</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>59</td>\n      <td>1.160466</td>\n      <td>2.401942</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>67</td>\n      <td>5.845952</td>\n      <td>0.759054</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>72</td>\n      <td>0.653719</td>\n      <td>0.939117</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>131953919</th>\n      <td>660</td>\n      <td>2147483597</td>\n      <td>5.895612</td>\n      <td>0.333071</td>\n    </tr>\n    <tr>\n      <th>131953920</th>\n      <td>660</td>\n      <td>2147483603</td>\n      <td>3.273695</td>\n      <td>1.503301</td>\n    </tr>\n    <tr>\n      <th>131953921</th>\n      <td>660</td>\n      <td>2147483617</td>\n      <td>2.945376</td>\n      <td>1.723253</td>\n    </tr>\n    <tr>\n      <th>131953922</th>\n      <td>660</td>\n      <td>2147483626</td>\n      <td>1.616582</td>\n      <td>1.937025</td>\n    </tr>\n    <tr>\n      <th>131953923</th>\n      <td>660</td>\n      <td>2147483627</td>\n      <td>3.062654</td>\n      <td>1.842630</td>\n    </tr>\n  </tbody>\n</table>\n<p>131953924 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"batch_ids = meta[\"batch_id\"].unique()\nbatch_ids","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:47:16.535368Z","iopub.execute_input":"2023-04-17T01:47:16.537129Z","iopub.status.idle":"2023-04-17T01:47:17.223405Z","shell.execute_reply.started":"2023-04-17T01:47:16.537068Z","shell.execute_reply":"2023-04-17T01:47:17.222362Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n       248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n       274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n       287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n       300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n       313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n       339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n       365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n       391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n       469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n       482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n       495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n       508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520,\n       521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533,\n       534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546,\n       547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n       560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572,\n       573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585,\n       586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598,\n       599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611,\n       612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624,\n       625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637,\n       638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650,\n       651, 652, 653, 654, 655, 656, 657, 658, 659, 660], dtype=int16)"},"metadata":{}}]},{"cell_type":"code","source":"# for i, b in enumerate(batch_ids):\n#     event_ids = meta[meta[\"batch_id\"] == b][\"event_id\"].tolist()\n#     y = meta[meta[\"batch_id\"] == b][['zenith', 'azimuth']].reset_index(drop=True)\n#     dataset = IceCubeDataset(\n#         b, event_ids, sensors, mode='train', y=y,\n#     )\n#     print(f'batch {i}')\n#     print(\"num of graph:\", len(dataset), '\\t', dataset[0], '\\t', dataset[1])\n#     if i >= 3:\n#         break","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:47:17.225036Z","iopub.execute_input":"2023-04-17T01:47:17.225433Z","iopub.status.idle":"2023-04-17T01:47:17.230368Z","shell.execute_reply.started":"2023-04-17T01:47:17.225393Z","shell.execute_reply":"2023-04-17T01:47:17.229467Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# dataset[0].edge_index","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:47:17.235209Z","iopub.execute_input":"2023-04-17T01:47:17.235919Z","iopub.status.idle":"2023-04-17T01:47:17.240410Z","shell.execute_reply.started":"2023-04-17T01:47:17.235876Z","shell.execute_reply":"2023-04-17T01:47:17.239425Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Dynamic graph","metadata":{}},{"cell_type":"code","source":"def calculate_distance_matrix(xyz_coords: Tensor) -> Tensor:\n    \"\"\"Calculate the matrix of pairwise distances between pulses.\n    Args:\n        xyz_coords: (x,y,z)-coordinates of pulses, of shape [nb_doms, 3].\n    Returns:\n        Matrix of pairwise distances, of shape [nb_doms, nb_doms]\n    \"\"\"\n    diff = xyz_coords.unsqueeze(dim=2) - xyz_coords.T.unsqueeze(dim=0)\n    return torch.sqrt(torch.sum(diff**2, dim=1))\n\n\nclass EuclideanGraphBuilder(nn.Module):\n    \"\"\"Builds graph according to Euclidean distance between nodes.\n    See https://arxiv.org/pdf/1809.06166.pdf.\n    \"\"\"\n    def __init__(\n        self,\n        sigma: float,\n        threshold: float = 0.0,\n        columns: List[int] = None,\n    ):\n        \"\"\"Construct `EuclideanGraphBuilder`.\"\"\"\n        # Base class constructor\n        super().__init__()\n\n        # Check(s)\n        if columns is None:\n            columns = [0, 1, 2]\n\n        # Member variable(s)\n        self._sigma = sigma\n        self._threshold = threshold\n        self._columns = columns\n\n    def forward(self, data: Data) -> Data:\n        \"\"\"Forward pass.\"\"\"\n        # Constructs the adjacency matrix from the raw, DOM-level data and\n        # returns this matrix\n        xyz_coords = data.x[:, self._columns]\n\n        # Construct block-diagonal matrix indicating whether pulses belong to\n        # the same event in the batch\n        batch_mask = data.batch.unsqueeze(dim=0) == data.batch.unsqueeze(dim=1)\n\n        distance_matrix = calculate_distance_matrix(xyz_coords)\n        affinity_matrix = torch.exp(\n            -0.5 * distance_matrix**2 / self._sigma**2\n        )\n\n        # Use softmax to normalise all adjacencies to one for each node\n        exp_row_sums = torch.exp(affinity_matrix).sum(axis=1)\n        weighted_adj_matrix = torch.exp(\n            affinity_matrix\n        ) / exp_row_sums.unsqueeze(dim=1)\n\n        # Only include edges with weights that exceed the chosen threshold (and\n        # are part of the same event)\n        sources, targets = torch.where(\n            (weighted_adj_matrix > self._threshold) & (batch_mask)\n        )\n        edge_weights = weighted_adj_matrix[sources, targets]\n\n        data.edge_index = torch.stack((sources, targets))\n        data.edge_weight = edge_weights\n\n        return data","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:47:17.242151Z","iopub.execute_input":"2023-04-17T01:47:17.242584Z","iopub.status.idle":"2023-04-17T01:47:17.255690Z","shell.execute_reply.started":"2023-04-17T01:47:17.242548Z","shell.execute_reply":"2023-04-17T01:47:17.254765Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class DenseDynBlock(nn.Module):\n    \"\"\"\n    Dense Dynamic graph convolution block\n    \"\"\"\n    def __init__(self, in_channels, out_channels=64, sigma=0.5):\n        super(DenseDynBlock, self).__init__()\n        self.GraphBuilder = EuclideanGraphBuilder(sigma=sigma)\n        self.gnn = SAGEConv(in_channels, out_channels)\n\n    def forward(self, data):\n        data1 = self.GraphBuilder(data)\n        x, edge_index, batch = data1.x, data1.edge_index, data1.batch\n        x = self.gnn(x, edge_index)\n        data1.x = torch.cat((x, data.x), 1)\n        return data1","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:47:17.257317Z","iopub.execute_input":"2023-04-17T01:47:17.258025Z","iopub.status.idle":"2023-04-17T01:47:17.270546Z","shell.execute_reply.started":"2023-04-17T01:47:17.257975Z","shell.execute_reply":"2023-04-17T01:47:17.269442Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class MyGNN(nn.Module):\n    \"\"\"\n    Dynamic graph convolution layer\n    \"\"\"\n    def __init__(self, in_channels, hidden_channels, out_channels, n_blocks):\n        super().__init__()\n        self.n_blocks = n_blocks\n        self.head = SAGEConv(in_channels, hidden_channels)\n        c_growth  = hidden_channels\n        self.gnn = nn.Sequential(*[DenseDynBlock(hidden_channels+i*c_growth, c_growth)\n                                    for i in range(n_blocks-1)])\n        fusion_dims = int(hidden_channels * self.n_blocks + c_growth * ((1 + self.n_blocks - 1) * (self.n_blocks - 1) / 2))\n        self.linear = nn.Linear(fusion_dims, out_channels)\n\n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        data.x = self.head(x, edge_index)\n        feats = [data.x]\n        for i in range(self.n_blocks-1):\n            data = self.gnn[i](data)\n            feats.append(data.x)\n        feats = torch.cat(feats, 1)\n        x = pyg_nn.global_mean_pool(feats, data.batch)\n        out = F.relu(self.linear(x))\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:47:17.272360Z","iopub.execute_input":"2023-04-17T01:47:17.272756Z","iopub.status.idle":"2023-04-17T01:47:17.283266Z","shell.execute_reply.started":"2023-04-17T01:47:17.272720Z","shell.execute_reply":"2023-04-17T01:47:17.282154Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = MyGNN(8, 16, 2, 3)\nmodel","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:47:17.284832Z","iopub.execute_input":"2023-04-17T01:47:17.285265Z","iopub.status.idle":"2023-04-17T01:47:17.308305Z","shell.execute_reply.started":"2023-04-17T01:47:17.285227Z","shell.execute_reply":"2023-04-17T01:47:17.307431Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"MyGNN(\n  (head): SAGEConv(8, 16, aggr=mean)\n  (gnn): Sequential(\n    (0): DenseDynBlock(\n      (GraphBuilder): EuclideanGraphBuilder()\n      (gnn): SAGEConv(16, 16, aggr=mean)\n    )\n    (1): DenseDynBlock(\n      (GraphBuilder): EuclideanGraphBuilder()\n      (gnn): SAGEConv(32, 16, aggr=mean)\n    )\n  )\n  (linear): Linear(in_features=96, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# train_loader = DataLoader(dataset[0:500], batch_size=32, num_workers=1)\n# for d in train_loader:\n#     print(d)\n#     break\n# for sample_batched in train_loader:\n#     outputs = model(sample_batched)\n#     print(outputs.shape, sample_batched.x.shape, sample_batched.y.shape)\n#     break","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:47:17.309749Z","iopub.execute_input":"2023-04-17T01:47:17.310090Z","iopub.status.idle":"2023-04-17T01:47:17.316492Z","shell.execute_reply.started":"2023-04-17T01:47:17.310055Z","shell.execute_reply":"2023-04-17T01:47:17.315289Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nbatchsize = 32\ncriterion = nn.L1Loss()\nopt = torch.optim.AdamW(model.parameters(), lr=0.3)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('using ', device)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:47:17.318445Z","iopub.execute_input":"2023-04-17T01:47:17.318856Z","iopub.status.idle":"2023-04-17T01:47:23.590922Z","shell.execute_reply.started":"2023-04-17T01:47:17.318819Z","shell.execute_reply":"2023-04-17T01:47:23.589740Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"using  cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, b in enumerate(batch_ids):\n    event_ids = meta[meta[\"batch_id\"] == b][\"event_id\"].tolist()\n    y = meta[meta[\"batch_id\"] == b][['zenith', 'azimuth']].reset_index(drop=True)\n    dataset = IceCubeDataset(\n        b, event_ids, sensors, mode='train', y=y,\n    )\n    train_len = int(0.7*len(dataset[0:3000]))\n    train_loader = DataLoader(dataset[0:train_len], batch_size=batchsize)\n    val_loader = DataLoader(dataset[train_len:3000], batch_size=batchsize)\n    \n    print(f'batch {i}')\n    for epoch_num in range(epochs):\n        total_loss_train = 0\n        model.train()\n        for sample_batched in tqdm(train_loader, desc='train'):\n            opt.zero_grad()\n            sample_batched = sample_batched.to(device)\n            outputs = model(sample_batched)\n            label = sample_batched.y.reshape(-1, 2).to(device)\n            loss = criterion(outputs, label)\n            total_loss_train += loss.cpu().item()\n            loss.backward()\n            opt.step()\n#             break\n        \n        total_loss_val = 0\n        model.eval()\n        with torch.no_grad():\n            for sample_batched in tqdm(val_loader, desc='val'):\n                sample_batched = sample_batched.to(device)\n                outputs = model(sample_batched)\n                label = sample_batched.y.reshape(-1, 2).to(device)\n                loss = criterion(outputs, label)\n                total_loss_val += loss.cpu().item()\n#                 break\n\n        print(f'epoch[{epoch_num}]', total_loss_train / train_len, total_loss_train / (len(dataset[0:3000]) - train_len))\n\n    # just three batch dataset\n    if i >= 2:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:47:23.592496Z","iopub.execute_input":"2023-04-17T01:47:23.593231Z","iopub.status.idle":"2023-04-17T01:54:35.189595Z","shell.execute_reply.started":"2023-04-17T01:47:23.593186Z","shell.execute_reply":"2023-04-17T01:54:35.188395Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"batch 0\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:11<00:00,  5.64it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  7.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[0] 0.15883770136606126 0.37062130318747627\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  6.93it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[1] 0.07365136612029302 0.17185318761401705\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  6.97it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  6.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[2] 0.07365136612029302 0.17185318761401705\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.04it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[3] 0.07365136612029302 0.17185318761401705\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.01it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[4] 0.07365136612029302 0.17185318761401705\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  6.76it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[5] 0.07365136612029302 0.17185318761401705\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.01it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[6] 0.07365136612029302 0.17185318761401705\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  6.73it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[7] 0.07365136612029302 0.17185318761401705\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  6.98it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  7.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[8] 0.07365136612029302 0.17185318761401705\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.09it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  6.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[9] 0.07365136612029302 0.17185318761401705\nbatch 1\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:10<00:00,  6.24it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  7.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[0] 0.07298439525422595 0.17029692225986057\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.05it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  6.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[1] 0.07298439525422595 0.17029692225986057\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  6.96it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[2] 0.07298439525422595 0.17029692225986057\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.04it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[3] 0.07298439525422595 0.17029692225986057\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  6.69it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  7.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[4] 0.07298439525422595 0.17029692225986057\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.09it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  7.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[5] 0.07298439525422595 0.17029692225986057\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  6.75it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  7.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[6] 0.07298439525422595 0.17029692225986057\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.00it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[7] 0.07298439525422595 0.17029692225986057\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  6.80it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  6.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[8] 0.07298439525422595 0.17029692225986057\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.11it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  7.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[9] 0.07298439525422595 0.17029692225986057\nbatch 2\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:10<00:00,  6.03it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  7.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[0] 0.0736443441254752 0.17183680295944215\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.11it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  7.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[1] 0.0736443441254752 0.17183680295944215\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.05it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  6.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[2] 0.0736443441254752 0.17183680295944215\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.04it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[3] 0.0736443441254752 0.17183680295944215\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.01it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  7.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[4] 0.0736443441254752 0.17183680295944215\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  6.80it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[5] 0.0736443441254752 0.17183680295944215\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.05it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[6] 0.0736443441254752 0.17183680295944215\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  6.73it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[7] 0.0736443441254752 0.17183680295944215\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.01it/s]\nval: 100%|██████████| 29/29 [00:03<00:00,  7.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch[8] 0.0736443441254752 0.17183680295944215\n","output_type":"stream"},{"name":"stderr","text":"train: 100%|██████████| 66/66 [00:09<00:00,  7.06it/s]\nval: 100%|██████████| 29/29 [00:04<00:00,  6.48it/s]","output_type":"stream"},{"name":"stdout","text":"epoch[9] 0.0736443441254752 0.17183680295944215\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Infer","metadata":{}},{"cell_type":"code","source":"def infer(model, loader, device=\"cpu\"):\n    model.to(device)\n    model.eval()\n\n    predictions = []\n    with torch.no_grad():\n        for batch in loader:\n            batch = batch.to(device)\n            pred_angles = model(batch)\n            predictions.append(pred_angles.cpu())\n\n    return torch.cat(predictions, 0)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:54:35.191192Z","iopub.execute_input":"2023-04-17T01:54:35.192137Z","iopub.status.idle":"2023-04-17T01:54:35.199737Z","shell.execute_reply.started":"2023-04-17T01:54:35.192062Z","shell.execute_reply":"2023-04-17T01:54:35.198437Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def make_predictions(model, device=\"cpu\", mode=\"test\", batch_size=32):\n    sensors = prepare_sensors()\n\n    meta = pd.read_parquet(\n        INPUT_PATH / f\"{mode}_meta.parquet\", columns=[\"batch_id\", \"event_id\"]\n    ).astype(_dtype)\n    batch_ids = meta[\"batch_id\"].unique()\n\n    if mode == \"train\":\n        batch_ids = batch_ids[:6]\n\n    batch_preds = []\n    for b in batch_ids:\n        event_ids = meta[meta[\"batch_id\"] == b][\"event_id\"].tolist()\n        dataset = IceCubeDataset(\n            b, event_ids, sensors, mode=mode,\n        )\n        loader = DataLoader(dataset, batch_size=batch_size, num_workers=1)\n        batch_preds.append(infer(model, loader, device=device))\n        print(\"Finished batch\", b)\n\n        if mode == \"train\" and b == 6:\n            break\n\n    output = torch.cat(batch_preds, 0)\n\n    event_id_labels = []\n    for b in batch_ids:\n        event_id_labels.extend(meta[meta[\"batch_id\"] == b][\"event_id\"].tolist())\n\n    sub = {\n        \"event_id\": event_id_labels,\n        \"azimuth\": output[:, 0],\n        \"zenith\": output[:, 1],\n    }\n\n    sub = pd.DataFrame(sub)\n    sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:54:35.201692Z","iopub.execute_input":"2023-04-17T01:54:35.202072Z","iopub.status.idle":"2023-04-17T01:54:35.214781Z","shell.execute_reply.started":"2023-04-17T01:54:35.202034Z","shell.execute_reply":"2023-04-17T01:54:35.213599Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"make_predictions(model, device=\"cuda\", mode=\"test\", batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:54:35.216096Z","iopub.execute_input":"2023-04-17T01:54:35.216679Z","iopub.status.idle":"2023-04-17T01:54:35.474736Z","shell.execute_reply.started":"2023-04-17T01:54:35.216632Z","shell.execute_reply":"2023-04-17T01:54:35.473321Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Finished batch 661\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.read_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-04-17T01:54:35.477589Z","iopub.execute_input":"2023-04-17T01:54:35.478286Z","iopub.status.idle":"2023-04-17T01:54:35.495191Z","shell.execute_reply.started":"2023-04-17T01:54:35.478237Z","shell.execute_reply":"2023-04-17T01:54:35.494071Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"   event_id  azimuth  zenith\n0      2092      0.0     0.0\n1      7344      0.0     0.0\n2      9482      0.0     0.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event_id</th>\n      <th>azimuth</th>\n      <th>zenith</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2092</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7344</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9482</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}