{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install jax jaxlib flax optax mtranslate sentencepiece datasets transformers accelerate scikit-learn ipywidgets datasets nltk importlib-metadata\n!pip install transformers --upgrade","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-23T01:35:17.411734Z","iopub.execute_input":"2023-04-23T01:35:17.412332Z","iopub.status.idle":"2023-04-23T01:35:53.980335Z","shell.execute_reply.started":"2023-04-23T01:35:17.412299Z","shell.execute_reply":"2023-04-23T01:35:53.978982Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/huggingface/transformers.git\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T00:14:44.532708Z","iopub.execute_input":"2023-04-20T00:14:44.534013Z","iopub.status.idle":"2023-04-20T00:15:00.813921Z","shell.execute_reply.started":"2023-04-20T00:14:44.533947Z","shell.execute_reply":"2023-04-20T00:15:00.812679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/transformers/examples/flax/question-answering/","metadata":{"execution":{"iopub.status.busy":"2023-04-20T00:16:31.479150Z","iopub.execute_input":"2023-04-20T00:16:31.479762Z","iopub.status.idle":"2023-04-20T00:16:31.488498Z","shell.execute_reply.started":"2023-04-20T00:16:31.479719Z","shell.execute_reply":"2023-04-20T00:16:31.487043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, HTML\n# from huggingface_hub import notebook_login\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport json\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForQuestionAnswering, AdamW, Trainer, TrainingArguments, default_data_collator, FlaxAutoModelForQuestionAnswering\nimport time\nimport nltk\nimport math\nimport torch\nfrom datasets import Dataset, DatasetDict, load_dataset, load_metric\nimport tensorflow as tf\nimport re\nfrom torch.nn.utils.rnn import pad_sequence\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport transformers\n# from accelerate import Accelerator\nimport datasets\nimport sentencepiece\nfrom time import sleep\nfrom time import time\nfrom random import randint\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T01:35:59.253716Z","iopub.execute_input":"2023-04-23T01:35:59.254793Z","iopub.status.idle":"2023-04-23T01:36:41.004536Z","shell.execute_reply.started":"2023-04-23T01:35:59.254741Z","shell.execute_reply":"2023-04-23T01:36:41.003327Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Вход в huggingface\n# notebook_login()\n!huggingface-cli login --token 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","metadata":{"execution":{"iopub.status.busy":"2023-04-23T01:36:45.239229Z","iopub.execute_input":"2023-04-23T01:36:45.239982Z","iopub.status.idle":"2023-04-23T01:36:46.402471Z","shell.execute_reply.started":"2023-04-23T01:36:45.239932Z","shell.execute_reply":"2023-04-23T01:36:46.401089Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"def translate_sentence(text):\n    input_ids = t_tokenizer(text, return_tensors=\"jax\").input_ids\n    sequences = t_model.generate(input_ids, num_beams=2).sequences\n    outputs = t_tokenizer.batch_decode(sequences, skip_special_tokens=True)\n    return outputs\n\nfrom jax import vmap, jit\n\n@jit\ndef translate_sentence_batch(words):\n    return vmap(translate_sentence)(words)\n\ndef translate_sentences(sentences):\n    words = sentence.split(' ')\n    outputs = translate_sentence_batch(words)\n    return [' '.join(output) for output in outputs]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T00:53:28.991408Z","iopub.execute_input":"2023-04-21T00:53:28.991950Z","iopub.status.idle":"2023-04-21T00:53:29.002669Z","shell.execute_reply.started":"2023-04-21T00:53:28.991904Z","shell.execute_reply":"2023-04-21T00:53:29.001290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = \"УТВЕРЖДАЮ: Председатель закупочной комиссии, заместитель генерального директора - по логистике и МТО АО «АТХ» ____________________ Т.Ю. Шустова «01» сентября 2022 г. ДОКУМЕНТАЦИЯ О КОНКУРЕНТНОЙ ЗАКУПКЕ ЗАПРОС ПРЕДЛОЖЕНИЙ В ЭЛЕКТРОННОЙ ФОРМЕ, УЧАСТНИКАМИ КОТОРОГО МОГУТ БЫТЬ ТОЛЬКО СУБЪЕКТЫ МАЛОГО И СРЕДНЕГО ПРЕДПРИНИМАТЕЛЬСТВА на право заключения Договора на выполнение работ по ремонту зданий и сооружений г. Киров 2022 год. Стр.2 СОДЕРЖАНИЕ СОДЕРЖАНИЕ 2 I. ОБЩИЕ УСЛОВИЯ ПРОВЕДЕНИЯ закупки 3 1. ОБЩИЕ ПОЛОЖЕНИЯ 3 1.1. Правовой статус документов 3 1.2. Заказчик, предмет и условия проведения закупки. 3 1.3. Начальная (максимальная) цена договора 4 1.4. Требования к участникам закупки 4 1.5. Участие в закупке коллективных участников (группы лиц) 5 1.6. Привлечение соисполнителей (субподрядчиков) к исполнению договора 6 1.7. Расходы на участие в закупке и при заключении договора 7 1.8. Предоставление приоритетов товаров российского происхождения, работ, услуг, выполняемых, оказываемых российс 3.5.2, 5.6.4 Закупка по единичным расценкам Нет.\"\n\ntranslate_sentence(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-04-20T23:50:05.382087Z","iopub.execute_input":"2023-04-20T23:50:05.382757Z","iopub.status.idle":"2023-04-20T23:50:05.389117Z","shell.execute_reply.started":"2023-04-20T23:50:05.382724Z","shell.execute_reply":"2023-04-20T23:50:05.387884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n# загружаем данные для обучения\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/train.json', 'r', encoding='utf-8') as file:\n    train_data = json.load(file)\n\n# загружаем данные для предсказания\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/test.json', 'r', encoding='utf-8') as file:\n    test_data = json.load(file)\n\n# Разбиваем данные на обучающую и валидационную выборки\ntrain_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n\nfrom transformers import FlaxMarianModel, MarianTokenizer, AutoModelForSeq2SeqLM, FlaxMarianMTModel\n\nt_tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")\nt_model = FlaxMarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\", from_pt=True)\n\nt_model.params = t_model.to_fp16(t_model.params)\n\nimport re\n\ndef translate_sentence(sentence):\n    words = sentence.split(' ')\n    translated_words = []\n    batch_size = 1  # Number of words to translate in one batch\n    for i in range(0, len(words), batch_size):\n        batch = words[i:i+batch_size]\n        input_ids = t_tokenizer(batch, return_tensors=\"jax\", max_length=64, padding=True, truncation=True).input_ids\n        outputs = t_model.generate(input_ids).sequences\n        translated_batch = t_tokenizer.batch_decode(outputs, max_length=64, skip_special_tokens=True)\n        translated_words.extend(translated_batch)\n    translated_sentence = ' '.join(translated_words)\n    return translated_sentence\n    \ndef clean_text(text):\n    # Удаление указанных символов из текста\n    text = re.sub(r'[\\\"\\#\\$\\;\\:\\^\\&\\№\\*\\-\\=\\+\\-\\,\\.\\@\\!\\?\\/\\]\\[\\}\\{\\|\\~\\«\\»\\`]', '', text)\n    text = re.sub(r'_', ' ', text)  # Замена _ на пробел\n    text = re.sub(r'\\s+', ' ', text)  # Удаление лишних пробелов\n    return text.strip()\n\ndef create_qa_dataframe(data):\n    examples = []\n    for row in tqdm(data, total = len(data)):\n        cleaned_text = clean_text(row['text'])\n        question = row['label']\n        extracted_part = row.get('extracted_part', {})\n        if extracted_part and extracted_part['text'] is not None:\n            answer = clean_text(extracted_part['text'][0].strip())\n            answer_start = extracted_part['answer_start'][0]\n            answer_end = extracted_part['answer_end'][0]\n            if answer:\n                answer_words = answer.split()\n                match_found = False\n                for i in range(len(answer_words)):\n                    answer_start_new = cleaned_text.find(answer_words[i])\n                    if answer_start_new != -1:\n                        match_found = True\n                        for j in range(i+1, len(answer_words)):\n                            next_word_start = answer_start_new + len(answer_words[i-1])\n                            next_word_end = next_word_start + len(answer_words[j])\n                            next_word = cleaned_text[next_word_start:next_word_end]\n                            if answer_words[j] != next_word:\n                                match_found = False\n                                break\n                        if match_found:\n                            answer_start = answer_start_new\n                            answer_end = answer_start_new + len(answer_words) - 1\n                            break\n                if not match_found:\n                    answer_start = answer_end = 0\n            else:\n                answer_start = answer_end = 0\n        else:\n            answer_start = answer_end = 0\n            answer = None\n            \n#         translated_text = translate_sentence(cleaned_text)\n#         translated_question = translate_sentence(question)\n#         translated_answer = translate_sentence(answer) if answer else None\n\n        example = {'context': cleaned_text, 'question': question, 'answer': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n        examples.append(example)\n    df = pd.DataFrame(examples)\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-04-21T00:30:03.434227Z","iopub.execute_input":"2023-04-21T00:30:03.434638Z","iopub.status.idle":"2023-04-21T00:30:06.357018Z","shell.execute_reply.started":"2023-04-21T00:30:03.434608Z","shell.execute_reply":"2023-04-21T00:30:06.355554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = create_qa_dataframe(train_data)\ndisplay(HTML(train_df[6:12].to_html()))","metadata":{"execution":{"iopub.status.busy":"2023-04-21T00:30:12.222891Z","iopub.execute_input":"2023-04-21T00:30:12.224073Z","iopub.status.idle":"2023-04-21T00:30:12.659435Z","shell.execute_reply.started":"2023-04-21T00:30:12.224030Z","shell.execute_reply":"2023-04-21T00:30:12.658084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# определите столбцы, которые нужно перевести\ncols_to_translate = ['context', 'question', 'answer']\n\n# создайте функцию, которая будет переводить строки\ndef translate_df_row(row):\n    for col in cols_to_translate:\n        row[col] = translate_sentences([row[col]])[0]\n    return row\n\n# примените функцию к каждой строке датафрейма\ntranslated_df = train_df[cols_to_translate].apply(translate_df_row, axis=1)\n\n# объедините оригинальный датафрейм с переведенными столбцами\ntrain_df[cols_to_translate] = translated_df[cols_to_translate]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create dataset","metadata":{}},{"cell_type":"code","source":"import mtranslate\n\nclass QADataset:\n    def __init__(self, train_data, val_data, test_data=None):\n        self.train_examples = self.create_qa_example(train_data)\n        self.val_examples = self.create_qa_example(val_data)\n        self.test_examples = self.create_qa_example(test_data) if test_data else []\n        self.train_dataset = datasets.Dataset.from_pandas(pd.DataFrame(self.train_examples))\n        self.val_dataset = datasets.Dataset.from_pandas(pd.DataFrame(self.val_examples))\n        self.test_dataset = datasets.Dataset.from_pandas(pd.DataFrame(self.test_examples)) if test_data else None\n        self.dataset_dict = DatasetDict({\n            'train': self.train_dataset,\n            'validation': self.val_dataset,\n            'test': self.test_dataset\n        })\n\n    def clean_text(self, text):\n        # Удаление указанных символов из текста\n        text = re.sub(r'[\\\"\\#\\$\\;\\:\\^\\&\\№\\*\\-\\=\\+\\-\\,\\.\\@\\!\\?\\/\\]\\[\\}\\{\\|\\~\\«\\»\\`]', '', text)\n        text = re.sub(r'_', ' ', text)  # Замена _ на пробел\n        text = re.sub(r'\\s+', ' ', text)  # Удаление лишних пробелов\n        return text.strip()\n\n    def create_qa_example(self, data):\n        examples = []\n        for row in tqdm(data, total = len(data)):\n            cleaned_text = self.clean_text(row['text'])\n            question = row['label']\n            extracted_part = row.get('extracted_part', {})\n            if extracted_part and extracted_part['text'] is not None:\n                answer = self.clean_text(extracted_part['text'][0].strip())\n                answer_start = extracted_part['answer_start'][0]\n                answer_end = extracted_part['answer_end'][0]\n                if answer:\n                    answer_words = answer.split()\n                    match_found = False\n                    for i in range(len(answer_words)):\n                        answer_start_new = cleaned_text.find(answer_words[i])\n                        if answer_start_new != -1:\n                            match_found = True\n                            for j in range(i+1, len(answer_words)):\n                                next_word_start = answer_start_new + len(answer_words[i-1])\n                                next_word_end = next_word_start + len(answer_words[j])\n                                next_word = cleaned_text[next_word_start:next_word_end]\n                                if answer_words[j] != next_word:\n                                    match_found = False\n                                    break\n                            if match_found:\n                                answer_start = answer_start_new\n                                answer_end = answer_start_new + len(answer_words) - 1\n                                break\n                    if not match_found:\n                        answer_start = answer_end = 0\n                else:\n                    answer_start = answer_end = 0\n            else:\n                answer_start = answer_end = 0\n                answer = None\n\n    #         translated_text = translate_sentence(cleaned_text)\n    #         translated_question = translate_sentence(question)\n    #         translated_answer = translate_sentence(answer) if answer else None\n\n            example = {'context': cleaned_text, 'question': question, 'answer': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n            examples.append(example)\n            \n        return examples\n    \ndef prepare_train_features(examples):\n#     examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n    tokenized_examples = tokenizer(\n        examples[\"question\"],\n        examples[\"context\"],\n        truncation=\"only_second\",\n        max_length=max_length,\n        stride=150,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n        return_tensors=\"jax\",\n    )\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n    tokenized_examples[\"start_positions\"] = []\n    tokenized_examples[\"end_positions\"] = []\n\n    for i, offsets in enumerate(offset_mapping):\n        input_ids = tokenized_examples[\"input_ids\"][i]\n#         cls_index = input_ids.index(tokenizer.cls_token_id)\n        cls_index = jnp.where(input_ids == tokenizer.cls_token_id)[0][0]\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        sample_index = sample_mapping[i]\n        answer_start = examples[\"answer_start\"][sample_index]\n        answer_end = examples[\"answer_end\"][sample_index]\n        if answer_start == 0 or answer_start == None:\n            tokenized_examples[\"start_positions\"].append(cls_index)\n            tokenized_examples[\"end_positions\"].append(cls_index)\n        else:\n            tokenized_examples[\"start_positions\"].append(answer_start)\n            tokenized_examples[\"end_positions\"].append(answer_end)\n#             token_start_index = 0\n#             while sequence_ids[token_start_index] != (0):\n#                 token_start_index += 1\n#             token_end_index = len(input_ids) - 1\n#             while sequence_ids[token_end_index] != (0):\n#                 token_end_index -= 1\n                \n#             if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n#                 tokenized_examples[\"start_positions\"].append(cls_index)\n#                 tokenized_examples[\"end_positions\"].append(cls_index)\n#             else:\n#                 while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n#                     token_start_index += 1\n#                 tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n#                 while offsets[token_end_index][1] >= end_char:\n#                     token_end_index -= 1\n#                 tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n\n    return tokenized_examples\n\nclass QATrainer:\n    def __init__(self, model_name, train_dataset, val_dataset, batch_size=1, epochs=3):\n        self.model_name = model_name\n#         self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.config = AutoConfig.from_pretrained(model_name)\n        self.model = AutoModelForQuestionAnswering.from_pretrained(model_name, config=self.config)\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.train_dataset = train_dataset\n        self.val_dataset = val_dataset\n        self.batch_size = batch_size\n        self.epochs = epochs\n    \n    def training(self):\n        model_name = self.model_name.split(\"/\")[-1]\n        args = TrainingArguments(\n            model_name,\n            evaluation_strategy = \"epoch\",\n            learning_rate=2e-5,\n            per_device_train_batch_size=self.batch_size,\n            per_device_eval_batch_size=self.batch_size,\n            num_train_epochs=self.epochs,\n            report_to = 'none', \n            weight_decay=0.01,\n            push_to_hub=False,\n        )\n\n        trainer = Trainer(\n            model=self.model,\n            args=args,\n            train_dataset=self.train_dataset,\n            eval_dataset=self.val_dataset,\n            data_collator=default_data_collator,\n            tokenizer=self.tokenizer,\n        )\n        \n        trainer.train()\n        trainer.save_model(\"QA-trained\")\n        \n        return self.model","metadata":{"execution":{"iopub.status.busy":"2023-04-23T02:03:54.950947Z","iopub.execute_input":"2023-04-23T02:03:54.951653Z","iopub.status.idle":"2023-04-23T02:03:54.986671Z","shell.execute_reply.started":"2023-04-23T02:03:54.951613Z","shell.execute_reply":"2023-04-23T02:03:54.985577Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# Used git finetune script","metadata":{}},{"cell_type":"code","source":"# загружаем данные для обучения\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/train.json', 'r', encoding='utf-8') as file:\n    train_data = json.load(file)\n\n# загружаем данные для предсказания\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/test.json', 'r', encoding='utf-8') as file:\n    test_data = json.load(file)\n\n# Разбиваем данные на обучающую и валидационную выборки\ntrain_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n\n# Args\n# num_labels = 1\n# seed = 60\n# num_train_epochs = 10\n# learning_rate = 2e-5\nper_device_batch_size = 3\ntotal_batch_size = per_device_batch_size * jax.local_device_count()\nmodel_name = \"google/bigbird-roberta-base\"\nmax_length = 1600\n\n# model elements\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nconfig = AutoConfig.from_pretrained(model_name)\nmodel = FlaxAutoModelForQuestionAnswering.from_pretrained(model_name, config=config)\npad_on_right = tokenizer.padding_side == \"right\"\n\n# dataset\nqa_dataset = QADataset(train_data, val_data, test_data=test_data)\ntokenized_dataset = qa_dataset.dataset_dict.map(prepare_train_features, batched=True, \n                                                 remove_columns=qa_dataset.dataset_dict[\"train\"].column_names)\ntrain_dataset = tokenized_dataset[\"train\"]\neval_dataset = tokenized_dataset[\"validation\"]\ntest_dataset = tokenized_dataset[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2023-04-23T01:03:26.286757Z","iopub.execute_input":"2023-04-23T01:03:26.287678Z","iopub.status.idle":"2023-04-23T01:03:33.798040Z","shell.execute_reply.started":"2023-04-23T01:03:26.287639Z","shell.execute_reply":"2023-04-23T01:03:33.796892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TPU used try 1","metadata":{}},{"cell_type":"code","source":"import jax\nimport flax\nimport optax\nfrom itertools import chain\nfrom tqdm.notebook import tqdm\nfrom typing import Callable\n\nimport jax.numpy as jnp\n\nfrom flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\nfrom flax.training import train_state\nfrom flax import traverse_util\n# from torch.utils.data import DataLoader\n# import datasets","metadata":{"execution":{"iopub.status.busy":"2023-04-23T01:37:03.907558Z","iopub.execute_input":"2023-04-23T01:37:03.907982Z","iopub.status.idle":"2023-04-23T01:37:04.168563Z","shell.execute_reply.started":"2023-04-23T01:37:03.907947Z","shell.execute_reply":"2023-04-23T01:37:04.167543Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(flax.__version__)\njax.local_devices()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T01:37:07.878658Z","iopub.execute_input":"2023-04-23T01:37:07.879855Z","iopub.status.idle":"2023-04-23T01:37:11.752599Z","shell.execute_reply.started":"2023-04-23T01:37:07.879806Z","shell.execute_reply":"2023-04-23T01:37:11.751646Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"0.6.8\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"},"metadata":{}}]},{"cell_type":"code","source":"# загружаем данные для обучения\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/train.json', 'r', encoding='utf-8') as file:\n    train_data = json.load(file)\n\n# загружаем данные для предсказания\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/test.json', 'r', encoding='utf-8') as file:\n    test_data = json.load(file)\n\n# Разбиваем данные на обучающую и валидационную выборки\ntrain_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T02:02:13.392802Z","iopub.execute_input":"2023-04-23T02:02:13.393083Z","iopub.status.idle":"2023-04-23T02:02:13.459540Z","shell.execute_reply.started":"2023-04-23T02:02:13.393057Z","shell.execute_reply":"2023-04-23T02:02:13.458558Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"qa_dataset = QADataset(train_data, val_data, test_data=test_data)\ntokenized_dataset = qa_dataset.dataset_dict.map(prepare_train_features, batched=True, \n                                                 remove_columns=qa_dataset.dataset_dict[\"train\"].column_names)\ntrain_dataset = tokenized_dataset[\"train\"]\neval_dataset = tokenized_dataset[\"validation\"]\ntest_dataset = tokenized_dataset[\"test\"]","metadata":{"execution":{"iopub.status.busy":"2023-04-23T02:04:00.351641Z","iopub.execute_input":"2023-04-23T02:04:00.352462Z","iopub.status.idle":"2023-04-23T02:06:10.144836Z","shell.execute_reply.started":"2023-04-23T02:04:00.352423Z","shell.execute_reply":"2023-04-23T02:06:10.143589Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"100%|██████████| 1439/1439 [00:00<00:00, 3162.33it/s]\n100%|██████████| 360/360 [00:00<00:00, 3400.04it/s]\n100%|██████████| 318/318 [00:00<00:00, 4229.43it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1439 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e95b0e392d8641629b8e3791b347d9ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/360 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc5ea3d3fa454615ba3481c61ac2643f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/318 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b306906a14a14ad8ba188751b19f187d"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-04-23T02:06:45.640620Z","iopub.execute_input":"2023-04-23T02:06:45.641724Z","iopub.status.idle":"2023-04-23T02:06:45.647337Z","shell.execute_reply.started":"2023-04-23T02:06:45.641689Z","shell.execute_reply":"2023-04-23T02:06:45.646191Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n    num_rows: 1439\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset['start_positions'][6]","metadata":{"execution":{"iopub.status.busy":"2023-04-23T02:06:49.139443Z","iopub.execute_input":"2023-04-23T02:06:49.140646Z","iopub.status.idle":"2023-04-23T02:06:49.148792Z","shell.execute_reply.started":"2023-04-23T02:06:49.140607Z","shell.execute_reply":"2023-04-23T02:06:49.147591Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"1008"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(train_dataset['input_ids'][6])","metadata":{"execution":{"iopub.status.busy":"2023-04-23T02:06:52.027971Z","iopub.execute_input":"2023-04-23T02:06:52.029194Z","iopub.status.idle":"2023-04-23T02:06:53.039652Z","shell.execute_reply.started":"2023-04-23T02:06:52.029158Z","shell.execute_reply":"2023-04-23T02:06:53.038392Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"\"<s> обеспечение гарантийных обязательств</s></s> 4 II ИНФОРМАЦИОННАЯ КАРТА пп Наименование Содержание 1 Требования к участникам закупок в соответствии с ч 11 ст 31 Федерального закона 44ФЗ Установлено 11 Требования предъявляемые к участникам закупки в соответствии с частями 2 и 21 статьи 31 Федерального закона 44ФЗ Не установлены 12 Размер обеспечения заявки на участие 000 руб 121 Реквизиты счета для перечисления денежных средств в случае предусмотренном ч 13 ст 44 Федерального закона 44ФЗ УФК по Хабаровскому краю (Краевое государственное казенное учреждение ''Оператор систем электронного правительства Хабаровского края многофункциональный центр предоставления государственных и муниципальных услуг'' ЛС 05222206690) ИНН 2721187743 КПП 272201001 Банк получателя платежа ОТДЕЛЕНИЕ ХАБАРОВСК БАНКА РОССИИУФК по Хабаровскому краю г Хабаровск БИК 010813050 расчетный счет 03222643080000002200 122 Порядок внесения денежных средств в качестве обеспечения заявок условия независимой гарантии Не предусмотрен 13 Размер обеспечения исполнения контракта 500 % 131 Размер обеспечения гарантийных обязательств 000 % 132 Реквизиты счета на котором в соответствии с законодательством Российской Федерации учитываются операции со средствами поступающими заказчику УФК по Хабаровскому краю (Краевое государственное казенное учреждение ''Оператор систем электронного правительства Хабаровского края многофункциональный центр предоставления государственных и муниципальных услуг'' ЛС 05222206690) ИНН 2721187743 КПП 272201001 Банк получателя платежа ОТДЕЛЕНИЕ ХАБАРОВСК БАНКА РОССИИУФК по Хабаровскому краю г Хабаровск БИК 010813050 расчетный счет 03222643080000002200 133 Порядок предоставления обеспечения исполнения контракта гарантийных обязательств требования к такому обеспечению Порядок предоставления обеспечения исполнения контракта (договора) требования к обеспечению в соответствии с частью 3 частью 4 статьи 96 Федерального закона от 05042013 44ФЗ ''О контрактной системе в сфере закупок товаров работ услуг для обеспечения государственных и муниципальных нужд'' и разделами 7 и 8 ча Наименование место нахождения почтовый адрес адрес электронной почты номер контактного телефона ответственное должностное лицо заказчика Краевое государственное казенное учреждение ''Оператор систем электронного правительства Хабаровского края многофункциональный центр предоставления государственных и</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n# Args\nnum_labels = 1\nseed = 60\nnum_train_epochs = 10\nlearning_rate = 2e-5\nper_device_batch_size = 1\ntotal_batch_size = per_device_batch_size * jax.local_device_count()\nmodel_name = 'xlm-roberta-base'\n# \"distilbert-base-uncased\"\nmax_length = 1440\n\n# model elements\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nconfig = AutoConfig.from_pretrained(model_name)\nmodel = FlaxAutoModelForQuestionAnswering.from_pretrained(model_name, config=config)\npad_on_right = tokenizer.padding_side == \"right\"\n\n# dataset\nqa_dataset = QADataset(train_data, val_data, test_data=test_data)\ntokenized_dataset = qa_dataset.dataset_dict.map(prepare_train_features, batched=True, \n                                                 remove_columns=qa_dataset.dataset_dict[\"train\"].column_names)\ntrain_dataset = tokenized_dataset[\"train\"]\neval_dataset = tokenized_dataset[\"validation\"]\ntest_dataset = tokenized_dataset[\"test\"]\n\n#add args\nnum_train_steps = len(train_dataset) // total_batch_size * num_train_epochs\nlearning_rate_function = optax.cosine_onecycle_schedule(transition_steps=num_train_steps, peak_value=learning_rate, pct_start=0.1, )\n\nprint(\"The overall batch size (both for training and eval) is\", total_batch_size)\nprint(\"The number of train steps (all the epochs) is\", num_train_steps)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T02:07:10.949299Z","iopub.execute_input":"2023-04-23T02:07:10.949715Z","iopub.status.idle":"2023-04-23T02:09:17.893951Z","shell.execute_reply.started":"2023-04-23T02:07:10.949682Z","shell.execute_reply":"2023-04-23T02:09:17.892692Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at xlm-roberta-base were not used when initializing FlaxXLMRobertaForQuestionAnswering: {('lm_head', 'dense', 'kernel'), ('lm_head', 'layer_norm', 'scale'), ('lm_head', 'layer_norm', 'bias'), ('lm_head', 'dense', 'bias'), ('lm_head', 'bias')}\n- This IS expected if you are initializing FlaxXLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing FlaxXLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of FlaxXLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: {('qa_outputs', 'bias'), ('qa_outputs', 'kernel')}\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n100%|██████████| 1439/1439 [00:00<00:00, 3548.78it/s]\n100%|██████████| 360/360 [00:00<00:00, 3561.10it/s]\n100%|██████████| 318/318 [00:00<00:00, 4329.44it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1439 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f180664949ed487f9e6023cd2a9d7b4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/360 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b32545559067457380ca1811e18478d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/318 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33184a400e7745588db6060b95ca151f"}},"metadata":{}},{"name":"stdout","text":"The overall batch size (both for training and eval) is 8\nThe number of train steps (all the epochs) is 1790\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset['train']['start_positions'][6]","metadata":{"execution":{"iopub.status.busy":"2023-04-23T01:38:54.608430Z","iopub.execute_input":"2023-04-23T01:38:54.608832Z","iopub.status.idle":"2023-04-23T01:38:54.616794Z","shell.execute_reply.started":"2023-04-23T01:38:54.608801Z","shell.execute_reply":"2023-04-23T01:38:54.615755Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"1008"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(tokenized_dataset['train']['input_ids'][6])","metadata":{"execution":{"iopub.status.busy":"2023-04-23T02:09:57.611545Z","iopub.execute_input":"2023-04-23T02:09:57.611925Z","iopub.status.idle":"2023-04-23T02:09:58.721313Z","shell.execute_reply.started":"2023-04-23T02:09:57.611896Z","shell.execute_reply":"2023-04-23T02:09:58.720057Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"\"<s> обеспечение гарантийных обязательств</s></s> 4 II ИНФОРМАЦИОННАЯ КАРТА пп Наименование Содержание 1 Требования к участникам закупок в соответствии с ч 11 ст 31 Федерального закона 44ФЗ Установлено 11 Требования предъявляемые к участникам закупки в соответствии с частями 2 и 21 статьи 31 Федерального закона 44ФЗ Не установлены 12 Размер обеспечения заявки на участие 000 руб 121 Реквизиты счета для перечисления денежных средств в случае предусмотренном ч 13 ст 44 Федерального закона 44ФЗ УФК по Хабаровскому краю (Краевое государственное казенное учреждение ''Оператор систем электронного правительства Хабаровского края многофункциональный центр предоставления государственных и муниципальных услуг'' ЛС 05222206690) ИНН 2721187743 КПП 272201001 Банк получателя платежа ОТДЕЛЕНИЕ ХАБАРОВСК БАНКА РОССИИУФК по Хабаровскому краю г Хабаровск БИК 010813050 расчетный счет 03222643080000002200 122 Порядок внесения денежных средств в качестве обеспечения заявок условия независимой гарантии Не предусмотрен 13 Размер обеспечения исполнения контракта 500 % 131 Размер обеспечения гарантийных обязательств 000 % 132 Реквизиты счета на котором в соответствии с законодательством Российской Федерации учитываются операции со средствами поступающими заказчику УФК по Хабаровскому краю (Краевое государственное казенное учреждение ''Оператор систем электронного правительства Хабаровского края многофункциональный центр предоставления государственных и муниципальных услуг'' ЛС 05222206690) ИНН 2721187743 КПП 272201001 Банк получателя платежа ОТДЕЛЕНИЕ ХАБАРОВСК БАНКА РОССИИУФК по Хабаровскому краю г Хабаровск БИК 010813050 расчетный счет 03222643080000002200 133 Порядок предоставления обеспечения исполнения контракта гарантийных обязательств требования к такому обеспечению Порядок предоставления обеспечения исполнения контракта (договора) требования к обеспечению в соответствии с частью 3 частью 4 статьи 96 Федерального закона от 05042013 44ФЗ ''О контрактной системе в сфере закупок товаров работ услуг для обеспечения государственных и муниципальных нужд'' и разделами 7 и 8 ча Наименование место нахождения почтовый адрес адрес электронной почты номер контактного телефона ответственное должностное лицо заказчика Краевое государственное казенное учреждение ''Оператор систем электронного правительства Хабаровского края многофункциональный центр предоставления государственных и</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\nclass RMSE(datasets.Metric):\n    def _info(self):\n        return datasets.MetricInfo(\n            description=\"Calculates Root Mean Squared Error (RMSE) metric.\",\n            citation=\"TODO: _CITATION\",\n            inputs_description=\"_KWARGS_DESCRIPTION\",\n            features=datasets.Features({\n                'predictions': datasets.Value('float32'),\n                'references': datasets.Value('float32'),\n            }),\n            codebase_urls=[],\n            reference_urls=[],\n            format='numpy'\n        )\n\n    def _compute(self, predictions, references):\n        rmse = np.sqrt(np.sum(np.square(predictions - references)) / predictions.shape[0])\n        return {\"RMSE\": rmse}\n\nclass TrainState(train_state.TrainState):\n    logits_function: Callable = flax.struct.field(pytree_node=False)\n    loss_function: Callable = flax.struct.field(pytree_node=False)\n        \ndef decay_mask_fn(params):\n    flat_params = traverse_util.flatten_dict(params)\n    flat_mask = {path: (path[-1] != \"bias\" and path[-2:] != (\"LayerNorm\", \"scale\")) for path in flat_params}\n    return traverse_util.unflatten_dict(flat_mask)\n\ndef adamw(weight_decay):\n    return optax.adamw(learning_rate=learning_rate_function, b1=0.9, b2=0.999, eps=1e-6, weight_decay=weight_decay, mask=decay_mask_fn)\n\nadamw = adamw(1e-2)\n\n@jax.jit\ndef loss_function(logits, labels):\n    return jnp.mean((logits[..., 0] - labels) ** 2)\n\n@jax.jit    \ndef eval_function(logits):\n    return logits[..., 0]\n\nstate = TrainState.create(\n    apply_fn=model.__call__,\n    params=model.params,\n    tx=adamw,\n    logits_function=eval_function,\n    loss_function=loss_function,\n)\n\ndef train_step(state, batch, dropout_rng):\n    start_positions = batch.pop(\"start_positions\")\n    end_positions = batch.pop(\"end_positions\")\n    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n#     print(batch)\n\n    def loss_fn(params):\n        outputs = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True, return_dict=True)\n#         start_logits, end_logits = jnp.squeeze(outputs, axis=-1).tolist()\n#         start_logits = np.array(start_logits)\n#         end_logits = np.array(end_logits)\n#         start_logits = jnp.asarray(start_logits)\n#         start_logits = jax.device_get(start_logits)\n#         end_logits = outputs.end_logits\n        print(outputs.start_logits)\n#         print(end_logits)\n        start_loss = state.loss_function(start_logits, start_positions)\n        end_loss = state.loss_function(end_logits, end_positions)\n        loss = (start_loss + end_loss) / 2.0\n        return loss\n\n    grad_function = jax.value_and_grad(loss_fn)\n    loss, grad = grad_function(state.params)\n    grad = jax.lax.pmean(grad, \"batch\")\n    new_state = state.apply_gradients(grads=grad)\n    metrics = jax.lax.pmean({\"loss\": loss, \"learning_rate\": learning_rate_function(state.step)}, axis_name=\"batch\")\n    return new_state, metrics, new_dropout_rng\n\nparallel_train_step = jax.pmap(train_step, axis_name=\"batch\", donate_argnums=(0,))\n\ndef eval_step(state, batch):\n    start_logits, end_logits = state.apply_fn(**batch, params=state.params, train=False)[0:2]\n    return state.logits_function(start_logits), state.logits_function(end_logits)\n\nparallel_eval_step = jax.pmap(eval_step, axis_name=\"batch\")\n\ndef train_data_loader(rng, dataset, batch_size):\n    steps_per_epoch = len(dataset) // batch_size\n    perms = jax.random.permutation(rng, len(dataset))\n    perms = perms[: steps_per_epoch * batch_size]\n    perms = perms.reshape((steps_per_epoch, batch_size))\n\n    for perm in perms:\n        batch = dataset[perm]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        batch = shard(batch)\n\n        yield batch\n        \ndef eval_data_loader(dataset, batch_size):\n    for i in range(len(dataset) // batch_size):\n        batch = dataset[i * batch_size : (i + 1) * batch_size]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        batch = shard(batch)\n\n        yield batch\n        \nstate = flax.jax_utils.replicate(state)\n\nrng = jax.random.PRNGKey(seed)\ndropout_rngs = jax.random.split(rng, jax.local_device_count())\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T02:42:53.136568Z","iopub.execute_input":"2023-04-23T02:42:53.137533Z","iopub.status.idle":"2023-04-23T02:42:53.411040Z","shell.execute_reply.started":"2023-04-23T02:42:53.137497Z","shell.execute_reply":"2023-04-23T02:42:53.409907Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n\nmetric_start = RMSE()\nmetric_end = RMSE()\n\nfor i, epoch in enumerate(tqdm(range(1, num_train_epochs + 1), desc=f\"Epoch ...\", position=0, leave=True)):\n    rng, input_rng = jax.random.split(rng)\n\n    # train\n    for batch in train_data_loader(input_rng, train_dataset, total_batch_size):\n#         print(batch)\n        state, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_rngs)\n\n    # evaluate\n    for batch in eval_data_loader(eval_dataset, total_batch_size):\n        start_positions = batch[\"start_positions\"]\n        end_positions = batch[\"end_positions\"]\n#         print(start_positions)\n#         print(\"\\n\")\n#         print(end_positions)\n#         print(\"\\n\")\n        inputs = {k: v for k, v in batch.items() if k not in [\"start_positions\", \"end_positions\"]}\n        print(inputs)\n        start_logits, end_logits = parallel_eval_step(state, inputs)\n        predictions_start = start_logits\n        predictions_end = end_logits\n        print(start_logits)\n        print(\"\\n\")\n        print(end_logits)\n        print(\"\\n\")\n#         print(predictions_start)\n        references_start = start_positions\n        references_end = end_positions\n#         print(references_start)\n        metric_start.add_batch(predictions=chain(*predictions_start), references=chain(*references_start))\n        metric_end.add_batch(predictions=chain(*predictions_end), references=chain(*references_end))\n\n    start_rmse = round(metric_start.compute()['RMSE'], 3)\n    end_rmse = round(metric_end.compute()['RMSE'], 3)\n\n    loss = round(flax.jax_utils.unreplicate(train_metrics)['loss'].item(), 3)\n    metric_name = \"RMSE\"\n    print(f\"{i+1}/{num_train_epochs} | Train loss: {loss} | Eval {metric_name}: start={start_rmse}, end={end_rmse}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T02:42:57.676541Z","iopub.execute_input":"2023-04-23T02:42:57.677635Z","iopub.status.idle":"2023-04-23T02:43:00.124090Z","shell.execute_reply.started":"2023-04-23T02:42:57.677602Z","shell.execute_reply":"2023-04-23T02:43:00.122820Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stderr","text":"Epoch ...:   0%|          | 0/10 [00:00<?, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/site-packages/jax/_src/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m1793\u001b[0m in \u001b[92m_get_axis_size\u001b[0m                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1790 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_axis_size\u001b[0m(name: \u001b[96mstr\u001b[0m, shape: Tuple[core.AxisSize, ...], axis: \u001b[96mint\u001b[0m               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1791 \u001b[0m\u001b[2m│   │   │   │   │    \u001b[0m) -> core.AxisSize:                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1792 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1793 \u001b[2m│     \u001b[0m\u001b[94mreturn\u001b[0m shape[axis]                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1794 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m (\u001b[96mIndexError\u001b[0m, \u001b[96mTypeError\u001b[0m) \u001b[94mas\u001b[0m e:                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1795 \u001b[0m\u001b[2m│     \u001b[0mmin_rank = axis + \u001b[94m1\u001b[0m \u001b[94mif\u001b[0m axis >= \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m -axis                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1796 \u001b[0m\u001b[2m│     \u001b[0m\u001b[2m# TODO(mattjj): better error message here\u001b[0m                                           \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mIndexError: \u001b[0mtuple index out of range\n\n\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n\n\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m13\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# train\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m batch \u001b[95min\u001b[0m train_data_loader(input_rng, train_dataset, total_batch_size):             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m#         print(batch)\u001b[0m                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m13 \u001b[2m│   │   \u001b[0mstate, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_r    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# evaluate\u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m batch \u001b[95min\u001b[0m eval_data_loader(eval_dataset, total_batch_size):                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/site-packages/jax/_src/\u001b[0m\u001b[1;33mtraceback_util.py\u001b[0m:\u001b[94m166\u001b[0m in                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92mreraise_with_filtered_traceback\u001b[0m                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mreraise_with_filtered_traceback\u001b[0m(*args, **kwargs):                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   \u001b[0m__tracebackhide__ = \u001b[94mTrue\u001b[0m                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m166 \u001b[2m│     \u001b[0m\u001b[94mreturn\u001b[0m fun(*args, **kwargs)                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│     \u001b[0mmode = _filtering_mode()                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mif\u001b[0m _is_under_reraiser(e) \u001b[95mor\u001b[0m mode == \u001b[33m\"\u001b[0m\u001b[33moff\u001b[0m\u001b[33m\"\u001b[0m:                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/site-packages/jax/_src/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m2370\u001b[0m in \u001b[92mcache_miss\u001b[0m                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2367 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2368 \u001b[0m\u001b[2m  \u001b[0m\u001b[1;95m@api_boundary\u001b[0m                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2369 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcache_miss\u001b[0m(*args, **kwargs):                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2370 \u001b[2m│   \u001b[0mp = _prepare_pmap(fun, in_axes, out_axes, static_broadcasted_tuple,                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2371 \u001b[0m\u001b[2m│   │   │   │   │     \u001b[0mdonate_tuple, global_arg_shapes, devices, backend,                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2372 \u001b[0m\u001b[2m│   │   │   │   │     \u001b[0maxis_size, args, kwargs)                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2373 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m arg \u001b[95min\u001b[0m p.flat_args:                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/site-packages/jax/_src/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m2191\u001b[0m in \u001b[92m_prepare_pmap\u001b[0m                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2188 \u001b[0m\u001b[2m  \u001b[0mglobal_arg_shapes_flat = \u001b[96mtuple\u001b[0m(flatten_axes(                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2189 \u001b[0m\u001b[2m│     \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mpmap global_arg_shapes\u001b[0m\u001b[33m\"\u001b[0m, in_tree, (dyn_global_arg_shapes, \u001b[94mNone\u001b[0m),                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2190 \u001b[0m\u001b[2m│     \u001b[0mkws=\u001b[94mTrue\u001b[0m))                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2191 \u001b[2m  \u001b[0mlocal_axis_size = _mapped_axis_size(fun, in_tree, args, in_axes_flat, \u001b[33m\"\u001b[0m\u001b[33mpmap\u001b[0m\u001b[33m\"\u001b[0m)           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2192 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2193 \u001b[0m\u001b[2m  \u001b[0mflat_fun, out_tree = flatten_fun(f, in_tree)                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2194 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/site-packages/jax/_src/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m1802\u001b[0m in \u001b[92m_mapped_axis_size\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1799 \u001b[0m\u001b[2m│   │     \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mwhich implies that its rank should be at least \u001b[0m\u001b[33m{\u001b[0mmin_rank\u001b[33m}\u001b[0m\u001b[33m, \u001b[0m\u001b[33m\"\u001b[0m                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1800 \u001b[0m\u001b[2m│   │     \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbut is only \u001b[0m\u001b[33m{\u001b[0m\u001b[96mlen\u001b[0m(shape)\u001b[33m}\u001b[0m\u001b[33m (its shape is \u001b[0m\u001b[33m{\u001b[0mshape\u001b[33m}\u001b[0m\u001b[33m)\u001b[0m\u001b[33m\"\u001b[0m) \u001b[94mfrom\u001b[0m \u001b[4;96me\u001b[0m                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1801 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1802 \u001b[2m  \u001b[0msizes = core.dedup_referents(_get_axis_size(name, np.shape(x), d)                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1803 \u001b[0m\u001b[2m│   │   │   │   │   │   │      \u001b[0m\u001b[94mfor\u001b[0m x, d \u001b[95min\u001b[0m \u001b[96mzip\u001b[0m(vals, dims) \u001b[94mif\u001b[0m d \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m)              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1804 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(sizes) == \u001b[94m1\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1805 \u001b[0m\u001b[2m│   \u001b[0msz, = sizes                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/site-packages/jax/_src/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m1230\u001b[0m in \u001b[92mdedup_referents\u001b[0m                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1227 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m get_referent(x) \u001b[95mis\u001b[0m get_referent(y)                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1228 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1229 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdedup_referents\u001b[0m(itr: Iterable[Any]) -> List[Any]:                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1230 \u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mlist\u001b[0m({HashableWrapper(get_referent(x)):x \u001b[94mfor\u001b[0m x \u001b[95min\u001b[0m itr}.values())                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1231 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1232 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1233 \u001b[0m\u001b[2m# -------------------- abstract values --------------------\u001b[0m                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/site-packages/jax/_src/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m1230\u001b[0m in \u001b[92m<dictcomp>\u001b[0m                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1227 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m get_referent(x) \u001b[95mis\u001b[0m get_referent(y)                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1228 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1229 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdedup_referents\u001b[0m(itr: Iterable[Any]) -> List[Any]:                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1230 \u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mlist\u001b[0m({HashableWrapper(get_referent(x)):x \u001b[94mfor\u001b[0m x \u001b[95min\u001b[0m itr}.values())                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1231 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1232 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1233 \u001b[0m\u001b[2m# -------------------- abstract values --------------------\u001b[0m                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/site-packages/jax/_src/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m1802\u001b[0m in \u001b[92m<genexpr>\u001b[0m                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1799 \u001b[0m\u001b[2m│   │     \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mwhich implies that its rank should be at least \u001b[0m\u001b[33m{\u001b[0mmin_rank\u001b[33m}\u001b[0m\u001b[33m, \u001b[0m\u001b[33m\"\u001b[0m                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1800 \u001b[0m\u001b[2m│   │     \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbut is only \u001b[0m\u001b[33m{\u001b[0m\u001b[96mlen\u001b[0m(shape)\u001b[33m}\u001b[0m\u001b[33m (its shape is \u001b[0m\u001b[33m{\u001b[0mshape\u001b[33m}\u001b[0m\u001b[33m)\u001b[0m\u001b[33m\"\u001b[0m) \u001b[94mfrom\u001b[0m \u001b[4;96me\u001b[0m                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1801 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1802 \u001b[2m  \u001b[0msizes = core.dedup_referents(_get_axis_size(name, np.shape(x), d)                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1803 \u001b[0m\u001b[2m│   │   │   │   │   │   │      \u001b[0m\u001b[94mfor\u001b[0m x, d \u001b[95min\u001b[0m \u001b[96mzip\u001b[0m(vals, dims) \u001b[94mif\u001b[0m d \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m)              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1804 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(sizes) == \u001b[94m1\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1805 \u001b[0m\u001b[2m│   \u001b[0msz, = sizes                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/site-packages/jax/_src/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m1797\u001b[0m in \u001b[92m_get_axis_size\u001b[0m                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1794 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m (\u001b[96mIndexError\u001b[0m, \u001b[96mTypeError\u001b[0m) \u001b[94mas\u001b[0m e:                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1795 \u001b[0m\u001b[2m│     \u001b[0mmin_rank = axis + \u001b[94m1\u001b[0m \u001b[94mif\u001b[0m axis >= \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m -axis                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1796 \u001b[0m\u001b[2m│     \u001b[0m\u001b[2m# TODO(mattjj): better error message here\u001b[0m                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1797 \u001b[2m│     \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1798 \u001b[0m\u001b[2m│   │     \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mname\u001b[33m}\u001b[0m\u001b[33m was requested to map its argument along axis \u001b[0m\u001b[33m{\u001b[0maxis\u001b[33m}\u001b[0m\u001b[33m, \u001b[0m\u001b[33m\"\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1799 \u001b[0m\u001b[2m│   │     \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mwhich implies that its rank should be at least \u001b[0m\u001b[33m{\u001b[0mmin_rank\u001b[33m}\u001b[0m\u001b[33m, \u001b[0m\u001b[33m\"\u001b[0m                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1800 \u001b[0m\u001b[2m│   │     \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbut is only \u001b[0m\u001b[33m{\u001b[0m\u001b[96mlen\u001b[0m(shape)\u001b[33m}\u001b[0m\u001b[33m (its shape is \u001b[0m\u001b[33m{\u001b[0mshape\u001b[33m}\u001b[0m\u001b[33m)\u001b[0m\u001b[33m\"\u001b[0m) \u001b[94mfrom\u001b[0m \u001b[4;96me\u001b[0m                      \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mValueError: \u001b[0mpmap was requested to map its argument along axis \u001b[1;36m0\u001b[0m, which implies that its rank should be at least \u001b[1;36m1\u001b[0m, \nbut is only \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mits shape is \u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1793</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_axis_size</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1790   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_axis_size</span>(name: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>, shape: Tuple[core.AxisSize, ...], axis: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1791 │   │   │   │   │    </span>) -&gt; core.AxisSize:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1792 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1793 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> shape[axis]                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1794 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">IndexError</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1795 │     </span>min_rank = axis + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> axis &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> -axis                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1796 │     # TODO(mattjj): better error message here</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">IndexError: </span>tuple index out of range\n\n<span style=\"font-style: italic\">The above exception was the direct cause of the following exception:</span>\n\n<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">13</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 │   # train</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> batch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> train_data_loader(input_rng, train_dataset, total_batch_size):             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 #         print(batch)</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>13 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>state, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_r    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 │   # evaluate</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> batch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> eval_data_loader(eval_dataset, total_batch_size):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">traceback_util.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">166</span> in                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reraise_with_filtered_traceback</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reraise_with_filtered_traceback</span>(*args, **kwargs):                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 │   </span>__tracebackhide__ = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>166 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fun(*args, **kwargs)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 │     </span>mode = _filtering_mode()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 │     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _is_under_reraiser(e) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> mode == <span style=\"color: #808000; text-decoration-color: #808000\">\"off\"</span>:                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2370</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cache_miss</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2367   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2368   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@api_boundary</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2369   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cache_miss</span>(*args, **kwargs):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2370 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>p = _prepare_pmap(fun, in_axes, out_axes, static_broadcasted_tuple,                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2371 │   │   │   │   │     </span>donate_tuple, global_arg_shapes, devices, backend,                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2372 │   │   │   │   │     </span>axis_size, args, kwargs)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2373 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> arg <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> p.flat_args:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2191</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_prepare_pmap</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2188   </span>global_arg_shapes_flat = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(flatten_axes(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2189 │     </span><span style=\"color: #808000; text-decoration-color: #808000\">\"pmap global_arg_shapes\"</span>, in_tree, (dyn_global_arg_shapes, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>),                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2190 │     </span>kws=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>))                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2191 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>local_axis_size = _mapped_axis_size(fun, in_tree, args, in_axes_flat, <span style=\"color: #808000; text-decoration-color: #808000\">\"pmap\"</span>)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2192   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2193   </span>flat_fun, out_tree = flatten_fun(f, in_tree)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2194 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1802</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_mapped_axis_size</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1799 │   │     </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"which implies that its rank should be at least {</span>min_rank<span style=\"color: #808000; text-decoration-color: #808000\">}, \"</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1800 │   │     </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"but is only {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(shape)<span style=\"color: #808000; text-decoration-color: #808000\">} (its shape is {</span>shape<span style=\"color: #808000; text-decoration-color: #808000\">})\"</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">e</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1801   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1802 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>sizes = core.dedup_referents(_get_axis_size(name, np.shape(x), d)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1803 │   │   │   │   │   │   │      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> x, d <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">zip</span>(vals, dims) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> d <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1804   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(sizes) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1805 │   </span>sz, = sizes                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1230</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">dedup_referents</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1227   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> get_referent(x) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> get_referent(y)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1228 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1229 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">dedup_referents</span>(itr: Iterable[Any]) -&gt; List[Any]:                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1230 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>({HashableWrapper(get_referent(x)):x <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> x <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> itr}.values())                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1231 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1232 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1233 # -------------------- abstract values --------------------</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1230</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;dictcomp&gt;</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1227   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> get_referent(x) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> get_referent(y)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1228 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1229 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">dedup_referents</span>(itr: Iterable[Any]) -&gt; List[Any]:                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1230 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>({HashableWrapper(get_referent(x)):x <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> x <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> itr}.values())                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1231 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1232 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1233 # -------------------- abstract values --------------------</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1802</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;genexpr&gt;</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1799 │   │     </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"which implies that its rank should be at least {</span>min_rank<span style=\"color: #808000; text-decoration-color: #808000\">}, \"</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1800 │   │     </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"but is only {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(shape)<span style=\"color: #808000; text-decoration-color: #808000\">} (its shape is {</span>shape<span style=\"color: #808000; text-decoration-color: #808000\">})\"</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">e</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1801   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1802 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>sizes = core.dedup_referents(_get_axis_size(name, np.shape(x), d)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1803 │   │   │   │   │   │   │      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> x, d <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">zip</span>(vals, dims) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> d <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1804   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(sizes) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1805 │   </span>sz, = sizes                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/site-packages/jax/_src/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">api.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_axis_size</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1794 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">IndexError</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1795 │     </span>min_rank = axis + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> axis &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> -axis                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1796 │     # TODO(mattjj): better error message here</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1798 │   │     </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>name<span style=\"color: #808000; text-decoration-color: #808000\">} was requested to map its argument along axis {</span>axis<span style=\"color: #808000; text-decoration-color: #808000\">}, \"</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1799 │   │     </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"which implies that its rank should be at least {</span>min_rank<span style=\"color: #808000; text-decoration-color: #808000\">}, \"</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1800 │   │     </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"but is only {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(shape)<span style=\"color: #808000; text-decoration-color: #808000\">} (its shape is {</span>shape<span style=\"color: #808000; text-decoration-color: #808000\">})\"</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">e</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>pmap was requested to map its argument along axis <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, which implies that its rank should be at least <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, \nbut is only <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> <span style=\"font-weight: bold\">(</span>its shape is <span style=\"font-weight: bold\">())</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport jax\nfrom flax.serialization import to_bytes, from_bytes\n\n# Определяем путь к файлу, в который мы хотим сохранить модель.\nmodel_path = 'my_model.jax'\n\n# Получаем параметры модели, которые мы хотим сохранить.\nmodel_params = jax.tree_map(lambda x: x.block_until_ready(), state.params)\n\n# Преобразуем параметры в байтовую строку.\nmodel_bytes = to_bytes(model_params)\n\n# Сохраняем модель в файл.\nwith open(model_path, 'wb') as f:\n    f.write(model_bytes)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-19T05:47:04.890221Z","iopub.execute_input":"2023-04-19T05:47:04.891169Z","iopub.status.idle":"2023-04-19T05:47:22.194355Z","shell.execute_reply.started":"2023-04-19T05:47:04.891128Z","shell.execute_reply":"2023-04-19T05:47:22.192871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import jax\n# from flax.serialization import from_bytes\n\n# # Определяем путь к файлу, из которого мы хотим загрузить модель.\n# model_path = 'my_model.jax'\n\n# # Загружаем модель из файла.\n# with open(model_path, 'rb') as f:\n#     model_bytes = f.read()\n\n# # Преобразуем байтовую строку в параметры модели.\n# model_params = from_bytes(model_bytes)\n\n# # Создаем новый экземпляр модели, используя загруженные параметры.\n# model = FlaxAutoModelForQuestionAnswering(**model_params)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_data_loader(dataset, batch_size):\n    if len(dataset)<batch_size:\n        batch = dataset[:]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        yield batch\n    else:\n        for i in range(len(dataset) // batch_size):\n            batch = dataset[i * batch_size : (i + 1) * batch_size]\n            batch = {k: jnp.array(v) for k, v in batch.items()}\n\n            yield batch\n        batch = dataset[(i+1) * batch_size:]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        yield batch\n        \nfrom flax.jax_utils import unreplicate\n\nunrep_state = unreplicate(state)\n\n\ndef test_step(unrep_state, batch):\n    start_logits, end_logits = unrep_state.apply_fn(**batch, params=unrep_state.params, train=False)[0:2]\n    return state.logits_function(start_logits), state.logits_function(end_logits)\n\nparallel_test_step = jax.pmap(test_step, axis_name=\"batch\")\n\ndef generate_results():\n    preds = []\n    for batch in test_data_loader(test_dataset, total_batch_size):\n\n        if jax.process_index() == 0:\n            inputs = {k: v for k, v in batch.items()}\n            start_logits, end_logits = parallel_test_step(state, inputs)\n            preds.append((start_logits, end_logits))\n    return preds\n","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:23:47.226124Z","iopub.execute_input":"2023-04-19T06:23:47.227060Z","iopub.status.idle":"2023-04-19T06:23:48.475211Z","shell.execute_reply.started":"2023-04-19T06:23:47.227018Z","shell.execute_reply":"2023-04-19T06:23:48.473911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = generate_results()","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:23:50.086713Z","iopub.execute_input":"2023-04-19T06:23:50.087644Z","iopub.status.idle":"2023-04-19T06:23:53.131172Z","shell.execute_reply.started":"2023-04-19T06:23:50.087602Z","shell.execute_reply":"2023-04-19T06:23:53.129742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# os.environ[\"WANDB_MODE\"] = \"disabled\"\nfrom datasets import Dataset, DatasetDict\nimport datasets\nmodel_name = \"valhalla/longformer-base-4096-finetuned-squadv1\" \"AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru\"\nmax_length = 4000\ntokenizer = AutoTokenizer.from_pretrained(model_name)\npad_on_right = tokenizer.padding_side == \"right\"\nqa_dataset = QADataset(train_data, val_data)\ntokenized_dataset = qa_dataset.dataset_dict.map(prepare_train_features, batched=True, \n                                                 remove_columns=qa_dataset.dataset_dict[\"train\"].column_names)\n\nQAtrainer = QATrainer(\n    model_name=model_name,\n    train_dataset=tokenized_dataset['train'],\n    val_dataset=tokenized_dataset['validation']\n)\n\nQAtrainer.training()\n\n# use_tpu = True  # Change to True if using TPU\n\n# if use_tpu:\n#     # Create distribution strategy\n#     print('TPU used')\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n#     strategy = tf.distribute.TPUStrategy(tpu)\n\n#     with strategy.scope():\n#         # Create model\n#         print('TPU used')\n# #         model = create_model(model_name)\n#         # Create trainer\n#         QAtrainer = QATrainer(\n#             model_name=model_name,\n#             train_dataset=tokenized_dataset['train'],\n#             val_dataset=tokenized_dataset['validation']\n#         )\n# else:\n#     if tf.config.list_physical_devices('GPU'):\n# #         gpus = tf.config.experimental.list_physical_devices('GPU')\n# #         for gpu in gpus:\n# #             tf.config.experimental.set_virtual_device_configuration(\n# #                 gpu, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n# #         tf.config.optimizer.set_jit(True)\n# #         policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n# #         tf.keras.mixed_precision.experimental.set_policy(policy)\n#         strategy = tf.distribute.MirroredStrategy()\n#     else:\n#         strategy = tf.distribute.OneDeviceStrategy(device=\"/CPU:0\")\n\n#     with strategy.scope():\n# #         model = create_model(model_name)\n#         # Create trainer\n#         QAtrainer = QATrainer(\n#             model_name=model_name,\n#             train_dataset=tokenized_dataset['train'],\n#             val_dataset=tokenized_dataset['validation']\n#         )\n\n# # Train the model\n# QAtrainer.training()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-18T13:06:28.834300Z","iopub.execute_input":"2023-04-18T13:06:28.834993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(tokenized_dataset['train']['attention_mask'][6])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets['validation']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qa_dataset = QADataset(train_data, val_data)\nqa_dataset.dataset_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip list | grep transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# загружаем данные для обучения\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/train.json', 'r', encoding='utf-8') as file:\n    train_data = json.load(file)\n\n# загружаем данные для предсказания\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/test.json', 'r', encoding='utf-8') as file:\n    test_data = json.load(file)\n\n# Разбиваем данные на обучающую и валидационную выборки\ntrain_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataframe(data, fields, subfields):\n    main_df = pd.DataFrame(data)[fields]\n    sub_df_list = []\n    for subfield in subfields:\n        sub_df = pd.DataFrame(list(main_df[subfield]))\n        sub_df.columns = [f\"{subfield}_{col}\" for col in sub_df.columns]\n        sub_df_list.append(sub_df)\n    main_df = main_df.drop(columns=['extracted_part'])\n    return pd.concat([main_df] + sub_df_list, axis=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_qa_examples(train_data)[0]['context']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmax_seq_length = 4000\nmodel_name = \"valhalla/longformer-base-4096-finetuned-squadv1\"\n# LongformerTokenizer.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\")\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nconfig = LongformerConfig.from_pretrained('valhalla/longformer-base-4096-finetuned-squadv1')\nconfig.attention_mode = 'sliding_chunks'\n\nnum_epochs = 3\nbatch_size = 16\npad_on_right = tokenizer.padding_side == \"right\"\ntrain_dataset = QADataset(train_data, model_name, max_seq_length)\nval_dataset = QADataset(val_data, model_name, max_seq_length)\n# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\nassert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer('<s>', '<s>')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"QAtrainer = QATrainer(\n    model_name=model_name,\n    train_dataset=tokenized_dataset['train'],\n    val_dataset=tokenized_dataset['validation']\n)\n\nQAtrainer.training()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TPU used try 2","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import default_data_collator\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ndata_collator = default_data_collator\nargs = TrainingArguments(\n    model_name,\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    push_to_hub=True,\n)\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=tokenized_dataset['train'],\n    eval_dataset=tokenized_dataset['validation'],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)\ntrainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nfrom transformers import BertConfig, BertModel\n\n# bert_config = BertConfig(\n#     vocab_size=32000,\n#     hidden_size=768,\n#     num_hidden_layers=12,\n#     num_attention_heads=12,\n#     intermediate_size=3072,\n#     hidden_dropout_prob=0.1,\n#     attention_probs_dropout_prob=0.1,\n#     max_position_embeddings=512,\n#     type_vocab_size=2,\n#     initializer_range=0.02,\n#     layer_norm_eps=1e-12,\n#     gradient_checkpointing=False,\n#     position_embedding_type=\"absolute\",\n#     use_cache=True,\n#     is_decoder=False,\n#     pad_token_id=0,\n#     bos_token_id=1,\n#     eos_token_id=2\n# )\n\ntokenizer = AutoTokenizer.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\")\nmax_seq_length = 4000\nbatch_size = 16\nepochs = eps = 1\n     \ntrain_dataset = QADataset(train_data, tokenizer, max_seq_length)\nval_dataset = QADataset(val_data, tokenizer, max_seq_length)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n\n# qa_model = QAModel(bert_config)\n# qa_trainer = QATrainer(qa_model, train_dataloader, val_dataloader, lr=1e-12, eps=eps)\n# train_losses, val_losses = qa_trainer.train(epochs)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, val_loader):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for step, batch in enumerate(val_loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            segment_ids = batch['segment_ids'].to(device)\n            start_positions = batch['start_positions'].to(device)\n            end_positions = batch['end_positions'].to(device)\n            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=segment_ids, start_positions=start_positions, end_positions=end_positions)\n            loss = outputs.loss\n            total_loss += loss.item()\n        avg_loss = total_loss / len(val_loader)\n        return avg_loss\n\ndef predict(model, test_loader):\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for step, batch in enumerate(test_loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            segment_ids = batch['segment_ids'].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=segment_ids)\n            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n            start_preds = torch.softmax(start_logits, dim=1).cpu().detach().numpy()\n            end_preds = torch.softmax(end_logits, dim=1).cpu().detach().numpy()\n            for i in range(len(start_preds)):\n                start_pred = np.argmax(start_preds[i])\n                end_pred = np.argmax(end_preds[i])\n                if start_pred > end_pred:\n                    answer = \"\"\n                else:\n                    answer = tokenizer.decode(input_ids[i][start_pred:end_pred+1], skip_special_tokens=True)\n                predictions.append({\n                    \"context\": batch['context'][i],\n                    \"question\": batch['question'][i],\n                    \"extracted_part\": answer\n                })\n    with open('predictions.json', 'w', encoding='utf-8') as f:\n        json.dump(predictions, f, ensure_ascii=False, indent=4)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class QADataset(Dataset):\n    def __init__(self, data, tokenizer, max_seq_length):\n        self.examples = self.create_qa_examples(data)\n        self.tokenizer = tokenizer\n        self.max_seq_length = max_seq_length\n        self.skip = False\n\n    def __len__(self):\n        return len(self.examples)\n    \n    def __getitem__(self, idx):\n        example = self.examples[idx]\n        context = example['context']\n        question = example['question']\n        answer = example['answer']\n        answer_start = example['answer_start']\n        answer_end = example['answer_end']\n        assert answer_end <= len(example['context'])\n        is_char_in_ans = [0] * len(context)\n        for i in range(answer_start, answer_end):\n            is_char_in_ans[i] = 1\n        tokenized_context = self.tokenizer.encode_plus(context, add_special_tokens=False, return_offsets_mapping=True, return_tensors=\"tf\")\n        ans_token_idx = []\n        is_ans_token = [0] * len(tokenized_context)\n\n        for idx, token in enumerate(tokenized_context):\n            token_start = tokenized_context.token_to_chars(idx)[0]\n            token_end = tokenized_context.token_to_chars(idx)[1]\n            if sum(is_char_in_ans[token_start:token_end]) > 0:\n                ans_token_idx.append(idx)\n                for i in range(token_start, token_end):\n                    is_ans_token[i] = 1\n        if sum(is_ans_token) == 0:\n            start_token_idx, end_token_idx = 0, 0\n        else:\n            start_token_idx = ans_token_idx[0]\n            end_token_idx = ans_token_idx[-1]\n            while start_token_idx > 0 and is_ans_token[tokenized_context.token_to_chars(start_token_idx-1)[0]]:\n                start_token_idx -= 1\n            while end_token_idx < len(tokenized_context)-1 and is_ans_token[tokenized_context.token_to_chars(end_token_idx+1)[1]-1]:\n                end_token_idx += 1\n            \n\n        tokenized_question = self.tokenizer.encode_plus(question, return_offsets_mapping=True, return_tensors=\"tf\")\n        tokens = ['<s>'] + tokenized_context.tokens() + ['</s>']+ ['</s>'] + tokenized_question.tokens() + ['</s>']\n        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n        token_type_ids = [0] * (len(tokenized_context.tokens())+2) + [1] * (len(\n            tokenized_question.tokens())+2)\n        attention_mask = [1] * len(input_ids)\n        padding_length = self.max_seq_length - len(input_ids)\n        if padding_length > 0:  # pad\n            input_ids = input_ids + ([0] * padding_length)\n            attention_mask = attention_mask + ([0] * padding_length)\n            token_type_ids = token_type_ids + ([0] * padding_length)\n        elif padding_length < 0:  # skip\n            self.skip = True\n            return\n        features = []\n#         encoded_dict = self.tokenizer.encode_plus(\n#             question,\n#             context,\n#             add_special_tokens=True,\n#             truncation='longest_first',\n#             max_length=self.max_seq_length,\n#             return_tensors='pt'\n#         )\n#         input_ids = encoded_dict['input_ids'].squeeze()\n#         attention_mask = encoded_dict['attention_mask'].squeeze()\n#         input_ids = torch.nn.functional.pad(encoded_dict['input_ids'], (0, self.max_seq_length - encoded_dict['input_ids'].shape[1]), mode='constant', value=0)\n#         attention_mask = torch.nn.functional.pad(encoded_dict['attention_mask'], (0, self.max_seq_length - encoded_dict['attention_mask'].shape[1]), mode='constant', value=0)\n        \n        features = {'input_ids': input_ids, 'attention_mask': attention_mask, \n                    'token_type_ids': token_type_ids, 'start_token_idx': start_token_idx, 'end_token_idx': end_token_idx}\n#         max_len_dict = {}\n#         for key, value in features.items():\n#             if isinstance(value, (list, tuple)):\n#                 max_len_dict[key] = max(len(seq) for seq in value)\n#         for key, value in features.items():\n#             if isinstance(value, (list, tuple)):\n#                 max_len = max_len_dict[key]\n#                 for i in range(len(value)):\n#                     pad_len = max_len - len(value[i])\n#                     value[i] = torch.cat([value[i], torch.zeros(pad_len, dtype=torch.long)])\n#                 features[key] = torch.stack(value)\n\n        return features\n    \n    def create_qa_examples(self, data):\n        examples = []\n        for row in data:\n            text = row['text']\n            question = row['label']\n            extracted_part = row.get('extracted_part', {})\n            if extracted_part and 'text' in extracted_part:\n                answer = extracted_part['text'][0].strip()\n                answer_start = extracted_part['answer_start'][0]\n                answer_end = extracted_part['answer_end'][0]\n            else:\n                answer = answer_start = answer_end = None\n\n            example = {'context': text, 'question': question, 'answer': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n            examples.append(example)\n        return examples\n    \n    \n    @staticmethod\n    def prepare_test_data(data):\n        examples = []\n        for row in data:\n            text = row['text']\n            question = row['label']\n            example = {'context': text, 'question': question}\n            examples.append(example)\n        return examples\n\ndef collate_fn(batch, device):\n    input_ids = pad_sequence([torch.tensor(example['input_ids']) for example in batch], batch_first=True, padding_value=0).to(device)\n    attention_mask = pad_sequence([torch.tensor(example['attention_mask']) for example in batch], batch_first=True, padding_value=0).to(device)\n    token_type_ids = pad_sequence([torch.tensor(example['token_type_ids']) for example in batch], batch_first=True, padding_value=0).to(device)\n    start_positions = torch.tensor([example['answer_start'] for example in batch]).to(device)\n    end_positions = torch.tensor([example['answer_end'] for example in batch]).to(device)\n    return {\n        'input_ids': input_ids,\n        'attention_mask': attention_mask,\n        'token_type_ids': token_type_ids,\n        'start_positions': start_positions,\n        'end_positions': end_positions\n    }\n\n\ndef create_inputs_targets(dataset):\n    dataset_dict = {\n        \"input_ids\": [],\n        \"token_type_ids\": [],\n        \"attention_mask\": [],\n        \"start_token_idx\": [],\n        \"end_token_idx\": [],\n    }\n    for idx in range(len(dataset)):\n        example = dataset[idx]\n        for key in dataset_dict:\n            if isinstance(example[key], torch.Tensor):\n                value = example[key].numpy().tolist()\n            else:\n                value = example[key]\n            dataset_dict[key].append(value)\n\n\n    x = [\n        dataset_dict[\"input_ids\"],\n        dataset_dict[\"token_type_ids\"],\n        dataset_dict[\"attention_mask\"],\n    ]\n    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n    return x, y\n\ndef x_y_split(model_name, train_data, validation_data, batch_size):\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = TFAutoModelForQuestionAnswering.from_pretrained(model_name)\n#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    train_dataset = QADataset(train_data, tokenizer, max_seq_length)\n#     train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True,\n#                                    collate_fn=lambda batch: collate_fn(batch, device))\n    x_train, y_train = create_inputs_targets(train_dataset)\n    \n    validation_dataset = QADataset(validation_data, tokenizer, max_seq_length)\n#     validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, drop_last=True,\n#                                         collate_fn=lambda batch: collate_fn(batch, device))\n    x_val, y_val = create_inputs_targets(validation_dataset)\n\n    return x_train, y_train, x_val, y_val\n\n\n\ndef create_model(model_name):\n    ## BERT encoder\n    encoder = TFLongformerForQuestionAnswering.from_pretrained(model_name)\n\n    ## QA Model\n    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n    embedding = encoder(\n        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n    )[0]\n\n    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n    start_logits = layers.Flatten()(start_logits)\n\n    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n    end_logits = layers.Flatten()(end_logits)\n\n    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n\n    model = keras.Model(\n        inputs=[input_ids, token_type_ids, attention_mask],\n        outputs=[start_probs, end_probs],\n    )\n    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n    optimizer = keras.optimizers.Adam(lr=5e-5)\n    model.compile(optimizer=optimizer, loss=[loss, loss])\n    return model\n\nclass ExactMatch(keras.callbacks.Callback):\n    def __init__(self, x_eval, y_eval):\n        super().__init__()\n        self.x_eval = x_eval\n        self.y_eval = y_eval\n\n    def on_epoch_end(self, epoch, logs=None):\n        pred_start, pred_end = self.model.predict(self.x_eval)\n        count = 0\n        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n            offsets = squad_eg.context_token_to_char\n            start = np.argmax(start)\n            end = np.argmax(end)\n            if start >= len(offsets):\n                continue\n            pred_char_start = offsets[start][0]\n            if end < len(offsets):\n                pred_char_end = offsets[end][1]\n                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n            else:\n                pred_ans = squad_eg.context[pred_char_start:]\n\n            if pred_ans in squad_eg.all_answers:\n                count += 1\n        acc = count / len(self.y_eval[0])\n        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\")\nexamp = QADataset(train_data, tokenizer, max_seq_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"QADataset(train_data, tokenizer, max_seq_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# загружаем данные для обучения\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/train.json', 'r', encoding='utf-8') as file:\n    train_data = json.load(file)\n\n# загружаем данные для предсказания\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/test.json', 'r', encoding='utf-8') as file:\n    test_data = json.load(file)\n\n# Разбиваем данные на обучающую и валидационную выборки\ntrain_data, validation_data = train_test_split(train_data[:50], test_size=0.2, random_state=42)\nmax_seq_length = 4000\nmodel_name = \"valhalla/longformer-base-4096-finetuned-squadv1\"\nconfiguration = LongformerConfig()\nnum_epochs = 3\n\nx_train, y_train, x_val, y_val = x_y_split(model_name = model_name, train_data = train_data, validation_data = validation_data, batch_size = 16)\nmax_len = len(x_train[0][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_train[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train имеет структуру словаря, в котором есть 3 подсловаря - признака, в каждом из них набор примеров n-го количества, в каждом примере уже непосредственно находятся данные\nв y_train 2 словаря, которые содержат n примеров, в каждом из которых находится таргет. \nкакие модели обучения можно написать на таких данных, не пользуясь предобученными моделями и их ограничениями","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntf.debugging.set_log_device_placement(True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_tpu = False  # Change to True if using TPU\n\nif use_tpu:\n    # Create distribution strategy\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    strategy = tf.distribute.TPUStrategy(tpu)\n\n    # Create model\n    with strategy.scope():\n        print('TPU used')\n        model = create_model(model_name)\nelse:\n#     # Use GPU if TPU is not available\n#     if tf.config.list_physical_devices('GPU'):\n#         strategy = tf.distribute.MirroredStrategy()\n        \n#     else:\n    strategy = tf.distribute.OneDeviceStrategy(device=\"/CPU:0\")\n\n    with strategy.scope():\n        model = create_model(model_name)\n\nmodel.summary()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\nprint(tf.test.is_built_with_cuda())\nprint(tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nx_train_np = [np.array(x_train[0]), np.array(x_train[1]), np.array(x_train[2])]\ny_train_np = [np.array(y_train[0]), np.array(y_train[1])]\nx_val_np = [np.array(x_val[0]), np.array(x_val[1]), np.array(x_val[2])]\ny_val_np = [np.array(y_val[0]), np.array(y_val[1])]\nexact_match_callback = ExactMatch(x_val_np, y_val_np)\nmodel.fit(\n    x_train_np,\n    y_train_np,\n    validation_data=(x_val_np, y_val_np),\n    epochs=1,\n    verbose=2,\n    batch_size=64,\n#     callbacks=[exact_match_callback],\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = QADataset(train_data, tokenizer, max_seq_length)\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True,\n                               collate_fn=lambda batch: collate_fn(batch, device))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader.dataset[2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained('cointegrated/LaBSE-en-ru')\n# examples = QADataset.create_qa_examples(train_data, train_data)\n# questions = [example['context'] for example in examples]\n# question_tokens = [tokenizer.tokenize(question) for question in questions]\n# import matplotlib.pyplot as plt\n\n# question_lengths = [len(tokens) for tokens in question_tokens]\n# plt.hist(question_lengths, bins=50)\n# plt.xlabel('Length of question tokens')\n# plt.ylabel('Frequency')\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Разбиваем данные на обучающую и валидационную выборки\n# train_data, validation_data = train_test_split(train_data, test_size=0.2, random_state=42)\n# max_seq_length = 3072\n# model_name = \"allenai/longformer-large-4096-finetuned-triviaqa\"\n\n# # Число эпох обучения\n# num_epochs = 3\n# output_dir = 'my_model'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'cointegrated/LaBSE-en-ru'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import BigBirdTokenizer, BigBirdForQuestionAnswering\n\n# tokenizer = BigBirdTokenizer.from_pretrained('google/bigbird-roberta-base')\n# model = BigBirdForQuestionAnswering.from_pretrained('google/bigbird-roberta-base')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# import tensorflow as tf\n\n# train(model_name, train_data, validation_data, output_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}