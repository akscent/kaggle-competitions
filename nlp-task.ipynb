{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install jax jaxlib flax optax mtranslate sentencepiece datasets transformers accelerate scikit-learn ipywidgets datasets nltk importlib-metadata\n!pip install transformers --upgrade\n\nfrom IPython.display import display, HTML\n# from huggingface_hub import notebook_login\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport json\nfrom sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelForQuestionAnswering, AdamW, Trainer, TrainingArguments, default_data_collator, FlaxAutoModelForQuestionAnswering\nimport time\nimport nltk\nimport math\nimport torch\nfrom datasets import Dataset, DatasetDict, load_dataset, load_metric\nimport tensorflow as tf\nimport re\nfrom torch.nn.utils.rnn import pad_sequence\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport transformers\n# from accelerate import Accelerator\nimport datasets\nimport sentencepiece\nfrom time import sleep\nfrom time import time\nfrom random import randint\nfrom transformers import FlaxMarianMTModel, AutoTokenizer\nimport jax\nfrom jax import vmap\nimport jax.numpy as jnp\nimport jax.numpy as jnp\nimport jax.lax as lax\nimport jax\nimport flax\nimport optax\nfrom itertools import chain\nfrom typing import Callable\nimport jax.numpy as jnp\nfrom flax.training.common_utils import get_metrics, onehot, shard, shard_prng_key\nfrom flax.training import train_state\nfrom flax import traverse_util\n# from torch.utils.data import DataLoader\n# import datasets\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:13.817849Z","iopub.execute_input":"2023-04-24T19:16:13.818797Z","iopub.status.idle":"2023-04-24T19:16:25.387480Z","shell.execute_reply.started":"2023-04-24T19:16:13.818760Z","shell.execute_reply":"2023-04-24T19:16:25.386084Z"},"trusted":true},"execution_count":97,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Вход в huggingface\n# notebook_login()\n!huggingface-cli login --token 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","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:25.389828Z","iopub.execute_input":"2023-04-24T19:16:25.390151Z","iopub.status.idle":"2023-04-24T19:16:26.699787Z","shell.execute_reply.started":"2023-04-24T19:16:25.390121Z","shell.execute_reply":"2023-04-24T19:16:26.698448Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Обзор данных","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# загружаем данные для обучения\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/train.json', 'r', encoding='utf-8') as file:\n    train_data = json.load(file)\n\n# загружаем данные для предсказания\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/test.json', 'r', encoding='utf-8') as file:\n    test_data = json.load(file)\n\n# Разбиваем данные на обучающую и валидационную выборки\ntrain_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n\ndef clean_text(text):\n    # Удаление лишних символов из текста\n    text = re.sub(r'[\\\"\\#\\$\\;\\:\\^\\&\\№\\*\\-\\=\\+\\-\\,\\.\\@\\!\\?\\/\\]\\[\\}\\{\\|\\~\\«\\»\\`]', '', text)\n    text = re.sub(r'_', ' ', text)  # Замена _ на пробел\n    text = re.sub(r'\\s+', ' ', text)  # Удаление лишних пробелов\n    return text.strip()\n\ndef create_qa_dataframe(data):\n    examples = []\n    for row in tqdm(data, total = len(data)):\n        cleaned_text = clean_text(row['text'])\n        token_cleaned_text = tokenizer.encode(cleaned_text, add_special_tokens=False)\n        question = row['label']\n        token_question = tokenizer.encode(question, add_special_tokens=False)\n        extracted_part = row.get('extracted_part', {})\n        if extracted_part and extracted_part['text'] is not None:\n            answer = clean_text(extracted_part['text'][0].strip())\n            answer_start = extracted_part['answer_start'][0]\n            answer_end = extracted_part['answer_end'][0]\n            if answer:\n                token_answer = tokenizer.encode(answer, add_special_tokens=False)\n#                 answer_words = answer.split()\n                match_found = False\n                start_indices = [i for i in range(len(token_cleaned_text)) if token_cleaned_text[i:i+len(token_answer)] == token_answer]\n                for i in range(len(start_indices)):\n                    answer_start_new = start_indices[i]\n                    if answer_start_new != -1:\n                        match_found = True\n                        for j in range(1, len(token_answer)):\n                            next_word_index = answer_start_new + j\n                            if next_word_index >= len(token_cleaned_text) or token_answer[j] != token_cleaned_text[next_word_index]:\n                                match_found = False\n                                break\n                        if match_found:\n                            answer_start = answer_start_new + len(token_question) + 3\n                            answer_end = answer_start + len(token_answer) - 1\n                            break\n                if not match_found:\n                    answer_start = answer_end = 0\n            else:\n                answer_start = answer_end = 0\n        else:\n            answer_start = answer_end = 0\n            answer = None\n\n        example = {'context': cleaned_text, 'question': question, 'answer': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n        examples.append(example)\n    df = pd.DataFrame(examples)\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:26.701502Z","iopub.execute_input":"2023-04-24T19:16:26.701810Z","iopub.status.idle":"2023-04-24T19:16:26.812428Z","shell.execute_reply.started":"2023-04-24T19:16:26.701780Z","shell.execute_reply":"2023-04-24T19:16:26.811235Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nСтоит заметить, что были заменены данные о начале и завершении вопроса на порядковые номера слов(токенов) в текстах\n\"\"\"\nmodel_name = 'xlm-roberta-base'\ntokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False, \n                                            strip_accents=False, \n                                            use_fast=True, add_special_tokens=False)\n\ntrain_df = create_qa_dataframe(train_data)\ndisplay(HTML(train_df[:10].to_html()))","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:38:33.002157Z","iopub.execute_input":"2023-04-24T19:38:33.002981Z","iopub.status.idle":"2023-04-24T19:38:38.841334Z","shell.execute_reply.started":"2023-04-24T19:38:33.002940Z","shell.execute_reply":"2023-04-24T19:38:38.840078Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stderr","text":"100%|██████████| 1439/1439 [00:04<00:00, 317.57it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>УТВЕРЖДАЮ Председатель закупочной комиссии заместитель генерального директора по логистике и МТО АО АТХ ТЮ Шустова 01 сентября 2022 г ДОКУМЕНТАЦИЯ О КОНКУРЕНТНОЙ ЗАКУПКЕ ЗАПРОС ПРЕДЛОЖЕНИЙ В ЭЛЕКТРОННОЙ ФОРМЕ УЧАСТНИКАМИ КОТОРОГО МОГУТ БЫТЬ ТОЛЬКО СУБЪЕКТЫ МАЛОГО И СРЕДНЕГО ПРЕДПРИНИМАТЕЛЬСТВА на право заключения Договора на выполнение работ по ремонту зданий и сооружений г Киров 2022 год Стр2 СОДЕРЖАНИЕ СОДЕРЖАНИЕ 2 I ОБЩИЕ УСЛОВИЯ ПРОВЕДЕНИЯ закупки 3 1 ОБЩИЕ ПОЛОЖЕНИЯ 3 11 Правовой статус документов 3 12 Заказчик предмет и условия проведения закупки 3 13 Начальная (максимальная) цена договора 4 14 Требования к участникам закупки 4 15 Участие в закупке коллективных участников (группы лиц) 5 16 Привлечение соисполнителей (субподрядчиков) к исполнению договора 6 17 Расходы на участие в закупке и при заключении договора 7 18 Предоставление приоритетов товаров российского происхождения работ услуг выполняемых оказываемых российс 352 564 Закупка по единичным расценкам Нет</td>\n      <td>обеспечение гарантийных обязательств</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>УТВЕРЖДАЮ Начальник государственного бюджетного учреждения Волгоградской области Волгоградская городская станция по борьбе с болезнями животных ВН Рудников 2022 г МП ИЗВЕЩЕНИЕ О ПРОВЕДЕНИИ ЗАПРОСА КОТИРОВОК В ЭЛЕКТРОННОЙ УТВЕРЖДАЮ Начальник государственного бюджетного учреждения Волгоградской области Волгоградская городская станция по борьбе с болезнями животных ВН Рудников 2022 г МП ИЗВЕЩЕНИЕ О ПРОВЕДЕНИИ ЗАПРОСА КОТИРОВОК В ЭЛЕКТРОННОЙ ФОРМЕ УЧАСТНИКАМИ КОТОРОГО МОГУТ БЫТЬ ТОЛЬКО СУБЪЕКТЫ МАЛОГО И СРЕДНЕГО ПРЕДПРИНИМАТЕЛЬСТВА на поставку расходных материалов пп Наименование Сведения 1 Используемый способ закупки Запрос котировок в электронной форме (далее – запрос котировок) 2 Информация о Заказчике (контактная информация) Наименование Государственное бюджетное учреждение Волгоградской области Волгоградская городская станция по борьбе с болезнями животных (ГБУ ВО Волгоградская горСББЖ) Почтовый адрес 400107 Волгоградская обл г Волгоград ул Карла Либкнехта 6 Адрес электронной почты zakupkivetmailru Номер контактного телефона 7 9610675527 Ответственное должностное лицо Заказчика Шкитина Ольга Николаевна 3 Адрес электронной площадки в сети Интернет w 22</td>\n      <td>обеспечение гарантийных обязательств</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Извещение о проведении запроса котировок в электронной форме участниками которого могут быть только субъекты малого и среднего предпринимательства рз2022084394 на право заключить договор на Выполнение работ по капитальному ремонту части здания расположенного по адресу Удмуртская Республика Сарапульский район с Северный ул Октябрьская д29 с изменениями от 02092022 город Ижевск 2022 г Настоящее извещение о проведении запроса котировок в электронной форме разработано в соответствии с Федеральным законом от 18 июля 2011 г 223ФЗ О закупках товаров работ услуг отдельными видами юридических лиц (далее – Федеральный закон 223ФЗ) и Положением о закупке товаров работ услуг Заказчика БЮДЖЕТНОЕ УЧРЕЖДЕНИЕ УДМУРТСКОЙ РЕСПУБЛИКИ ''САРАПУЛЬСКАЯ МЕЖРАЙОННАЯ СТАНЦИЯ ПО БОРЬБЕ С БОЛЕЗНЯМИ ЖИВОТНЫХ'' (далее – Положение) СОДЕРЖАНИЕ Раздел 1 Общая часть Раздел 2 Информационная карта Раздел 3 Формы документов Раздел 4 Описание предмета закупки техническое задание Разд Обоснование начальной (максимальной) цены договора либо цены единицы товара работы услуги Определение начальной (максимальной) цены договора осуществляется в порядке установленном Положением на основании локального сметного расчета – Приложение 1 (являющемся</td>\n      <td>обеспечение гарантийных обязательств</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Приложение 1 к заявке – заказу ​​​​ от 2022г изненно необходимых и важнейших лекарственных препаратов в соответствии с постановлением Правительства Российской Федерации от 30112015г 1289 Об ограничениях и условиях допуска происходящих из иностранных государств лекарственных препаратов включенных в перечень жизненно необходимых и важнейших лекарственных препаратов для целей осуществления закупок для обеспечения государственных и муниципальных нужд Нет 1810 Установление запрета на допуск товаров легкой промышленности происходящих из иностранных государств и (или) услуг по прокату таких товаров в соответствии с постановлением Правительства Российской Федерации от 11082014г 791 Об установлении запрета на допуск товаров легкой промышленности происходящих из иностранных государств и (или) услуг по прокату таких товаров в целях осуществления закупок для обеспечения федеральных нужд нужд субъектов Российской Федерации и муниципальных нужд Нет 19 Размер обеспечения заявки на участие в электронном аукционе нет 20 Размер обеспечения исполнения контракта 5% от цены контракта 21 Обеспечение исполнения контракта путем внесения денежных средств на указанный заказчиком счет Реквизиты счета для предоставления обеспечения исполнения контракта Наименование учреждения Муниципальное общеобразовательное бюджетное учреждение средняя общеобразовательная школа сТемясово муниципального района Баймакский район Республики Башкортостан Юридический адрес 453663 Республика Башкортостан Баймакский район сТемясово улСоветская 20 ИНН 0254005845 КПП 025401001 Рс 40102810045370000067 Казначейский счет 03234643806060000100 Наименование банка Отделение НБ Республика Башкортостан БИК 018073401 лс 20103020420 Получатель Муниципальное общеобразовательное бюджетное учреждение средняя общеобразовательная школа сТемясово муниципального района Баймакский район Республики Башкортостан Факт внесения денежных средств в качестве обеспечения исполнения контракта подтверждается платежным поручением с отметкой банка об оплате Денежные средства возвращаются поставщику с По согласованию с заказчиком поставка дров может быть осуществлена в полном объеме в более ранние сроки Кубм 500</td>\n      <td>обеспечение исполнения контракта</td>\n      <td>Размер обеспечения исполнения контракта 5% от цены контракта</td>\n      <td>195</td>\n      <td>204</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>УТВЕРЖДАЮ Директор ГУП СК Ставрополькоммунэлектро ИВ Ягубов 2022 г ДОКУМЕНТАЦИЯ О ЗАКУПКЕ Конкурс в электронной форме на право заключения договора на выполнение работ по капитальному ремонту нежилых помещений в г Михайловске г Ставрополь 2022 год Стр32 СОДЕРЖАНИЕ СОДЕРЖАНИЕ 2 I ОБЩИЕ УСЛОВИЯ ПРОВЕДЕНИЯ закупки 4 1 ОБЩИЕ ПОЛОЖЕНИЯ 4 11 Правовой статус документов 4 12 Заказчик предмет и условия проведения закупки 4 13 Начальная (максимальная) цена договора 4 14 Требования к участникам закупки 5 15 Привлечение соисполнителей (субподрядчиков) к исполнению договора 6 16 Расходы на участие в закупке и при заключении договора 6 17 Предоставление приоритетов товаров российского происхождения работ услуг выполняемых оказываемых российскими лицами по отношению к товарам происходящим из иностранного государства работам услугам выполняемым оказываемым иностранными лицами при проведении закупки 6 2 ДОКУМЕНТАЦИЯ О ЗАКУПКЕ 7 21 ПРОЕКТНОСМЕТНАЯ ДОКУМЕНТАЦИЯ Смотрите архив приложенный к документации Часть VI ПРОЕКТНОСМЕТНАЯ ДОКУМЕНТАЦИЯ</td>\n      <td>обеспечение гарантийных обязательств</td>\n      <td></td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Извещение о проведении электронного аукциона для закупки 0151100013322000069 Общая информация Номер извещения 0151100013322000069 Наименование объекта закупки Поставка обложек для гражданских административных и уголовных дел для нужд районных (городских) судов г иц Ограничения 1 Запрет на допуск товаров работ услуг при осуществлении закупок а также ограничения и условия допуска в соответствии с требованиями установленными ст 14 Закона 44ФЗ Дополнительная информация к ограничению отсутствует Вид требования Нормативноправовой акт Обстоятельства допускающие исключение из установленных запретов или ограничений Обоснование невозможности соблюдения запрета ограничения допуска Примечание Условие допуска Участникам заявки или окончательные предложения которых содержат предложения о поставке товаров в соответствии с приказом Минфина России 126н от 04062018 Ограничение допуска Постановление Правительства РФ от 30042020 617 Об ограничениях допуска отдельных видов промышленных товаров происходящих из иностранных государств для целей осуществления закупок для обеспечения государственных и муниципальных нужд Обеспечение заявки Обеспечение заявок не требуется Обеспечение исполнения контракта Требуется обеспечение исполнения контракта Размер обеспечения исполнения контракта 1000% Порядок обеспечения исполнения контракта требования к обеспечению Обеспечение исполнения контракта предоставляется в виде независимой гарантии соответствующей требованиям ст ст 45 96 Федерального закона от 05042013 N 44ФЗ или внесением денежных средств на указанный заказчиком счет Способ обеспечения исполнения контракта определяется участником закупки самостоятельно Контракт заключается после предоставления участником закупки обеспечения исполнения контракта БИК 015004950 рсчет 03212643000000015100 Корсчет 40102810445370000043 лс 05511129080 Банк СИБИРСКОЕ ГУ БАНКА РОССИИУФК по Новосибирской области г Новосибирск Код 0002 (поле 22 Код платежного поручения обязательно к заполнению) Вид платежа обеспечение исполнения государственного контракта (указать наименование и закупки) Платежные реквизиты Номер расчётного счёта 00000000000000000000 Номер лицевого счёта См прилагаемые документы БИК 000000000 Наименование кредитной организации Номер корреспондентск Вид платежа обеспечение исполнения государственного контракта (указать наименование и закупки) Платежные реквизиты Номер расчётного счёта 00000000000000000000 Номер лицевого счёта См прилагаемые документы БИК 000000000 Наименование кредитной организации Номер корреспондентского</td>\n      <td>обеспечение исполнения контракта</td>\n      <td>Размер обеспечения исполнения контракта 1000%</td>\n      <td>250</td>\n      <td>256</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4 II ИНФОРМАЦИОННАЯ КАРТА пп Наименование Содержание 1 Требования к участникам закупок в соответствии с ч 11 ст 31 Федерального закона 44ФЗ Установлено 11 Требования предъявляемые к участникам закупки в соответствии с частями 2 и 21 статьи 31 Федерального закона 44ФЗ Не установлены 12 Размер обеспечения заявки на участие 000 руб 121 Реквизиты счета для перечисления денежных средств в случае предусмотренном ч 13 ст 44 Федерального закона 44ФЗ УФК по Хабаровскому краю (Краевое государственное казенное учреждение ''Оператор систем электронного правительства Хабаровского края многофункциональный центр предоставления государственных и муниципальных услуг'' ЛС 05222206690) ИНН 2721187743 КПП 272201001 Банк получателя платежа ОТДЕЛЕНИЕ ХАБАРОВСК БАНКА РОССИИУФК по Хабаровскому краю г Хабаровск БИК 010813050 расчетный счет 03222643080000002200 122 Порядок внесения денежных средств в качестве обеспечения заявок условия независимой гарантии Не предусмотрен 13 Размер обеспечения исполнения контракта 500 % 131 Размер обеспечения гарантийных обязательств 000 % 132 Реквизиты счета на котором в соответствии с законодательством Российской Федерации учитываются операции со средствами поступающими заказчику УФК по Хабаровскому краю (Краевое государственное казенное учреждение ''Оператор систем электронного правительства Хабаровского края многофункциональный центр предоставления государственных и муниципальных услуг'' ЛС 05222206690) ИНН 2721187743 КПП 272201001 Банк получателя платежа ОТДЕЛЕНИЕ ХАБАРОВСК БАНКА РОССИИУФК по Хабаровскому краю г Хабаровск БИК 010813050 расчетный счет 03222643080000002200 133 Порядок предоставления обеспечения исполнения контракта гарантийных обязательств требования к такому обеспечению Порядок предоставления обеспечения исполнения контракта (договора) требования к обеспечению в соответствии с частью 3 частью 4 статьи 96 Федерального закона от 05042013 44ФЗ ''О контрактной системе в сфере закупок товаров работ услуг для обеспечения государственных и муниципальных нужд'' и разделами 7 и 8 ча Наименование место нахождения почтовый адрес адрес электронной почты номер контактного телефона ответственное должностное лицо заказчика Краевое государственное казенное учреждение ''Оператор систем электронного правительства Хабаровского края многофункциональный центр предоставления государственных и</td>\n      <td>обеспечение гарантийных обязательств</td>\n      <td>Размер обеспечения гарантийных обязательств 000 %</td>\n      <td>239</td>\n      <td>246</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>КОНТРАКТ&lt;1&gt; &lt;2&gt; на поставку продуктов питания (бакалея 4) (Идентификационный код закупки 222710703104371070100101760001061244 ) &lt;4&gt; 20 &lt;5&gt; Государственное учреждение здравоохранения Городская больница 7 г Тулы&lt;6&gt; именуемое &lt;7&gt; в отребовать уплату штрафа Размер штрафа определяется в соответствии с Правилами и составляет 1000 (одна тысяча) рублей 00 копеек 714 Применение неустойки (штрафа пени) не освобождает Стороны от исполнения обязательств по настоящему Контракту 715 Общая сумма начисленных штрафов за неисполнение или ненадлежащее исполнение Поставщиком обязательств предусмотренных настоящим Контрактом не может превышать цену Контракта 716 Общая сумма начисленных штрафов за ненадлежащее исполнение Заказчиком обязательств предусмотренных настоящим Контрактом не может превышать цену Контракта 717 В случае расторжения настоящего Контракта в связи с односторонним отказом Стороны от исполнения настоящего Контракта другая Сторона вправе потребовать возмещения только фактически понесенного ущерба непосредственно обусловленного обстоятельствами являющимися основанием для принятия решения об одностороннем отказе от исполнения настоящего Контракта VIII ОБЕСПЕЧЕНИЕ ИСПОЛНЕНИЯ КОНТРАКТА &lt;109&gt; 81 Обеспечение исполнения настоящего Контракта установлено в размере 5% &lt;110&gt; 82 Обеспечение исполнения настоящего Контракта обеспечивает все обязательства Поставщика предусмотренные настоящим Контрактом включая исполнение основного обязательства по поставке Товара предоставление Поставщиком Заказчику предусмотренных настоящим Контрактом и приложениями к нему результатов включая отчетные документы соблюдение срока поставки возмещение убытков причиненных Заказчику Поставщиком в результате ненадлежащего исполнения неисполнения предусмотренного настоящим Контрактом и приложениями к нему обязательства последнего а также обязанность выплаты неустойки (пени штрафа) предусмотренной настоящим Контрактом 83 Исполнение настоящего Контракта может обеспечиваться предоставлением независимой гарантии выданной лицом соответствующим требованиям статьи 45 Закона 44ФЗ или внесением денежных средств на указанный в настоящем Контракте счет Заказчика Способ и срок действия обеспечения исполнения настоящего Контракта определяется Поставщиком сам &lt;144&gt; Указывается в случае наличия претензий</td>\n      <td>обеспечение исполнения контракта</td>\n      <td>Обеспечение исполнения настоящего Контракта установлено в размере 5%</td>\n      <td>301</td>\n      <td>312</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>УТВЕРЖДАЮ Главный врач ГУЗ Саратовская городская клиническая больница 1 им ЮЯ Гордеева Е П Ковалев 2022 года ДОКУМЕНТАЦИЯ ОБ АУКЦИОНЕ В ЭЛЕКТРОННОЙ ФОРМЕ ДЛЯ СУБЪЕКТОВ МАЛОГО усмотрено закупочной документацией и проектом договора 93 Односторонний отказ от исполнения обязательств по договору допускается по основаниям предусмотренным ГК РФ для одностороннего отказа от исполнения отдельного вида обязательств 10 Антидемпинговые меры 101 Если при проведении закупки участником закупки с которым заключается договор предложена цена договора которая на двадцать пять и более процентов ниже начальной (максимальной) цены договора договор заключается только после предоставления таким участником обеспечения исполнения договора в размере превышающем в полтора раза размер обеспечения исполнения договора указанный в закупочной документации но не менее чем в размере аванса (если договором предусмотрена выплата аванса) 102 Если при проведении закупки обеспечение исполнения договора не было установлено а участником с которым заключается договор предложена цена договора которая на двадцать пять и более процентов ниже начальной (максимальной) цены договора договор заключается только после предоставления таким участником обеспечения исполнения договора в размере 25% начальной (максимальной) цены договора но не менее чем в размере аванса (если договором предусмотрена выплата аванса) Заказчик в закупочной документации вправе установить требование об обеспечении исполнения договора заключаемого по результатам проведения процедуры закупки размер которого не может быть менее размера уплачиваемого аванса В случае когда выплата аванса не предусмотрена закупочной документацией и проектом договора не более тридцати процентов начальной (максимальной) цены договора а в случае если участниками могут быть только субъекты малого и среднего предпринимательства размер такого обеспечения не может превышать пять процентов начальной (максимальной) цены договора 103 Обеспечение установленное частью 91 или частью 92 предоставляется победителем закупки или участником с которым в соответствии с Положением заключается договор до заключения договора 104 В случае непредставления обеспечения предусмотренного частью 91 или частью 92 настоящей статьи победитель закупки или участник с кот Если в описании объекта закупки не используются установленные в соответствии с законодательством Российской Федерации о техническом регулировании законодательством Российской Федерации о стандартизации показатели требования условные обозначения и терминология то</td>\n      <td>обеспечение исполнения контракта</td>\n      <td>договор заключается только после предоставления таким участником обеспечения исполнения договора в размере 25% начальной (максимальной) цены договора</td>\n      <td>240</td>\n      <td>261</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>УТВЕРЖДАЮ Врио начальника ОМВД России по городу Мончегорску подполковник полиции ВВ Станченков сентября 2022 г ИЗВЕЩЕНИЕ О ПРОВЕДЕНИИ ЭЛЕКТРОННОГО АУКЦИОНА Сведения о лице проводящем закупку Наименование место нахождения условия о том что расходы возникающие в связи с перечислением денежных средств гарантом по независимой гарантии несет гарант обязательное наличие нумерации на всех листах независимой гарантии которые должны быть прошиты подписаны и скреплены печатью (при наличии) гаранта в случае ее оформления в письменной форме на бумажном носителе на нескольких листах Недопустимо включение в независимую гарантию требований о предоставлении заказчиком гаранту одновременно с требованием об осуществлении уплаты денежной суммы по независимой гарантии документов не включенных в перечень документов представляемых заказчиком банку одновременно с требованием об осуществлении уплаты денежной суммы по независимой гарантии утвержденный постановлением 1005 требований о представлении заказчиком гаранту судебных актов подтверждающих неисполнение принципалом обязательств обеспечиваемых независимой гарантией Сведения об обеспечении исполнения контракта Размер обеспечения исполнения контракта Размер обеспечения исполнения Контракта составляет 5% (пять) начальной (максимальной) цены Контракта что составляет 26 297 (двадцать шесть тысяч двести девяносто семь) рублей 00 копейки Порядок предоставления обеспечения исполнения контракта Обеспечение исполнения контракта предоставляется в виде независимой гарантии соответствующей требованиям ст ст 45 96 Федерального закона 44ФЗ или внесением денежных средств на указанный заказчиком счет Способ обеспечения исполнения контракта определяется участником закупки самостоятельно Контракт заключается после предоставления участником закупки обеспечения исполнения контракта Платежные реквизиты для обеспечения исполнения контракта Государственный Заказчик – ОМВД России по городу Мончегорску Место нахождения и юридический адрес 184500 г Мончегорск ул Комсомольская наб д58 ИНН 510 701 01 84 КПП 510 701 001 лсч 05491374020 в УФК по Мурманской области (ОМВД России по городу Мончегорску) Банк ОТДЕЛЕНИЕ МУРМАНСК БАНКА РОССИИУФК по Мурманской области г Мурманск БИК 014 705 901 Номер счета банка получателя средств 401028 В платежном поручении в разделе 22 Код 0002</td>\n      <td>обеспечение исполнения контракта</td>\n      <td>Размер обеспечения исполнения Контракта составляет 5% (пять) начальной (максимальной) цены Контракта</td>\n      <td>261</td>\n      <td>282</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"train_df['answer_end'].max() #искомые промежутки входят в классические 512 токенов","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.713995Z","iopub.status.idle":"2023-04-24T19:16:31.714352Z","shell.execute_reply.started":"2023-04-24T19:16:31.714167Z","shell.execute_reply":"2023-04-24T19:16:31.714195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create dataset","metadata":{}},{"cell_type":"code","source":"# import mtranslate\n\nclass QADataset:\n    def __init__(self, train_data, val_data, test_data=None, zero_flag=False):\n        self.zero_flag = zero_flag\n        self.train_examples = self.create_qa_example(train_data)\n        self.val_examples = self.create_qa_example(val_data)\n        self.zero_flag = False\n        self.test_examples = self.create_qa_example(test_data) if test_data else []\n        self.train_dataset = datasets.Dataset.from_pandas(pd.DataFrame(self.train_examples))\n        self.val_dataset = datasets.Dataset.from_pandas(pd.DataFrame(self.val_examples))\n        self.test_dataset = datasets.Dataset.from_pandas(pd.DataFrame(self.test_examples)) if test_data else None\n        if test_data:\n            self.dataset_dict = DatasetDict({\n                'train': self.train_dataset,\n                'validation': self.val_dataset,\n                'test': self.test_dataset\n            })\n        else:\n            self.dataset_dict = DatasetDict({\n                'train': self.train_dataset,\n                'validation': self.val_dataset\n            })\n\n    def clean_text(self, text):\n        # Удаление указанных символов из текста\n        text = re.sub(r'[\\\"\\#\\$\\;\\:\\^\\&\\№\\*\\-\\=\\+\\-\\,\\.\\@\\!\\?\\/\\]\\[\\}\\{\\|\\~\\«\\»\\`]', '', text)\n        text = re.sub(r'_', ' ', text)  # Замена _ на пробел\n        text = re.sub(r'\\s+', ' ', text)  # Удаление лишних пробелов\n        return text.strip()\n\n    def create_qa_example(self, data):\n        examples = []\n        for row in tqdm(data, total = len(data)):\n            cleaned_text = self.clean_text(row['text'])\n            token_cleaned_text = tokenizer.encode(cleaned_text, add_special_tokens=False)\n            question = row['label']\n            token_question = tokenizer.encode(question, add_special_tokens=False)\n            extracted_part = row.get('extracted_part', {})\n            if extracted_part and extracted_part['text'] is not None:\n                answer = self.clean_text(extracted_part['text'][0].strip())\n                answer_start = extracted_part['answer_start'][0]\n                answer_end = extracted_part['answer_end'][0]\n                if answer:\n                    token_answer = tokenizer.encode(answer, add_special_tokens=False)\n    #                 answer_words = answer.split()\n                    match_found = False\n                    start_indices = [i for i in range(len(token_cleaned_text)) if token_cleaned_text[i:i+len(token_answer)] == token_answer]\n                    for i in range(len(start_indices)):\n                        answer_start_new = start_indices[i]\n                        if answer_start_new != -1:\n                            match_found = True\n                            for j in range(1, len(token_answer)):\n                                next_word_index = answer_start_new + j\n                                if next_word_index >= len(token_cleaned_text) or token_answer[j] != token_cleaned_text[next_word_index]:\n                                    match_found = False\n                                    break\n                            if match_found:\n                                answer_start = answer_start_new + len(token_question) + 3\n                                answer_end = answer_start + len(token_answer) - 1\n                                break\n                    if not match_found:\n                        answer_start = answer_end = 0\n                else:\n                    answer_start = answer_end = 0\n            else:\n                answer_start = answer_end = 0\n                answer = None\n\n#             translated_text = translate_sentence(cleaned_text)\n    #         translated_question = translate_sentence(question)\n    #         translated_answer = translate_sentence(answer) if answer else None\n\n            # Append example only if answer is not None\n            if self.zero_flag:\n                if answer_start != 0 :\n                    example = {'context': cleaned_text, 'question': question, 'answer': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n                    examples.append(example)\n            else:\n                example = {'context': cleaned_text, 'question': question, 'answer': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n                examples.append(example)\n            \n        return examples\n    \ndef prepare_train_features(examples):\n#     examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n    tokenized_examples = tokenizer(\n        examples[\"question\"],\n        examples[\"context\"],\n        truncation=\"only_second\",\n        max_length=max_length,\n        stride=150,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n        return_tensors=\"jax\",\n    )\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n    tokenized_examples[\"start_positions\"] = []\n    tokenized_examples[\"end_positions\"] = []\n\n    for i, offsets in enumerate(offset_mapping):\n        input_ids = tokenized_examples[\"input_ids\"][i]\n#         cls_index = input_ids.index(tokenizer.cls_token_id)\n        cls_index = jnp.where(input_ids == tokenizer.cls_token_id)[0][0]\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        sample_index = sample_mapping[i]\n        answer_start = examples[\"answer_start\"][sample_index]\n        answer_end = examples[\"answer_end\"][sample_index]\n        if answer_start == 0 or answer_start == None:\n            tokenized_examples[\"start_positions\"].append(cls_index)\n            tokenized_examples[\"end_positions\"].append(cls_index)\n        else:\n            tokenized_examples[\"start_positions\"].append(answer_start)\n            tokenized_examples[\"end_positions\"].append(answer_end)\n\n    return tokenized_examples","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:46:38.951402Z","iopub.execute_input":"2023-04-24T19:46:38.952098Z","iopub.status.idle":"2023-04-24T19:46:38.984059Z","shell.execute_reply.started":"2023-04-24T19:46:38.952050Z","shell.execute_reply":"2023-04-24T19:46:38.982989Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"markdown","source":"# TPU used try 1","metadata":{}},{"cell_type":"code","source":"print(flax.__version__)\njax.local_devices()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.717952Z","iopub.status.idle":"2023-04-24T19:16:31.718364Z","shell.execute_reply.started":"2023-04-24T19:16:31.718155Z","shell.execute_reply":"2023-04-24T19:16:31.718173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\n# загружаем данные для обучения\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/train.json', 'r', encoding='utf-8') as file:\n    train_data = json.load(file)\n\n# загружаем данные для предсказания\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/test.json', 'r', encoding='utf-8') as file:\n    test_data = json.load(file)\n\n# Разбиваем данные на обучающую и валидационную выборки\ntrain_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n\n# Args\nnum_labels = 1\nseed = 60\nnum_train_epochs = 18\nlearning_rate = 2e-5\nper_device_batch_size = 16\ntotal_batch_size = per_device_batch_size * jax.local_device_count()\nmodel_name = 'xlm-roberta-base'\n# \"distilbert-base-uncased\"\nmax_length = 640\n\n# model elements\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nconfig = AutoConfig.from_pretrained(model_name)\nmodel = FlaxAutoModelForQuestionAnswering.from_pretrained(model_name, config=config)\npad_on_right = tokenizer.padding_side == \"right\"\n\n# dataset\nqa_dataset = QADataset(train_data, val_data, test_data=test_data, zero_flag=True)\n# test_data=test_data\ntokenized_dataset = qa_dataset.dataset_dict.map(prepare_train_features, batched=True, \n                                                 remove_columns=qa_dataset.dataset_dict[\"train\"].column_names)\ntrain_dataset = tokenized_dataset[\"train\"]\neval_dataset = tokenized_dataset[\"validation\"]\ntest_dataset = tokenized_dataset[\"test\"]\n\n#add args\nnum_train_steps = len(train_dataset) // total_batch_size * num_train_epochs\n\nprint(\"The overall batch size (both for training and eval) is\", total_batch_size)\nprint(\"The number of train steps (all the epochs) is\", num_train_steps)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:46:44.442515Z","iopub.execute_input":"2023-04-24T19:46:44.443402Z","iopub.status.idle":"2023-04-24T19:47:54.591018Z","shell.execute_reply.started":"2023-04-24T19:46:44.443358Z","shell.execute_reply":"2023-04-24T19:47:54.589751Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stderr","text":"100%|██████████| 1439/1439 [00:04<00:00, 337.40it/s]\n100%|██████████| 360/360 [00:01<00:00, 345.80it/s]\n100%|██████████| 318/318 [00:00<00:00, 399.11it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1182 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5acef5c143ff4ef0b58eec614398dbf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/296 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a78fd2b215c04b4398e408353d9c5073"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/318 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e71a27a8bf944a93b05b993a51df1fb2"}},"metadata":{}},{"name":"stdout","text":"The overall batch size (both for training and eval) is 128\nThe number of train steps (all the epochs) is 162\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:48:26.940733Z","iopub.execute_input":"2023-04-24T19:48:26.941865Z","iopub.status.idle":"2023-04-24T19:48:26.948100Z","shell.execute_reply.started":"2023-04-24T19:48:26.941827Z","shell.execute_reply":"2023-04-24T19:48:26.946990Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n        num_rows: 1185\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n        num_rows: 296\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n        num_rows: 319\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tokenized_dataset['train']['input_ids'][6])","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.724016Z","iopub.status.idle":"2023-04-24T19:16:31.724369Z","shell.execute_reply.started":"2023-04-24T19:16:31.724199Z","shell.execute_reply":"2023-04-24T19:16:31.724215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(tokenized_dataset['train']['input_ids'][6])","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.725693Z","iopub.status.idle":"2023-04-24T19:16:31.726035Z","shell.execute_reply.started":"2023-04-24T19:16:31.725859Z","shell.execute_reply":"2023-04-24T19:16:31.725874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = FlaxAutoModelForQuestionAnswering.from_pretrained(model_name, config=config)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:26:13.822314Z","iopub.execute_input":"2023-04-24T19:26:13.823168Z","iopub.status.idle":"2023-04-24T19:26:16.500404Z","shell.execute_reply.started":"2023-04-24T19:26:13.823128Z","shell.execute_reply":"2023-04-24T19:26:16.499006Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# from tqdm import tqdm\n\nclass RMSE(datasets.Metric):\n    def _info(self):\n        return datasets.MetricInfo(\n            description=\"Calculates Root Mean Squared Error (RMSE) metric.\",\n            citation=\"TODO: _CITATION\",\n            inputs_description=\"_KWARGS_DESCRIPTION\",\n            features=datasets.Features({\n                'predictions': datasets.Value('float32'),\n                'references': datasets.Value('float32'),\n            }),\n            codebase_urls=[],\n            reference_urls=[],\n            format='numpy'\n        )\n\n    def _compute(self, predictions, references):\n        rmse = np.sqrt(np.sum(np.square(predictions - references)) / predictions.shape[0])\n        return {\"RMSE\": rmse}\n\nclass TrainState(train_state.TrainState):\n    logits_function: Callable = flax.struct.field(pytree_node=False)\n    loss_function: Callable = flax.struct.field(pytree_node=False)\n\nlearning_rate_function = optax.cosine_onecycle_schedule(transition_steps=num_train_steps, \n                                                        peak_value=learning_rate, pct_start=0.1, \n                                                       )\ndef decay_mask_fn(params):\n    flat_params = traverse_util.flatten_dict(params)\n    flat_mask = {path: (path[-1] != \"bias\" and path[-2:] != (\"LayerNorm\", \"scale\")) for path in flat_params}\n    return traverse_util.unflatten_dict(flat_mask)\n\ndef adamw(weight_decay):\n    return optax.adamw(learning_rate=learning_rate_function, b1=0.9, b2=0.999, eps=1e-6, \n                       weight_decay=weight_decay, mask=decay_mask_fn)\n\n@jax.jit\ndef loss_function(start_logits, end_logits, start_positions, end_positions):\n    start_probs = jax.nn.softmax(start_logits, axis=-1)\n    end_probs = jax.nn.softmax(end_logits, axis=-1)\n    s_pred_positions = jnp.argmax(start_probs, axis=-1)\n    e_pred_positions = jnp.argmax(end_probs, axis=-1)\n    \n    s_loss = jnp.mean((s_pred_positions - start_positions) ** 2)\n    e_loss = jnp.mean((e_pred_positions - end_positions) ** 2)\n    \n    return s_loss, e_loss\n\n@jax.jit    \ndef eval_function(logits):\n    logits = jax.nn.softmax(logits, axis=-1)\n    l_index = jnp.argmax(logits, axis=-1)\n    \n    return l_index\n\nstate = TrainState.create(apply_fn=model.__call__, params=model.params, tx=adamw(1e-2),\n                          logits_function=eval_function, loss_function=loss_function,\n                         )\n\ndef train_step(state, batch, dropout_rng):\n    start_positions = batch.pop(\"start_positions\")\n    end_positions = batch.pop(\"end_positions\")\n    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng)\n\n    def loss_fn(params):\n        outputs = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True, return_dict=True)\n        start_logits = outputs.start_logits\n        end_logits = outputs.end_logits\n        start_loss, end_loss = state.loss_function(start_logits, end_logits, start_positions, end_positions)\n        loss = (start_loss + end_loss) / 2.0\n        return loss\n\n    grad_function = jax.value_and_grad(loss_fn)\n    loss, grad = grad_function(state.params)\n    grad = jax.lax.pmean(grad, \"batch\")\n#     loss = jax.lax.pmean(loss)\n    new_state = state.apply_gradients(grads=grad)\n    new_params = new_state.params\n    new_params = jax.tree_map(lambda p, g: p - learning_rate_function(state.step) * g, new_state.params, grad)\n    new_state = new_state.replace(params=new_params)\n#     learning_rate = jax.lax.pmean(learning_rate_function(state.step))\n    metrics = {\"loss\": loss, \"learning_rate\": learning_rate_function(state.step)}\n    return new_state, metrics, new_dropout_rng\n\nparallel_train_step = jax.pmap(train_step, axis_name=\"batch\", donate_argnums=(0,))\n\ndef eval_step(state, batch):\n    outputs = state.apply_fn(**batch, params=state.params, train=False)\n    start_logits = outputs.start_logits\n    end_logits = outputs.end_logits\n    \n    start_logits = state.logits_function(start_logits)\n    end_logits = state.logits_function(end_logits)\n    return start_logits, end_logits\n\nparallel_eval_step = jax.pmap(eval_step, axis_name=\"batch\")\n\ndef train_data_loader(rng, dataset, batch_size):\n    steps_per_epoch = len(dataset) // batch_size\n    perms = jax.random.permutation(rng, len(dataset))\n    perms = perms[: steps_per_epoch * batch_size]\n    perms = perms.reshape((steps_per_epoch, batch_size))\n    for perm in perms:\n        batch = dataset[perm]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        batch = shard(batch)\n        yield batch\n        \ndef eval_data_loader(dataset, batch_size):\n    for i in range(len(dataset) // batch_size):\n        batch = dataset[i * batch_size : (i + 1) * batch_size]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        batch = shard(batch)\n        yield batch\n        \nstate = flax.jax_utils.replicate(state)\nrng = jax.random.PRNGKey(seed)\ndropout_rngs = jax.random.split(rng, jax.local_device_count())","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:48:45.236650Z","iopub.execute_input":"2023-04-24T19:48:45.237079Z","iopub.status.idle":"2023-04-24T19:48:46.242694Z","shell.execute_reply.started":"2023-04-24T19:48:45.237026Z","shell.execute_reply":"2023-04-24T19:48:46.241326Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nmetric_start = RMSE()\nmetric_end = RMSE()\n    \nfor i, epoch in enumerate(tqdm(range(1, num_train_epochs + 1), desc=f\"Epoch ...\", position=0, leave=True)):\n    rng, input_rng = jax.random.split(rng)\n    \n    metric_start = RMSE()\n    metric_end = RMSE()\n    \n    for batch in train_data_loader(input_rng, train_dataset, total_batch_size):\n        state, train_metrics, dropout_rngs = parallel_train_step(state, batch, dropout_rngs)\n#         print(train_metrics)\n\n    # evaluate\n    for batch in eval_data_loader(eval_dataset, total_batch_size):\n        start_positions = batch[\"start_positions\"]\n        end_positions = batch[\"end_positions\"]\n        inputs = {k: v for k, v in batch.items() if k not in [\"start_positions\", \"end_positions\"]}\n        start_logits, end_logits = parallel_eval_step(state, inputs)\n        predictions_start = start_logits\n        predictions_end = end_logits\n        references_start = start_positions\n        references_end = end_positions\n        metric_start.add_batch(predictions=chain(*predictions_start), references=chain(*references_start))\n        metric_end.add_batch(predictions=chain(*predictions_end), references=chain(*references_end))\n\n    start_rmse = round(metric_start.compute()['RMSE'], 3)\n    end_rmse = round(metric_end.compute()['RMSE'], 3)\n\n    loss = round(flax.jax_utils.unreplicate(train_metrics)['loss'].item(), 3)\n    metric_name = \"RMSE\"\n    print(f\"{i+1}/{num_train_epochs} | Train loss: {loss} | Eval {metric_name}: start={start_rmse}, end={end_rmse}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:48:51.259920Z","iopub.execute_input":"2023-04-24T19:48:51.260407Z","iopub.status.idle":"2023-04-24T19:56:00.959697Z","shell.execute_reply.started":"2023-04-24T19:48:51.260366Z","shell.execute_reply":"2023-04-24T19:56:00.958360Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stderr","text":"Epoch ...:   6%|▌         | 1/18 [01:05<18:36, 65.69s/it]","output_type":"stream"},{"name":"stdout","text":"1/18 | Train loss: 53774.875 | Eval RMSE: start=236.19, end=224.389\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  11%|█         | 2/18 [01:27<10:36, 39.80s/it]","output_type":"stream"},{"name":"stdout","text":"2/18 | Train loss: 64912.812 | Eval RMSE: start=236.48, end=224.051\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  17%|█▋        | 3/18 [01:48<07:51, 31.42s/it]","output_type":"stream"},{"name":"stdout","text":"3/18 | Train loss: 65489.469 | Eval RMSE: start=236.763, end=224.468\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  22%|██▏       | 4/18 [02:10<06:25, 27.52s/it]","output_type":"stream"},{"name":"stdout","text":"4/18 | Train loss: 67459.0 | Eval RMSE: start=236.754, end=224.86\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  28%|██▊       | 5/18 [02:31<05:28, 25.31s/it]","output_type":"stream"},{"name":"stdout","text":"5/18 | Train loss: 73802.531 | Eval RMSE: start=236.516, end=224.408\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  33%|███▎      | 6/18 [02:53<04:47, 23.98s/it]","output_type":"stream"},{"name":"stdout","text":"6/18 | Train loss: 64315.625 | Eval RMSE: start=236.583, end=224.876\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  39%|███▉      | 7/18 [03:14<04:14, 23.10s/it]","output_type":"stream"},{"name":"stdout","text":"7/18 | Train loss: 65071.969 | Eval RMSE: start=236.772, end=224.86\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  44%|████▍     | 8/18 [03:35<03:44, 22.43s/it]","output_type":"stream"},{"name":"stdout","text":"8/18 | Train loss: 77193.938 | Eval RMSE: start=236.803, end=225.043\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  50%|█████     | 9/18 [03:56<03:18, 22.08s/it]","output_type":"stream"},{"name":"stdout","text":"9/18 | Train loss: 60209.062 | Eval RMSE: start=236.538, end=225.034\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  56%|█████▌    | 10/18 [04:18<02:55, 21.98s/it]","output_type":"stream"},{"name":"stdout","text":"10/18 | Train loss: 70291.344 | Eval RMSE: start=236.759, end=224.267\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  61%|██████    | 11/18 [04:39<02:32, 21.75s/it]","output_type":"stream"},{"name":"stdout","text":"11/18 | Train loss: 66692.219 | Eval RMSE: start=236.427, end=224.525\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  67%|██████▋   | 12/18 [05:00<02:09, 21.60s/it]","output_type":"stream"},{"name":"stdout","text":"12/18 | Train loss: 72404.875 | Eval RMSE: start=236.815, end=224.128\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  72%|███████▏  | 13/18 [05:22<01:47, 21.48s/it]","output_type":"stream"},{"name":"stdout","text":"13/18 | Train loss: 79320.906 | Eval RMSE: start=236.931, end=224.617\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  78%|███████▊  | 14/18 [05:43<01:25, 21.42s/it]","output_type":"stream"},{"name":"stdout","text":"14/18 | Train loss: 73976.531 | Eval RMSE: start=236.387, end=224.772\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  83%|████████▎ | 15/18 [06:05<01:04, 21.52s/it]","output_type":"stream"},{"name":"stdout","text":"15/18 | Train loss: 73235.75 | Eval RMSE: start=236.387, end=224.772\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  89%|████████▉ | 16/18 [06:26<00:42, 21.42s/it]","output_type":"stream"},{"name":"stdout","text":"16/18 | Train loss: 76419.25 | Eval RMSE: start=236.387, end=224.772\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...:  94%|█████████▍| 17/18 [06:47<00:21, 21.47s/it]","output_type":"stream"},{"name":"stdout","text":"17/18 | Train loss: 66150.438 | Eval RMSE: start=236.387, end=224.772\n","output_type":"stream"},{"name":"stderr","text":"Epoch ...: 100%|██████████| 18/18 [07:09<00:00, 23.87s/it]","output_type":"stream"},{"name":"stdout","text":"18/18 | Train loss: 78255.062 | Eval RMSE: start=236.387, end=224.772\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict_on_test_data(test_data, batch_size, state):\n    predictions = []\n    for batch in eval_data_loader(test_data, batch_size):\n        inputs = {k: v for k, v in batch.items() if k not in [\"start_positions\", \"end_positions\"]}\n        start_logits, end_logits = parallel_eval_step(state, inputs)\n        predictions_start = start_logits\n        predictions_end = end_logits\n        for start, end in zip(predictions_start, predictions_end):\n            test_data['start_positions'] = start.tolist()\n            test_data['end_positions'] = end.tolist()\n\n    return test_data","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:13:22.011425Z","iopub.execute_input":"2023-04-24T20:13:22.012481Z","iopub.status.idle":"2023-04-24T20:13:22.020168Z","shell.execute_reply.started":"2023-04-24T20:13:22.012431Z","shell.execute_reply":"2023-04-24T20:13:22.019164Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"preds = predict_on_test_data(test_dataset, total_batch_size, state)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:13:24.573253Z","iopub.execute_input":"2023-04-24T20:13:24.573708Z","iopub.status.idle":"2023-04-24T20:13:26.894713Z","shell.execute_reply.started":"2023-04-24T20:13:24.573671Z","shell.execute_reply":"2023-04-24T20:13:26.893322Z"},"trusted":true},"execution_count":153,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 preds = predict_on_test_data(test_dataset, total_batch_size, state)                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92mpredict_on_test_data\u001b[0m:\u001b[94m9\u001b[0m                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   │   \u001b[0mpredictions_start = start_logits                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   │   \u001b[0mpredictions_end = end_logits                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m start, end \u001b[95min\u001b[0m \u001b[96mzip\u001b[0m(predictions_start, predictions_end):                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 9 \u001b[2m│   │   │   \u001b[0mtest_data[\u001b[33m'\u001b[0m\u001b[33mstart_positions\u001b[0m\u001b[33m'\u001b[0m] = start.tolist()                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   │   │   \u001b[0mtest_data[\u001b[33m'\u001b[0m\u001b[33mend_positions\u001b[0m\u001b[33m'\u001b[0m] = end.tolist()                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m test_data                                                                        \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mTypeError: \u001b[0m\u001b[32m'Dataset'\u001b[0m object does not support item assignment\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 preds = predict_on_test_data(test_dataset, total_batch_size, state)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict_on_test_data</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 │   │   </span>predictions_start = start_logits                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 │   │   </span>predictions_end = end_logits                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> start, end <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">zip</span>(predictions_start, predictions_end):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 9 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>test_data[<span style=\"color: #808000; text-decoration-color: #808000\">'start_positions'</span>] = start.tolist()                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 │   │   │   </span>test_data[<span style=\"color: #808000; text-decoration-color: #808000\">'end_positions'</span>] = end.tolist()                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> test_data                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Dataset'</span> object does not support item assignment\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# preds['start_positions']","metadata":{"execution":{"iopub.status.busy":"2023-04-24T20:13:43.597758Z","iopub.execute_input":"2023-04-24T20:13:43.598760Z","iopub.status.idle":"2023-04-24T20:13:43.603150Z","shell.execute_reply.started":"2023-04-24T20:13:43.598718Z","shell.execute_reply":"2023-04-24T20:13:43.602131Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"### import os\nimport jax\nfrom flax.serialization import to_bytes, from_bytes\n\n# Определяем путь к файлу, в который мы хотим сохранить модель.\nmodel_path = 'my_model.jax'\n\n# Получаем параметры модели, которые мы хотим сохранить.\nmodel_params = jax.tree_map(lambda x: x.block_until_ready(), state.params)\n\n# Преобразуем параметры в байтовую строку.\nmodel_bytes = to_bytes(model_params)\n\n# Сохраняем модель в файл.\nwith open(model_path, 'wb') as f:\n    f.write(model_bytes)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.734876Z","iopub.status.idle":"2023-04-24T19:16:31.735226Z","shell.execute_reply.started":"2023-04-24T19:16:31.735046Z","shell.execute_reply":"2023-04-24T19:16:31.735062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import jax\n# from flax.serialization import from_bytes\n\n# # Определяем путь к файлу, из которого мы хотим загрузить модель.\n# model_path = 'my_model.jax'\n\n# # Загружаем модель из файла.\n# with open(model_path, 'rb') as f:\n#     model_bytes = f.read()\n\n# # Преобразуем байтовую строку в параметры модели.\n# model_params = from_bytes(model_bytes)\n\n# # Создаем новый экземпляр модели, используя загруженные параметры.\n# model = FlaxAutoModelForQuestionAnswering(**model_params)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.736048Z","iopub.status.idle":"2023-04-24T19:16:31.736400Z","shell.execute_reply.started":"2023-04-24T19:16:31.736235Z","shell.execute_reply":"2023-04-24T19:16:31.736251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_data_loader(dataset, batch_size):\n    if len(dataset)<batch_size:\n        batch = dataset[:]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        yield batch\n    else:\n        for i in range(len(dataset) // batch_size):\n            batch = dataset[i * batch_size : (i + 1) * batch_size]\n            batch = {k: jnp.array(v) for k, v in batch.items()}\n\n            yield batch\n        batch = dataset[(i+1) * batch_size:]\n        batch = {k: jnp.array(v) for k, v in batch.items()}\n        yield batch\n        \nfrom flax.jax_utils import unreplicate\n\nunrep_state = unreplicate(state)\n\n\ndef test_step(unrep_state, batch):\n    start_logits, end_logits = unrep_state.apply_fn(**batch, params=unrep_state.params, train=False)[0:2]\n    return state.logits_function(start_logits), state.logits_function(end_logits)\n\nparallel_test_step = jax.pmap(test_step, axis_name=\"batch\")\n\ndef generate_results():\n    preds = []\n    for batch in test_data_loader(test_dataset, total_batch_size):\n\n        if jax.process_index() == 0:\n            inputs = {k: v for k, v in batch.items()}\n            start_logits, end_logits = parallel_test_step(state, inputs)\n            preds.append((start_logits, end_logits))\n    return preds\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.737621Z","iopub.status.idle":"2023-04-24T19:16:31.738006Z","shell.execute_reply.started":"2023-04-24T19:16:31.737810Z","shell.execute_reply":"2023-04-24T19:16:31.737828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = generate_results()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.739706Z","iopub.status.idle":"2023-04-24T19:16:31.740049Z","shell.execute_reply.started":"2023-04-24T19:16:31.739871Z","shell.execute_reply":"2023-04-24T19:16:31.739887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# os.environ[\"WANDB_MODE\"] = \"disabled\"\nfrom datasets import Dataset, DatasetDict\nimport datasets\nmodel_name = \"valhalla/longformer-base-4096-finetuned-squadv1\" \"AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru\"\nmax_length = 4000\ntokenizer = AutoTokenizer.from_pretrained(model_name)\npad_on_right = tokenizer.padding_side == \"right\"\nqa_dataset = QADataset(train_data, val_data)\ntokenized_dataset = qa_dataset.dataset_dict.map(prepare_train_features, batched=True, \n                                                 remove_columns=qa_dataset.dataset_dict[\"train\"].column_names)\n\nQAtrainer = QATrainer(\n    model_name=model_name,\n    train_dataset=tokenized_dataset['train'],\n    val_dataset=tokenized_dataset['validation']\n)\n\nQAtrainer.training()\n\n# use_tpu = True  # Change to True if using TPU\n\n# if use_tpu:\n#     # Create distribution strategy\n#     print('TPU used')\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n#     strategy = tf.distribute.TPUStrategy(tpu)\n\n#     with strategy.scope():\n#         # Create model\n#         print('TPU used')\n# #         model = create_model(model_name)\n#         # Create trainer\n#         QAtrainer = QATrainer(\n#             model_name=model_name,\n#             train_dataset=tokenized_dataset['train'],\n#             val_dataset=tokenized_dataset['validation']\n#         )\n# else:\n#     if tf.config.list_physical_devices('GPU'):\n# #         gpus = tf.config.experimental.list_physical_devices('GPU')\n# #         for gpu in gpus:\n# #             tf.config.experimental.set_virtual_device_configuration(\n# #                 gpu, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n# #         tf.config.optimizer.set_jit(True)\n# #         policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n# #         tf.keras.mixed_precision.experimental.set_policy(policy)\n#         strategy = tf.distribute.MirroredStrategy()\n#     else:\n#         strategy = tf.distribute.OneDeviceStrategy(device=\"/CPU:0\")\n\n#     with strategy.scope():\n# #         model = create_model(model_name)\n#         # Create trainer\n#         QAtrainer = QATrainer(\n#             model_name=model_name,\n#             train_dataset=tokenized_dataset['train'],\n#             val_dataset=tokenized_dataset['validation']\n#         )\n\n# # Train the model\n# QAtrainer.training()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.741495Z","iopub.status.idle":"2023-04-24T19:16:31.741825Z","shell.execute_reply.started":"2023-04-24T19:16:31.741662Z","shell.execute_reply":"2023-04-24T19:16:31.741677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(tokenized_dataset['train']['attention_mask'][6])","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.743287Z","iopub.status.idle":"2023-04-24T19:16:31.743619Z","shell.execute_reply.started":"2023-04-24T19:16:31.743452Z","shell.execute_reply":"2023-04-24T19:16:31.743468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets['validation']","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.744766Z","iopub.status.idle":"2023-04-24T19:16:31.745141Z","shell.execute_reply.started":"2023-04-24T19:16:31.744928Z","shell.execute_reply":"2023-04-24T19:16:31.744943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qa_dataset = QADataset(train_data, val_data)\nqa_dataset.dataset_dict","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.746144Z","iopub.status.idle":"2023-04-24T19:16:31.746482Z","shell.execute_reply.started":"2023-04-24T19:16:31.746317Z","shell.execute_reply":"2023-04-24T19:16:31.746333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.747996Z","iopub.status.idle":"2023-04-24T19:16:31.748422Z","shell.execute_reply.started":"2023-04-24T19:16:31.748207Z","shell.execute_reply":"2023-04-24T19:16:31.748226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip list | grep transformers","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.749615Z","iopub.status.idle":"2023-04-24T19:16:31.749940Z","shell.execute_reply.started":"2023-04-24T19:16:31.749776Z","shell.execute_reply":"2023-04-24T19:16:31.749792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# загружаем данные для обучения\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/train.json', 'r', encoding='utf-8') as file:\n    train_data = json.load(file)\n\n# загружаем данные для предсказания\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/test.json', 'r', encoding='utf-8') as file:\n    test_data = json.load(file)\n\n# Разбиваем данные на обучающую и валидационную выборки\ntrain_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.751054Z","iopub.status.idle":"2023-04-24T19:16:31.751392Z","shell.execute_reply.started":"2023-04-24T19:16:31.751226Z","shell.execute_reply":"2023-04-24T19:16:31.751242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataframe(data, fields, subfields):\n    main_df = pd.DataFrame(data)[fields]\n    sub_df_list = []\n    for subfield in subfields:\n        sub_df = pd.DataFrame(list(main_df[subfield]))\n        sub_df.columns = [f\"{subfield}_{col}\" for col in sub_df.columns]\n        sub_df_list.append(sub_df)\n    main_df = main_df.drop(columns=['extracted_part'])\n    return pd.concat([main_df] + sub_df_list, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.752521Z","iopub.status.idle":"2023-04-24T19:16:31.752848Z","shell.execute_reply.started":"2023-04-24T19:16:31.752683Z","shell.execute_reply":"2023-04-24T19:16:31.752698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_qa_examples(train_data)[0]['context']","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.754364Z","iopub.status.idle":"2023-04-24T19:16:31.754697Z","shell.execute_reply.started":"2023-04-24T19:16:31.754530Z","shell.execute_reply":"2023-04-24T19:16:31.754546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmax_seq_length = 4000\nmodel_name = \"valhalla/longformer-base-4096-finetuned-squadv1\"\n# LongformerTokenizer.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\")\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nconfig = LongformerConfig.from_pretrained('valhalla/longformer-base-4096-finetuned-squadv1')\nconfig.attention_mode = 'sliding_chunks'\n\nnum_epochs = 3\nbatch_size = 16\npad_on_right = tokenizer.padding_side == \"right\"\ntrain_dataset = QADataset(train_data, model_name, max_seq_length)\nval_dataset = QADataset(val_data, model_name, max_seq_length)\n# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\nassert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.755771Z","iopub.status.idle":"2023-04-24T19:16:31.756106Z","shell.execute_reply.started":"2023-04-24T19:16:31.755932Z","shell.execute_reply":"2023-04-24T19:16:31.755947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.757219Z","iopub.status.idle":"2023-04-24T19:16:31.757608Z","shell.execute_reply.started":"2023-04-24T19:16:31.757408Z","shell.execute_reply":"2023-04-24T19:16:31.757426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer('<s>', '<s>')","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.759121Z","iopub.status.idle":"2023-04-24T19:16:31.759536Z","shell.execute_reply.started":"2023-04-24T19:16:31.759357Z","shell.execute_reply":"2023-04-24T19:16:31.759374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"QAtrainer = QATrainer(\n    model_name=model_name,\n    train_dataset=tokenized_dataset['train'],\n    val_dataset=tokenized_dataset['validation']\n)\n\nQAtrainer.training()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.760532Z","iopub.status.idle":"2023-04-24T19:16:31.760865Z","shell.execute_reply.started":"2023-04-24T19:16:31.760694Z","shell.execute_reply":"2023-04-24T19:16:31.760709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TPU used try 2","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.762393Z","iopub.status.idle":"2023-04-24T19:16:31.762736Z","shell.execute_reply.started":"2023-04-24T19:16:31.762570Z","shell.execute_reply":"2023-04-24T19:16:31.762585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import default_data_collator\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ndata_collator = default_data_collator\nargs = TrainingArguments(\n    model_name,\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    push_to_hub=True,\n)\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=tokenized_dataset['train'],\n    eval_dataset=tokenized_dataset['validation'],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.763843Z","iopub.status.idle":"2023-04-24T19:16:31.764197Z","shell.execute_reply.started":"2023-04-24T19:16:31.764011Z","shell.execute_reply":"2023-04-24T19:16:31.764027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nfrom transformers import BertConfig, BertModel\n\n# bert_config = BertConfig(\n#     vocab_size=32000,\n#     hidden_size=768,\n#     num_hidden_layers=12,\n#     num_attention_heads=12,\n#     intermediate_size=3072,\n#     hidden_dropout_prob=0.1,\n#     attention_probs_dropout_prob=0.1,\n#     max_position_embeddings=512,\n#     type_vocab_size=2,\n#     initializer_range=0.02,\n#     layer_norm_eps=1e-12,\n#     gradient_checkpointing=False,\n#     position_embedding_type=\"absolute\",\n#     use_cache=True,\n#     is_decoder=False,\n#     pad_token_id=0,\n#     bos_token_id=1,\n#     eos_token_id=2\n# )\n\ntokenizer = AutoTokenizer.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\")\nmax_seq_length = 4000\nbatch_size = 16\nepochs = eps = 1\n     \ntrain_dataset = QADataset(train_data, tokenizer, max_seq_length)\nval_dataset = QADataset(val_data, tokenizer, max_seq_length)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n\n# qa_model = QAModel(bert_config)\n# qa_trainer = QATrainer(qa_model, train_dataloader, val_dataloader, lr=1e-12, eps=eps)\n# train_losses, val_losses = qa_trainer.train(epochs)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.765636Z","iopub.status.idle":"2023-04-24T19:16:31.765981Z","shell.execute_reply.started":"2023-04-24T19:16:31.765800Z","shell.execute_reply":"2023-04-24T19:16:31.765816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, val_loader):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for step, batch in enumerate(val_loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            segment_ids = batch['segment_ids'].to(device)\n            start_positions = batch['start_positions'].to(device)\n            end_positions = batch['end_positions'].to(device)\n            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=segment_ids, start_positions=start_positions, end_positions=end_positions)\n            loss = outputs.loss\n            total_loss += loss.item()\n        avg_loss = total_loss / len(val_loader)\n        return avg_loss\n\ndef predict(model, test_loader):\n    model.eval()\n    predictions = []\n    with torch.no_grad():\n        for step, batch in enumerate(test_loader):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            segment_ids = batch['segment_ids'].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=segment_ids)\n            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n            start_preds = torch.softmax(start_logits, dim=1).cpu().detach().numpy()\n            end_preds = torch.softmax(end_logits, dim=1).cpu().detach().numpy()\n            for i in range(len(start_preds)):\n                start_pred = np.argmax(start_preds[i])\n                end_pred = np.argmax(end_preds[i])\n                if start_pred > end_pred:\n                    answer = \"\"\n                else:\n                    answer = tokenizer.decode(input_ids[i][start_pred:end_pred+1], skip_special_tokens=True)\n                predictions.append({\n                    \"context\": batch['context'][i],\n                    \"question\": batch['question'][i],\n                    \"extracted_part\": answer\n                })\n    with open('predictions.json', 'w', encoding='utf-8') as f:\n        json.dump(predictions, f, ensure_ascii=False, indent=4)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.767101Z","iopub.status.idle":"2023-04-24T19:16:31.767509Z","shell.execute_reply.started":"2023-04-24T19:16:31.767316Z","shell.execute_reply":"2023-04-24T19:16:31.767334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class QADataset(Dataset):\n    def __init__(self, data, tokenizer, max_seq_length):\n        self.examples = self.create_qa_examples(data)\n        self.tokenizer = tokenizer\n        self.max_seq_length = max_seq_length\n        self.skip = False\n\n    def __len__(self):\n        return len(self.examples)\n    \n    def __getitem__(self, idx):\n        example = self.examples[idx]\n        context = example['context']\n        question = example['question']\n        answer = example['answer']\n        answer_start = example['answer_start']\n        answer_end = example['answer_end']\n        assert answer_end <= len(example['context'])\n        is_char_in_ans = [0] * len(context)\n        for i in range(answer_start, answer_end):\n            is_char_in_ans[i] = 1\n        tokenized_context = self.tokenizer.encode_plus(context, add_special_tokens=False, return_offsets_mapping=True, return_tensors=\"tf\")\n        ans_token_idx = []\n        is_ans_token = [0] * len(tokenized_context)\n\n        for idx, token in enumerate(tokenized_context):\n            token_start = tokenized_context.token_to_chars(idx)[0]\n            token_end = tokenized_context.token_to_chars(idx)[1]\n            if sum(is_char_in_ans[token_start:token_end]) > 0:\n                ans_token_idx.append(idx)\n                for i in range(token_start, token_end):\n                    is_ans_token[i] = 1\n        if sum(is_ans_token) == 0:\n            start_token_idx, end_token_idx = 0, 0\n        else:\n            start_token_idx = ans_token_idx[0]\n            end_token_idx = ans_token_idx[-1]\n            while start_token_idx > 0 and is_ans_token[tokenized_context.token_to_chars(start_token_idx-1)[0]]:\n                start_token_idx -= 1\n            while end_token_idx < len(tokenized_context)-1 and is_ans_token[tokenized_context.token_to_chars(end_token_idx+1)[1]-1]:\n                end_token_idx += 1\n            \n\n        tokenized_question = self.tokenizer.encode_plus(question, return_offsets_mapping=True, return_tensors=\"tf\")\n        tokens = ['<s>'] + tokenized_context.tokens() + ['</s>']+ ['</s>'] + tokenized_question.tokens() + ['</s>']\n        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n        token_type_ids = [0] * (len(tokenized_context.tokens())+2) + [1] * (len(\n            tokenized_question.tokens())+2)\n        attention_mask = [1] * len(input_ids)\n        padding_length = self.max_seq_length - len(input_ids)\n        if padding_length > 0:  # pad\n            input_ids = input_ids + ([0] * padding_length)\n            attention_mask = attention_mask + ([0] * padding_length)\n            token_type_ids = token_type_ids + ([0] * padding_length)\n        elif padding_length < 0:  # skip\n            self.skip = True\n            return\n        features = []\n#         encoded_dict = self.tokenizer.encode_plus(\n#             question,\n#             context,\n#             add_special_tokens=True,\n#             truncation='longest_first',\n#             max_length=self.max_seq_length,\n#             return_tensors='pt'\n#         )\n#         input_ids = encoded_dict['input_ids'].squeeze()\n#         attention_mask = encoded_dict['attention_mask'].squeeze()\n#         input_ids = torch.nn.functional.pad(encoded_dict['input_ids'], (0, self.max_seq_length - encoded_dict['input_ids'].shape[1]), mode='constant', value=0)\n#         attention_mask = torch.nn.functional.pad(encoded_dict['attention_mask'], (0, self.max_seq_length - encoded_dict['attention_mask'].shape[1]), mode='constant', value=0)\n        \n        features = {'input_ids': input_ids, 'attention_mask': attention_mask, \n                    'token_type_ids': token_type_ids, 'start_token_idx': start_token_idx, 'end_token_idx': end_token_idx}\n#         max_len_dict = {}\n#         for key, value in features.items():\n#             if isinstance(value, (list, tuple)):\n#                 max_len_dict[key] = max(len(seq) for seq in value)\n#         for key, value in features.items():\n#             if isinstance(value, (list, tuple)):\n#                 max_len = max_len_dict[key]\n#                 for i in range(len(value)):\n#                     pad_len = max_len - len(value[i])\n#                     value[i] = torch.cat([value[i], torch.zeros(pad_len, dtype=torch.long)])\n#                 features[key] = torch.stack(value)\n\n        return features\n    \n    def create_qa_examples(self, data):\n        examples = []\n        for row in data:\n            text = row['text']\n            question = row['label']\n            extracted_part = row.get('extracted_part', {})\n            if extracted_part and 'text' in extracted_part:\n                answer = extracted_part['text'][0].strip()\n                answer_start = extracted_part['answer_start'][0]\n                answer_end = extracted_part['answer_end'][0]\n            else:\n                answer = answer_start = answer_end = None\n\n            example = {'context': text, 'question': question, 'answer': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n            examples.append(example)\n        return examples\n    \n    \n    @staticmethod\n    def prepare_test_data(data):\n        examples = []\n        for row in data:\n            text = row['text']\n            question = row['label']\n            example = {'context': text, 'question': question}\n            examples.append(example)\n        return examples\n\ndef collate_fn(batch, device):\n    input_ids = pad_sequence([torch.tensor(example['input_ids']) for example in batch], batch_first=True, padding_value=0).to(device)\n    attention_mask = pad_sequence([torch.tensor(example['attention_mask']) for example in batch], batch_first=True, padding_value=0).to(device)\n    token_type_ids = pad_sequence([torch.tensor(example['token_type_ids']) for example in batch], batch_first=True, padding_value=0).to(device)\n    start_positions = torch.tensor([example['answer_start'] for example in batch]).to(device)\n    end_positions = torch.tensor([example['answer_end'] for example in batch]).to(device)\n    return {\n        'input_ids': input_ids,\n        'attention_mask': attention_mask,\n        'token_type_ids': token_type_ids,\n        'start_positions': start_positions,\n        'end_positions': end_positions\n    }\n\n\ndef create_inputs_targets(dataset):\n    dataset_dict = {\n        \"input_ids\": [],\n        \"token_type_ids\": [],\n        \"attention_mask\": [],\n        \"start_token_idx\": [],\n        \"end_token_idx\": [],\n    }\n    for idx in range(len(dataset)):\n        example = dataset[idx]\n        for key in dataset_dict:\n            if isinstance(example[key], torch.Tensor):\n                value = example[key].numpy().tolist()\n            else:\n                value = example[key]\n            dataset_dict[key].append(value)\n\n\n    x = [\n        dataset_dict[\"input_ids\"],\n        dataset_dict[\"token_type_ids\"],\n        dataset_dict[\"attention_mask\"],\n    ]\n    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n    return x, y\n\ndef x_y_split(model_name, train_data, validation_data, batch_size):\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = TFAutoModelForQuestionAnswering.from_pretrained(model_name)\n#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    train_dataset = QADataset(train_data, tokenizer, max_seq_length)\n#     train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True,\n#                                    collate_fn=lambda batch: collate_fn(batch, device))\n    x_train, y_train = create_inputs_targets(train_dataset)\n    \n    validation_dataset = QADataset(validation_data, tokenizer, max_seq_length)\n#     validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, drop_last=True,\n#                                         collate_fn=lambda batch: collate_fn(batch, device))\n    x_val, y_val = create_inputs_targets(validation_dataset)\n\n    return x_train, y_train, x_val, y_val\n\n\n\ndef create_model(model_name):\n    ## BERT encoder\n    encoder = TFLongformerForQuestionAnswering.from_pretrained(model_name)\n\n    ## QA Model\n    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n    embedding = encoder(\n        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n    )[0]\n\n    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n    start_logits = layers.Flatten()(start_logits)\n\n    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n    end_logits = layers.Flatten()(end_logits)\n\n    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n\n    model = keras.Model(\n        inputs=[input_ids, token_type_ids, attention_mask],\n        outputs=[start_probs, end_probs],\n    )\n    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n    optimizer = keras.optimizers.Adam(lr=5e-5)\n    model.compile(optimizer=optimizer, loss=[loss, loss])\n    return model\n\nclass ExactMatch(keras.callbacks.Callback):\n    def __init__(self, x_eval, y_eval):\n        super().__init__()\n        self.x_eval = x_eval\n        self.y_eval = y_eval\n\n    def on_epoch_end(self, epoch, logs=None):\n        pred_start, pred_end = self.model.predict(self.x_eval)\n        count = 0\n        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n            offsets = squad_eg.context_token_to_char\n            start = np.argmax(start)\n            end = np.argmax(end)\n            if start >= len(offsets):\n                continue\n            pred_char_start = offsets[start][0]\n            if end < len(offsets):\n                pred_char_end = offsets[end][1]\n                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n            else:\n                pred_ans = squad_eg.context[pred_char_start:]\n\n            if pred_ans in squad_eg.all_answers:\n                count += 1\n        acc = count / len(self.y_eval[0])\n        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.768843Z","iopub.status.idle":"2023-04-24T19:16:31.769257Z","shell.execute_reply.started":"2023-04-24T19:16:31.769039Z","shell.execute_reply":"2023-04-24T19:16:31.769057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\")\nexamp = QADataset(train_data, tokenizer, max_seq_length)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.770832Z","iopub.status.idle":"2023-04-24T19:16:31.771192Z","shell.execute_reply.started":"2023-04-24T19:16:31.771010Z","shell.execute_reply":"2023-04-24T19:16:31.771026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"QADataset(train_data, tokenizer, max_seq_length)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.771962Z","iopub.status.idle":"2023-04-24T19:16:31.772307Z","shell.execute_reply.started":"2023-04-24T19:16:31.772127Z","shell.execute_reply":"2023-04-24T19:16:31.772143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# загружаем данные для обучения\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/train.json', 'r', encoding='utf-8') as file:\n    train_data = json.load(file)\n\n# загружаем данные для предсказания\nwith open('/kaggle/input/nlp-test-task-2023/nlp_test_task_2023/dataset/test.json', 'r', encoding='utf-8') as file:\n    test_data = json.load(file)\n\n# Разбиваем данные на обучающую и валидационную выборки\ntrain_data, validation_data = train_test_split(train_data[:50], test_size=0.2, random_state=42)\nmax_seq_length = 4000\nmodel_name = \"valhalla/longformer-base-4096-finetuned-squadv1\"\nconfiguration = LongformerConfig()\nnum_epochs = 3\n\nx_train, y_train, x_val, y_val = x_y_split(model_name = model_name, train_data = train_data, validation_data = validation_data, batch_size = 16)\nmax_len = len(x_train[0][0])","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.773513Z","iopub.status.idle":"2023-04-24T19:16:31.773837Z","shell.execute_reply.started":"2023-04-24T19:16:31.773675Z","shell.execute_reply":"2023-04-24T19:16:31.773690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.775420Z","iopub.status.idle":"2023-04-24T19:16:31.775753Z","shell.execute_reply.started":"2023-04-24T19:16:31.775585Z","shell.execute_reply":"2023-04-24T19:16:31.775601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train имеет структуру словаря, в котором есть 3 подсловаря - признака, в каждом из них набор примеров n-го количества, в каждом примере уже непосредственно находятся данные\nв y_train 2 словаря, которые содержат n примеров, в каждом из которых находится таргет. \nкакие модели обучения можно написать на таких данных, не пользуясь предобученными моделями и их ограничениями","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.777233Z","iopub.status.idle":"2023-04-24T19:16:31.777622Z","shell.execute_reply.started":"2023-04-24T19:16:31.777424Z","shell.execute_reply":"2023-04-24T19:16:31.777442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntf.debugging.set_log_device_placement(True)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.778910Z","iopub.status.idle":"2023-04-24T19:16:31.779323Z","shell.execute_reply.started":"2023-04-24T19:16:31.779104Z","shell.execute_reply":"2023-04-24T19:16:31.779123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.780206Z","iopub.status.idle":"2023-04-24T19:16:31.780525Z","shell.execute_reply.started":"2023-04-24T19:16:31.780364Z","shell.execute_reply":"2023-04-24T19:16:31.780380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_tpu = False  # Change to True if using TPU\n\nif use_tpu:\n    # Create distribution strategy\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    strategy = tf.distribute.TPUStrategy(tpu)\n\n    # Create model\n    with strategy.scope():\n        print('TPU used')\n        model = create_model(model_name)\nelse:\n#     # Use GPU if TPU is not available\n#     if tf.config.list_physical_devices('GPU'):\n#         strategy = tf.distribute.MirroredStrategy()\n        \n#     else:\n    strategy = tf.distribute.OneDeviceStrategy(device=\"/CPU:0\")\n\n    with strategy.scope():\n        model = create_model(model_name)\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.782022Z","iopub.status.idle":"2023-04-24T19:16:31.782363Z","shell.execute_reply.started":"2023-04-24T19:16:31.782197Z","shell.execute_reply":"2023-04-24T19:16:31.782213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\nprint(tf.test.is_built_with_cuda())\nprint(tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.783640Z","iopub.status.idle":"2023-04-24T19:16:31.783966Z","shell.execute_reply.started":"2023-04-24T19:16:31.783802Z","shell.execute_reply":"2023-04-24T19:16:31.783817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nx_train_np = [np.array(x_train[0]), np.array(x_train[1]), np.array(x_train[2])]\ny_train_np = [np.array(y_train[0]), np.array(y_train[1])]\nx_val_np = [np.array(x_val[0]), np.array(x_val[1]), np.array(x_val[2])]\ny_val_np = [np.array(y_val[0]), np.array(y_val[1])]\nexact_match_callback = ExactMatch(x_val_np, y_val_np)\nmodel.fit(\n    x_train_np,\n    y_train_np,\n    validation_data=(x_val_np, y_val_np),\n    epochs=1,\n    verbose=2,\n    batch_size=64,\n#     callbacks=[exact_match_callback],\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.785242Z","iopub.status.idle":"2023-04-24T19:16:31.785571Z","shell.execute_reply.started":"2023-04-24T19:16:31.785406Z","shell.execute_reply":"2023-04-24T19:16:31.785422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = QADataset(train_data, tokenizer, max_seq_length)\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True,\n                               collate_fn=lambda batch: collate_fn(batch, device))","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.786483Z","iopub.status.idle":"2023-04-24T19:16:31.786802Z","shell.execute_reply.started":"2023-04-24T19:16:31.786641Z","shell.execute_reply":"2023-04-24T19:16:31.786656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader.dataset[2]","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.787895Z","iopub.status.idle":"2023-04-24T19:16:31.788296Z","shell.execute_reply.started":"2023-04-24T19:16:31.788086Z","shell.execute_reply":"2023-04-24T19:16:31.788104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained('cointegrated/LaBSE-en-ru')\n# examples = QADataset.create_qa_examples(train_data, train_data)\n# questions = [example['context'] for example in examples]\n# question_tokens = [tokenizer.tokenize(question) for question in questions]\n# import matplotlib.pyplot as plt\n\n# question_lengths = [len(tokens) for tokens in question_tokens]\n# plt.hist(question_lengths, bins=50)\n# plt.xlabel('Length of question tokens')\n# plt.ylabel('Frequency')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.789664Z","iopub.status.idle":"2023-04-24T19:16:31.789996Z","shell.execute_reply.started":"2023-04-24T19:16:31.789824Z","shell.execute_reply":"2023-04-24T19:16:31.789839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Разбиваем данные на обучающую и валидационную выборки\n# train_data, validation_data = train_test_split(train_data, test_size=0.2, random_state=42)\n# max_seq_length = 3072\n# model_name = \"allenai/longformer-large-4096-finetuned-triviaqa\"\n\n# # Число эпох обучения\n# num_epochs = 3\n# output_dir = 'my_model'","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.791339Z","iopub.status.idle":"2023-04-24T19:16:31.791675Z","shell.execute_reply.started":"2023-04-24T19:16:31.791502Z","shell.execute_reply":"2023-04-24T19:16:31.791518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'cointegrated/LaBSE-en-ru'\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.793252Z","iopub.status.idle":"2023-04-24T19:16:31.793584Z","shell.execute_reply.started":"2023-04-24T19:16:31.793416Z","shell.execute_reply":"2023-04-24T19:16:31.793432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import BigBirdTokenizer, BigBirdForQuestionAnswering\n\n# tokenizer = BigBirdTokenizer.from_pretrained('google/bigbird-roberta-base')\n# model = BigBirdForQuestionAnswering.from_pretrained('google/bigbird-roberta-base')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.794383Z","iopub.status.idle":"2023-04-24T19:16:31.794699Z","shell.execute_reply.started":"2023-04-24T19:16:31.794539Z","shell.execute_reply":"2023-04-24T19:16:31.794554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# import tensorflow as tf\n\n# train(model_name, train_data, validation_data, output_dir)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T19:16:31.796114Z","iopub.status.idle":"2023-04-24T19:16:31.796460Z","shell.execute_reply.started":"2023-04-24T19:16:31.796289Z","shell.execute_reply":"2023-04-24T19:16:31.796305Z"},"trusted":true},"execution_count":null,"outputs":[]}]}