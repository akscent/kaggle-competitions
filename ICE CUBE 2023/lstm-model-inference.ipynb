{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import Modules\nimport gc\nimport os\nimport multiprocessing\nimport time\nimport numpy as np\nimport pandas as pd\nimport pyarrow.parquet as pq\nimport tensorflow as tf\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-17T02:16:40.115865Z","iopub.execute_input":"2023-04-17T02:16:40.116414Z","iopub.status.idle":"2023-04-17T02:16:45.605793Z","shell.execute_reply.started":"2023-04-17T02:16:40.116317Z","shell.execute_reply":"2023-04-17T02:16:45.604826Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Directories and constants\nhome_dir = \"/kaggle/input/icecube-neutrinos-in-deep-ice/\"\ntest_format = home_dir + 'test/batch_{batch_id:d}.parquet'\nmodel_home = \"/kaggle/input/lstmicecubesdata/\"\n\n# Model(s)\nmodel_names = [\"4347_MAE_1-02076_bin24_pp96_n6_batch2048_epoch29.h5\",\n               \"4347_MAE_1-02039_bin24_pp96_n6_batch2048_epoch25.h5\", \n               \"4346_MAE_1-02020_bin24_pp96_n6_batch2048_epoch27.h5\"]\nmodel_weights = np.array([0.30, \n                          0.30,\n                          0.40])","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:16:45.607809Z","iopub.execute_input":"2023-04-17T02:16:45.608508Z","iopub.status.idle":"2023-04-17T02:16:45.615425Z","shell.execute_reply.started":"2023-04-17T02:16:45.608462Z","shell.execute_reply":"2023-04-17T02:16:45.614125Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Load Model(s)","metadata":{}},{"cell_type":"code","source":"# Load Models\nmodels = []\nfor model_name in model_names:\n    print(f'\\n========== Model File: {model_name}')\n    \n    # Load Model\n    model_path = model_home + model_name\n    model = tf.keras.models.load_model(model_path, compile = False)\n    models.append(model)      \n    \n    # Model summary\n    model.summary()\n    \n# Get Model Parameters\npulse_count = model.inputs[0].shape[1]\nfeature_count = model.inputs[0].shape[2]\noutput_bins = model.layers[-1].weights[0].shape[-1]\nbin_num = int(np.sqrt(output_bins))\n\n# Model Parameter Summary\nprint(\"\\n==== Model Parameters\")\nprint(f\"Bin Numbers: {bin_num}\")\nprint(f\"Maximum Pulse Count: {pulse_count}\")\nprint(f\"Features Count: {feature_count}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:16:45.617471Z","iopub.execute_input":"2023-04-17T02:16:45.617829Z","iopub.status.idle":"2023-04-17T02:17:03.324087Z","shell.execute_reply.started":"2023-04-17T02:16:45.617794Z","shell.execute_reply":"2023-04-17T02:17:03.323096Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\n========== Model File: 4347_MAE_1-02076_bin24_pp96_n6_batch2048_epoch29.h5\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 96, 6)]           0         \n_________________________________________________________________\nmasking (Masking)            (None, 96, 6)             0         \n_________________________________________________________________\nbidirectional (Bidirectional (None, 96, 384)           230400    \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 96, 384)           665856    \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 384)               665856    \n_________________________________________________________________\ndense (Dense)                (None, 256)               98560     \n_________________________________________________________________\ndense_1 (Dense)              (None, 576)               148032    \n=================================================================\nTotal params: 1,808,704\nTrainable params: 1,808,704\nNon-trainable params: 0\n_________________________________________________________________\n\n========== Model File: 4347_MAE_1-02039_bin24_pp96_n6_batch2048_epoch25.h5\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 96, 6)]           0         \n_________________________________________________________________\nmasking (Masking)            (None, 96, 6)             0         \n_________________________________________________________________\nbidirectional (Bidirectional (None, 96, 384)           230400    \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 96, 384)           665856    \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 384)               665856    \n_________________________________________________________________\ndense (Dense)                (None, 256)               98560     \n_________________________________________________________________\ndense_1 (Dense)              (None, 576)               148032    \n=================================================================\nTotal params: 1,808,704\nTrainable params: 1,808,704\nNon-trainable params: 0\n_________________________________________________________________\n\n========== Model File: 4346_MAE_1-02020_bin24_pp96_n6_batch2048_epoch27.h5\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 96, 6)]           0         \n_________________________________________________________________\nmasking (Masking)            (None, 96, 6)             0         \n_________________________________________________________________\nbidirectional (Bidirectional (None, 96, 384)           230400    \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 96, 384)           665856    \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 384)               665856    \n_________________________________________________________________\ndense (Dense)                (None, 256)               98560     \n_________________________________________________________________\ndense_1 (Dense)              (None, 576)               148032    \n=================================================================\nTotal params: 1,808,704\nTrainable params: 1,808,704\nNon-trainable params: 0\n_________________________________________________________________\n\n==== Model Parameters\nBin Numbers: 24\nMaximum Pulse Count: 96\nFeatures Count: 6\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Detector Information","metadata":{}},{"cell_type":"code","source":"# Load sensor_geometry\nsensor_geometry_df = pd.read_csv(home_dir + \"sensor_geometry.csv\")\n\n# Get Sensor Information\nsensor_x = sensor_geometry_df.x\nsensor_y = sensor_geometry_df.y\nsensor_z = sensor_geometry_df.z\n\n# Detector constants\nc_const = 0.299792458  # speed of light [m/ns]\n\n# Sensor Min / Max Coordinates\nx_min = sensor_x.min()\nx_max = sensor_x.max()\ny_min = sensor_y.min()\ny_max = sensor_y.max()\nz_min = sensor_z.min()\nz_max = sensor_z.max()\n\ndetector_length = np.sqrt((x_max - x_min)**2 + (y_max - y_min)**2 + (z_max - z_min)**2)\nt_valid_length = detector_length / c_const\n\nprint(f\"time valid length: {t_valid_length} ns\")","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:17:03.326855Z","iopub.execute_input":"2023-04-17T02:17:03.327426Z","iopub.status.idle":"2023-04-17T02:17:03.353503Z","shell.execute_reply.started":"2023-04-17T02:17:03.327370Z","shell.execute_reply":"2023-04-17T02:17:03.352121Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"time valid length: 6199.700247193777 ns\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create Azimuth Edges\nazimuth_edges = np.linspace(0, 2 * np.pi, bin_num + 1)\nprint(azimuth_edges)\n\n# Create Zenith Edges\nzenith_edges = []\nzenith_edges.append(0)\nfor bin_idx in range(1, bin_num):\n    zenith_edges.append(np.arccos(np.cos(zenith_edges[-1]) - 2 / (bin_num)))\nzenith_edges.append(np.pi)\nzenith_edges = np.array(zenith_edges)\nprint(zenith_edges)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:17:03.355176Z","iopub.execute_input":"2023-04-17T02:17:03.355668Z","iopub.status.idle":"2023-04-17T02:17:03.365011Z","shell.execute_reply.started":"2023-04-17T02:17:03.355632Z","shell.execute_reply":"2023-04-17T02:17:03.364063Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[0.         0.26179939 0.52359878 0.78539816 1.04719755 1.30899694\n 1.57079633 1.83259571 2.0943951  2.35619449 2.61799388 2.87979327\n 3.14159265 3.40339204 3.66519143 3.92699082 4.1887902  4.45058959\n 4.71238898 4.97418837 5.23598776 5.49778714 5.75958653 6.02138592\n 6.28318531]\n[0.         0.41113786 0.58568554 0.72273425 0.84106867 0.94796974\n 1.04719755 1.1410209  1.23095942 1.31811607 1.40334825 1.48736624\n 1.57079633 1.65422641 1.73824441 1.82347658 1.91063324 2.00057176\n 2.0943951  2.19362291 2.30052398 2.41885841 2.55590711 2.73045479\n 3.14159265]\n","output_type":"stream"}]},{"cell_type":"code","source":"angle_bin_zenith0 = np.tile(zenith_edges[:-1], bin_num)\nangle_bin_zenith1 = np.tile(zenith_edges[1:], bin_num)\nangle_bin_azimuth0 = np.repeat(azimuth_edges[:-1], bin_num)\nangle_bin_azimuth1 = np.repeat(azimuth_edges[1:], bin_num)\n\nangle_bin_area = (angle_bin_azimuth1 - angle_bin_azimuth0) * (np.cos(angle_bin_zenith0) - np.cos(angle_bin_zenith1))\nangle_bin_vector_sum_x = (np.sin(angle_bin_azimuth1) - np.sin(angle_bin_azimuth0)) * ((angle_bin_zenith1 - angle_bin_zenith0) / 2 - (np.sin(2 * angle_bin_zenith1) - np.sin(2 * angle_bin_zenith0)) / 4)\nangle_bin_vector_sum_y = (np.cos(angle_bin_azimuth0) - np.cos(angle_bin_azimuth1)) * ((angle_bin_zenith1 - angle_bin_zenith0) / 2 - (np.sin(2 * angle_bin_zenith1) - np.sin(2 * angle_bin_zenith0)) / 4)\nangle_bin_vector_sum_z = (angle_bin_azimuth1 - angle_bin_azimuth0) * ((np.cos(2 * angle_bin_zenith0) - np.cos(2 * angle_bin_zenith1)) / 4)\n\nangle_bin_vector_mean_x = angle_bin_vector_sum_x / angle_bin_area\nangle_bin_vector_mean_y = angle_bin_vector_sum_y / angle_bin_area\nangle_bin_vector_mean_z = angle_bin_vector_sum_z / angle_bin_area\n\nangle_bin_vector = np.zeros((1, bin_num * bin_num, 3))\nangle_bin_vector[:, :, 0] = angle_bin_vector_mean_x\nangle_bin_vector[:, :, 1] = angle_bin_vector_mean_y\nangle_bin_vector[:, :, 2] = angle_bin_vector_mean_z\n\nangle_bin_vector_unit = angle_bin_vector[0].copy()\nangle_bin_vector_unit /= np.sqrt((angle_bin_vector_unit**2).sum(axis=1).reshape((-1, 1)))","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:17:03.366334Z","iopub.execute_input":"2023-04-17T02:17:03.367159Z","iopub.status.idle":"2023-04-17T02:17:03.380322Z","shell.execute_reply.started":"2023-04-17T02:17:03.367120Z","shell.execute_reply":"2023-04-17T02:17:03.379445Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def pred_to_angle(pred, epsilon = 1e-8):\n    # Convert prediction\n    pred_vector = (pred.reshape((-1, bin_num**2, 1)) * angle_bin_vector).sum(axis = 1)\n    \n    # Normalize\n    pred_vector_norm = np.sqrt((pred_vector**2).sum(axis = 1))\n    mask = pred_vector_norm < epsilon\n    pred_vector_norm[mask] = 1\n    \n    # Assign <1, 0, 0> to very small vectors (badly predicted)\n    pred_vector /= pred_vector_norm.reshape((-1, 1))\n    pred_vector[mask] = np.array([1., 0., 0.])\n    \n    # Convert to angle\n    azimuth = np.arctan2(pred_vector[:, 1], pred_vector[:, 0])\n    azimuth[azimuth < 0] += 2 * np.pi\n    zenith = np.arccos(pred_vector[:, 2])\n    \n    # Mask bad norm predictions as 0, 0\n    azimuth[mask] = 0.\n    zenith[mask] = 0.\n    \n    return azimuth, zenith","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:17:03.381719Z","iopub.execute_input":"2023-04-17T02:17:03.382449Z","iopub.status.idle":"2023-04-17T02:17:03.395045Z","shell.execute_reply.started":"2023-04-17T02:17:03.382390Z","shell.execute_reply":"2023-04-17T02:17:03.393982Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Weighted-Vector Ensemble","metadata":{}},{"cell_type":"code","source":"def weighted_vector_ensemble(angles, weight):\n    # Convert angle to vector\n    vec_models = list()\n    for angle in angles:\n        az, zen = angle\n        sa = np.sin(az)\n        ca = np.cos(az)\n        sz = np.sin(zen)\n        cz = np.cos(zen)\n        vec = np.stack([sz * ca, sz * sa, cz], axis=1)\n        vec_models.append(vec)\n    vec_models = np.array(vec_models)\n\n    # Weighted-mean\n    vec_mean = (weight.reshape((-1, 1, 1)) * vec_models).sum(axis=0) / weight.sum()\n    vec_mean /= np.sqrt((vec_mean**2).sum(axis=1)).reshape((-1, 1))\n\n    # Convert vector to angle\n    zenith = np.arccos(vec_mean[:, 2])\n    azimuth = np.arctan2(vec_mean[:, 1], vec_mean[:, 0])\n    azimuth[azimuth < 0] += 2 * np.pi\n    \n    return azimuth, zenith","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:17:03.396502Z","iopub.execute_input":"2023-04-17T02:17:03.397051Z","iopub.status.idle":"2023-04-17T02:17:03.410770Z","shell.execute_reply.started":"2023-04-17T02:17:03.397016Z","shell.execute_reply":"2023-04-17T02:17:03.409653Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Placeholder\nopen_batch_dict = dict()\n\n# Read single event from batch_meta_df\ndef read_event(event_idx, batch_meta_df, pulse_count):\n    # Read metadata\n    batch_id, first_pulse_index, last_pulse_index = batch_meta_df.iloc[event_idx][[\"batch_id\", \"first_pulse_index\", \"last_pulse_index\"]].astype(\"int\")\n\n    # close past batch df\n    if batch_id - 1 in open_batch_dict.keys():\n        del open_batch_dict[batch_id - 1]\n\n    # open current batch df\n    if batch_id not in open_batch_dict.keys():\n        open_batch_dict.update({batch_id: pd.read_parquet(test_format.format(batch_id=batch_id))})\n    \n    batch_df = open_batch_dict[batch_id]\n    \n    # Read event\n    event_feature = batch_df[first_pulse_index:last_pulse_index + 1]\n    sensor_id = event_feature.sensor_id\n    \n    # Merge features into single structured array\n    dtype = [(\"time\", \"float16\"),\n             (\"charge\", \"float16\"),\n             (\"auxiliary\", \"float16\"),\n             (\"x\", \"float16\"),\n             (\"y\", \"float16\"),\n             (\"z\", \"float16\"),\n             (\"rank\", \"short\")]    \n    \n    # Create event_x\n    event_x = np.zeros(last_pulse_index - first_pulse_index + 1, dtype)\n    event_x[\"time\"] = event_feature.time.values - event_feature.time.min()\n    event_x[\"charge\"] = event_feature.charge.values\n    event_x[\"auxiliary\"] = event_feature.auxiliary.values\n    event_x[\"x\"] = sensor_geometry_df.x[sensor_id].values\n    event_x[\"y\"] = sensor_geometry_df.y[sensor_id].values\n    event_x[\"z\"] = sensor_geometry_df.z[sensor_id].values\n\n    # For long event, pick-up\n    if len(event_x) > pulse_count:\n        # Find valid time window\n        t_peak = event_x[\"time\"][event_x[\"charge\"].argmax()]\n        t_valid_min = t_peak - t_valid_length\n        t_valid_max = t_peak + t_valid_length\n        t_valid = (event_x[\"time\"] > t_valid_min) * (event_x[\"time\"] < t_valid_max)\n\n        # Rank\n        event_x[\"rank\"] = 2 * (1 - event_x[\"auxiliary\"]) + (t_valid)\n\n        # Sort by Rank and Charge (important goes to backward)\n        event_x = np.sort(event_x, order = [\"rank\", \"charge\"])\n\n        # pick-up from backward\n        event_x = event_x[-pulse_count:]\n\n        # Sort events by time \n        event_x = np.sort(event_x, order = \"time\")\n\n    return event_idx, len(event_x), event_x","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:17:03.412569Z","iopub.execute_input":"2023-04-17T02:17:03.413062Z","iopub.status.idle":"2023-04-17T02:17:03.426391Z","shell.execute_reply.started":"2023-04-17T02:17:03.413024Z","shell.execute_reply":"2023-04-17T02:17:03.425107Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Test metadata","metadata":{}},{"cell_type":"code","source":"# Read Test Meta data\ntest_meta_df = pq.read_table(home_dir + 'test_meta.parquet').to_pandas()\nbatch_counts = test_meta_df.batch_id.value_counts().sort_index()\n\nbatch_max_index = batch_counts.cumsum()\nbatch_max_index[test_meta_df.batch_id.min() - 1] = 0\nbatch_max_index = batch_max_index.sort_index()\n\n# Support Function\ndef test_meta_df_spliter(batch_id):\n    return test_meta_df.loc[batch_max_index[batch_id - 1]:batch_max_index[batch_id] - 1]","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:17:03.429985Z","iopub.execute_input":"2023-04-17T02:17:03.430376Z","iopub.status.idle":"2023-04-17T02:17:03.516915Z","shell.execute_reply.started":"2023-04-17T02:17:03.430351Z","shell.execute_reply":"2023-04-17T02:17:03.515972Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Read test data and predict batchwise","metadata":{}},{"cell_type":"code","source":"# Get Batch IDs\ntest_batch_ids = test_meta_df.batch_id.unique()\n\n# Submission Placeholders\ntest_event_id = []\ntest_azimuth = []\ntest_zenith = []\n\n# Batch Loop\nfor batch_id in test_batch_ids:\n    # Batch Meta DF\n    batch_meta_df = test_meta_df_spliter(batch_id)\n\n    # Set Pulses\n    test_x = np.zeros((len(batch_meta_df), pulse_count, feature_count), dtype = \"float16\")    \n    test_x[:, :, 2] = -1    \n\n    # Read Event Data\n    def read_event_local(event_idx):\n        return read_event(event_idx, batch_meta_df, pulse_count)\n    \n    # Multiprocess Events\n    iterator = range(len(batch_meta_df))\n    with multiprocessing.Pool() as pool:\n        for event_idx, pulsecount, event_x in pool.map(read_event_local, iterator):\n            # Features\n            test_x[event_idx, :pulsecount, 0] = event_x[\"time\"]\n            test_x[event_idx, :pulsecount, 1] = event_x[\"charge\"]\n            test_x[event_idx, :pulsecount, 2] = event_x[\"auxiliary\"]\n            test_x[event_idx, :pulsecount, 3] = event_x[\"x\"]\n            test_x[event_idx, :pulsecount, 4] = event_x[\"y\"]\n            test_x[event_idx, :pulsecount, 5] = event_x[\"z\"]\n    \n    del batch_meta_df\n    \n    # Normalize\n    test_x[:, :, 0] /= 1000  # time\n    test_x[:, :, 1] /= 300  # charge\n    test_x[:, :, 3:] /= 600  # space\n        \n    # Predict\n    pred_angles = []\n    for model in models:\n        pred_model = model.predict(test_x, verbose=0)\n        az_model, zen_model = pred_to_angle(pred_model)\n        pred_angles.append((az_model, zen_model))\n    \n    # Get Predicted Azimuth and Zenith\n    pred_azimuth, pred_zenith = weighted_vector_ensemble(pred_angles, model_weights)\n    \n    # Get Event IDs\n    event_ids = test_meta_df.event_id[test_meta_df.batch_id == batch_id].values\n    \n    # Finalize \n    for event_id, azimuth, zenith in zip(event_ids, pred_azimuth, pred_zenith):\n        if np.isfinite(azimuth) and np.isfinite(zenith):\n            test_event_id.append(int(event_id))\n            test_azimuth.append(azimuth)\n            test_zenith.append(zenith)\n        else:\n            test_event_id.append(int(event_id))\n            test_azimuth.append(0.)\n            test_zenith.append(0.)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:17:03.518394Z","iopub.execute_input":"2023-04-17T02:17:03.518746Z","iopub.status.idle":"2023-04-17T02:17:23.638928Z","shell.execute_reply.started":"2023-04-17T02:17:03.518713Z","shell.execute_reply":"2023-04-17T02:17:23.637665Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Create Submission","metadata":{}},{"cell_type":"code","source":"# Create and Save Submission.csv\nsubmission_df = pd.DataFrame({\"event_id\": test_event_id,\n                              \"azimuth\": test_azimuth,\n                              \"zenith\": test_zenith})\nsubmission_df = submission_df.sort_values(by = ['event_id'])\nsubmission_df.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:17:23.641869Z","iopub.execute_input":"2023-04-17T02:17:23.642309Z","iopub.status.idle":"2023-04-17T02:17:23.654775Z","shell.execute_reply.started":"2023-04-17T02:17:23.642266Z","shell.execute_reply":"2023-04-17T02:17:23.653443Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Summary\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T02:17:23.657140Z","iopub.execute_input":"2023-04-17T02:17:23.657956Z","iopub.status.idle":"2023-04-17T02:17:23.677750Z","shell.execute_reply.started":"2023-04-17T02:17:23.657900Z","shell.execute_reply":"2023-04-17T02:17:23.676897Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   event_id   azimuth    zenith\n0      2092  1.925599  1.546070\n1      7344  3.405561  2.528163\n2      9482  4.585169  1.533669","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event_id</th>\n      <th>azimuth</th>\n      <th>zenith</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2092</td>\n      <td>1.925599</td>\n      <td>1.546070</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7344</td>\n      <td>3.405561</td>\n      <td>2.528163</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9482</td>\n      <td>4.585169</td>\n      <td>1.533669</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}